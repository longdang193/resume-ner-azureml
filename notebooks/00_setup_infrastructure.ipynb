{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infrastructure Setup\n",
    "\n",
    "This notebook provisions and validates Azure infrastructure for the Resume NER training pipeline.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Step 1**: Load Configuration\n",
    "- **Step 2**: Validate Environment Variables\n",
    "- **Step 3**: Create/Verify Azure ML Workspace\n",
    "- **Step 4**: Create/Verify Storage Account and Containers\n",
    "- **Step 5**: Create/Verify Compute Clusters\n",
    "- **Step 6**: (Optional) Validate Infrastructure\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Authenticate with Azure** (via `DefaultAzureCredential`):\n",
    "   - Azure CLI: `az login`\n",
    "   - VS Code Azure extension\n",
    "   - Managed Identity\n",
    "   - Service Principal environment variables\n",
    "\n",
    "2. **Install dependencies**:\n",
    "   ```bash\n",
    "   pip install -r setup/requirements.txt\n",
    "   ```\n",
    "\n",
    "3. **Configure environment variables**:\n",
    "   ```bash\n",
    "   cp config.env.example config.env\n",
    "   # Edit config.env with your values\n",
    "   ```\n",
    "\n",
    "## Configuration\n",
    "\n",
    "Edit `config/infrastructure.yaml` to customize resource names, VM sizes, and auto-scale settings.\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Operations are idempotent (safe to run multiple times)\n",
    "- Compute clusters auto-scale to 0 when idle\n",
    "- Infrastructure must exist before running orchestration notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] NOTEBOOK_DIR: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\notebooks\n",
      "[DEBUG] PROJECT_ROOT: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\n",
      "[DEBUG] CONFIG_PATH: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config\\infrastructure.yaml (exists: True)\n",
      "[DEBUG] ENV_PATH: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config.env (exists: True)\n",
      "\n",
      "[DEBUG] Loaded environment from: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config.env\n",
      "[DEBUG] AZURE_LOCATION: germanywestcentral\n",
      "[DEBUG] AZURE_SUBSCRIPTION_ID: 50c06ef8...\n",
      "[DEBUG] AZURE_RESOURCE_GROUP: resume_ner_2026-01-02-16-47-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from typing import Dict, Any, Tuple\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Workspace, AmlCompute\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "from azure.mgmt.storage.models import (\n",
    "    StorageAccountCreateParameters,\n",
    "    Sku,\n",
    "    SkuName,\n",
    "    Kind,\n",
    "    AccessTier,\n",
    "    PublicAccess,\n",
    ")\n",
    "from azure.mgmt.resource import ResourceManagementClient\n",
    "from azure.mgmt.resource.resources.models import ResourceGroup\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Fix path resolution - ensure we find config.env from notebook directory\n",
    "# Get the notebook's directory (where this file is)\n",
    "NOTEBOOK_DIR = Path.cwd()  # Current working directory when notebook runs\n",
    "# If running from notebooks/ directory, go up one level\n",
    "if NOTEBOOK_DIR.name == \"notebooks\":\n",
    "    PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "else:\n",
    "    # Try to find project root by looking for config.env\n",
    "    PROJECT_ROOT = NOTEBOOK_DIR\n",
    "    while PROJECT_ROOT != PROJECT_ROOT.parent:\n",
    "        if (PROJECT_ROOT / \"config.env\").exists():\n",
    "            break\n",
    "        PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "    else:\n",
    "        # Fallback: assume we're in project root\n",
    "        PROJECT_ROOT = NOTEBOOK_DIR\n",
    "\n",
    "CONFIG_PATH = PROJECT_ROOT / \"config\" / \"infrastructure.yaml\"\n",
    "ENV_PATH = PROJECT_ROOT / \"config.env\"\n",
    "REQUIRED_ENV_VARS = [\"AZURE_SUBSCRIPTION_ID\", \"AZURE_RESOURCE_GROUP\"]\n",
    "CONNECTION_STRING_TEMPLATE = \"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "\n",
    "print(f\"[DEBUG] NOTEBOOK_DIR: {NOTEBOOK_DIR}\")\n",
    "print(f\"[DEBUG] PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "print(f\"[DEBUG] CONFIG_PATH: {CONFIG_PATH} (exists: {CONFIG_PATH.exists()})\")\n",
    "print(f\"[DEBUG] ENV_PATH: {ENV_PATH} (exists: {ENV_PATH.exists()})\")\n",
    "print()\n",
    "\n",
    "# Load environment variables with explicit path\n",
    "if ENV_PATH.exists():\n",
    "    load_dotenv(ENV_PATH, override=True)\n",
    "    print(f\"[DEBUG] Loaded environment from: {ENV_PATH}\")\n",
    "    az_location = os.getenv(\"AZURE_LOCATION\")\n",
    "    az_sub_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "    az_rg = os.getenv(\"AZURE_RESOURCE_GROUP\")\n",
    "    print(f\"[DEBUG] AZURE_LOCATION: {az_location}\")\n",
    "    print(f\"[DEBUG] AZURE_SUBSCRIPTION_ID: {az_sub_id[:8] if az_sub_id else None}...\")\n",
    "    print(f\"[DEBUG] AZURE_RESOURCE_GROUP: {az_rg}\")\n",
    "else:\n",
    "    print(f\"[WARNING] config.env not found at: {ENV_PATH}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Validate Environment Variables\n",
    "\n",
    "Ensure required environment variables are set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_environment_variables() -> None:\n",
    "    \"\"\"\n",
    "    Validate required environment variables are set.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If required variables are missing\n",
    "    \"\"\"\n",
    "    missing = [var for var in REQUIRED_ENV_VARS if not os.getenv(var)]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing environment variables: {', '.join(missing)}\")\n",
    "\n",
    "\n",
    "validate_environment_variables()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create/Verify Azure ML Workspace\n",
    "\n",
    "Create or retrieve the Azure ML Workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load and resolve infrastructure configuration from config.yaml.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Configuration dictionary with resolved environment variables\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: If config file does not exist\n",
    "    \"\"\"\n",
    "    if not CONFIG_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Config file not found: {CONFIG_PATH}\")\n",
    "    \n",
    "    # Reload environment variables to ensure latest values\n",
    "    if ENV_PATH.exists():\n",
    "        load_dotenv(ENV_PATH, override=True)\n",
    "    \n",
    "    with open(CONFIG_PATH, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    # Resolve subscription_id - prioritize environment variable\n",
    "    subscription_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "    if subscription_id:\n",
    "        config[\"azure\"][\"subscription_id\"] = subscription_id\n",
    "    elif isinstance(config[\"azure\"][\"subscription_id\"], str) and config[\"azure\"][\"subscription_id\"].startswith(\"${\"):\n",
    "        match = re.match(r'\\$\\{([^:]+)(?::-([^}]+))?\\}', config[\"azure\"][\"subscription_id\"])\n",
    "        if match:\n",
    "            var_name, default = match.groups()\n",
    "            config[\"azure\"][\"subscription_id\"] = os.getenv(var_name, default or \"\")\n",
    "    \n",
    "    # Resolve resource_group - prioritize environment variable\n",
    "    resource_group = os.getenv(\"AZURE_RESOURCE_GROUP\")\n",
    "    if resource_group:\n",
    "        config[\"azure\"][\"resource_group\"] = resource_group\n",
    "    elif isinstance(config[\"azure\"][\"resource_group\"], str) and config[\"azure\"][\"resource_group\"].startswith(\"${\"):\n",
    "        match = re.match(r'\\$\\{([^:]+)(?::-([^}]+))?\\}', config[\"azure\"][\"resource_group\"])\n",
    "        if match:\n",
    "            var_name, default = match.groups()\n",
    "            config[\"azure\"][\"resource_group\"] = os.getenv(var_name, default or \"\")\n",
    "    \n",
    "    # Resolve location - prioritize environment variable\n",
    "    location = os.getenv(\"AZURE_LOCATION\")\n",
    "    if location:\n",
    "        config[\"azure\"][\"location\"] = location\n",
    "    elif isinstance(config[\"azure\"][\"location\"], str) and config[\"azure\"][\"location\"].startswith(\"${\"):\n",
    "        match = re.match(r'\\$\\{([^:]+)(?::-([^}]+))?\\}', config[\"azure\"][\"location\"])\n",
    "        if match:\n",
    "            var_name, default = match.groups()\n",
    "            config[\"azure\"][\"location\"] = os.getenv(var_name, default or \"southeastasia\")\n",
    "    \n",
    "    # Warn if location seems invalid\n",
    "    valid_regions = [\"eastus\", \"eastus2\", \"westus\", \"westus2\", \"westus3\", \"westcentralus\",\n",
    "                     \"southcentralus\", \"northcentralus\", \"centralus\", \"westeurope\", \"northeurope\",\n",
    "                     \"swedencentral\", \"uksouth\", \"ukwest\", \"francecentral\", \"germanywestcentral\",\n",
    "                     \"norwayeast\", \"switzerlandnorth\", \"eastasia\", \"southeastasia\", \"japaneast\",\n",
    "                     \"japanwest\", \"koreacentral\", \"koreasouth\", \"australiaeast\", \"australiasoutheast\",\n",
    "                     \"australiacentral\", \"brazilsouth\", \"canadaeast\", \"canadacentral\", \"southindia\",\n",
    "                     \"centralindia\", \"westindia\", \"uaenorth\", \"southafricanorth\", \"qatarcentral\"]\n",
    "    \n",
    "    if config[\"azure\"][\"location\"] not in valid_regions:\n",
    "        print(f\"[WARNING] Location '{config['azure']['location']}' may not be a valid Azure region.\")\n",
    "    \n",
    "    # Summary output\n",
    "    print(f\"Configuration loaded:\")\n",
    "    print(f\"  Subscription ID: {config['azure']['subscription_id'][:8]}...\")\n",
    "    print(f\"  Resource Group: {config['azure']['resource_group']}\")\n",
    "    print(f\"  Location: {config['azure']['location']}\")\n",
    "    print()\n",
    "    \n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  Subscription ID: 50c06ef8...\n",
      "  Resource Group: resume_ner_2026-01-02-16-47-05\n",
      "  Location: germanywestcentral\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "def create_or_get_resource_group(config: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Create resource group if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        config: Infrastructure configuration dictionary\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If resource group creation fails\n",
    "    \"\"\"\n",
    "    subscription_id = config[\"azure\"][\"subscription_id\"]\n",
    "    resource_group = config[\"azure\"][\"resource_group\"]\n",
    "    location = config[\"azure\"][\"location\"]\n",
    "    credential = DefaultAzureCredential()\n",
    "    \n",
    "    resource_client = ResourceManagementClient(credential, subscription_id)\n",
    "    \n",
    "    try:\n",
    "        resource_client.resource_groups.get(resource_group)\n",
    "    except ResourceNotFoundError:\n",
    "        resource_group_params = ResourceGroup(location=location)\n",
    "        resource_client.resource_groups.create_or_update(resource_group, resource_group_params)\n",
    "\n",
    "\n",
    "def create_or_get_workspace(config: Dict[str, Any]) -> MLClient:\n",
    "    \"\"\"\n",
    "    Create or retrieve Azure ML Workspace.\n",
    "    \n",
    "    Args:\n",
    "        config: Infrastructure configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        MLClient: MLClient instance connected to the workspace\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If workspace creation or access fails\n",
    "    \"\"\"\n",
    "    subscription_id = config[\"azure\"][\"subscription_id\"]\n",
    "    resource_group = config[\"azure\"][\"resource_group\"]\n",
    "    workspace_name = config[\"workspace\"][\"name\"]\n",
    "    credential = DefaultAzureCredential()\n",
    "    \n",
    "    create_or_get_resource_group(config)\n",
    "    \n",
    "    try:\n",
    "        ml_client = MLClient(credential, subscription_id, resource_group, workspace_name)\n",
    "        ml_client.workspaces.get(workspace_name)\n",
    "        return ml_client\n",
    "    except ResourceNotFoundError:\n",
    "        workspace = Workspace(\n",
    "            name=workspace_name,\n",
    "            location=config[\"azure\"][\"location\"],\n",
    "            description=config[\"workspace\"].get(\"description\", \"\"),\n",
    "            display_name=workspace_name,\n",
    "        )\n",
    "        ml_client = MLClient(credential, subscription_id, resource_group)\n",
    "        ml_client.workspaces.begin_create(workspace).result()\n",
    "        return MLClient(credential, subscription_id, resource_group, workspace_name)\n",
    "\n",
    "\n",
    "# Ensure config is loaded\n",
    "if 'config' not in globals():\n",
    "    config = load_config()\n",
    "\n",
    "ml_client = create_or_get_workspace(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create/Verify Storage Account and Containers\n",
    "\n",
    "Create or retrieve Azure Blob Storage account and required containers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_connection_string(account_name: str, account_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Build storage account connection string.\n",
    "    \n",
    "    Args:\n",
    "        account_name: Storage account name\n",
    "        account_key: Storage account key\n",
    "        \n",
    "    Returns:\n",
    "        str: Connection string for blob service client\n",
    "    \"\"\"\n",
    "    return CONNECTION_STRING_TEMPLATE.format(account_name=account_name, account_key=account_key)\n",
    "\n",
    "\n",
    "def create_or_get_storage(config: Dict[str, Any]) -> BlobServiceClient:\n",
    "    \"\"\"\n",
    "    Create or retrieve Azure Blob Storage account and containers.\n",
    "    \n",
    "    Args:\n",
    "        config: Infrastructure configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        BlobServiceClient: BlobServiceClient instance\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If storage creation or access fails\n",
    "    \"\"\"\n",
    "    subscription_id = config[\"azure\"][\"subscription_id\"]\n",
    "    resource_group = config[\"azure\"][\"resource_group\"]\n",
    "    location = config[\"azure\"][\"location\"]\n",
    "    account_name = config[\"storage\"][\"account_name\"]\n",
    "    \n",
    "    credential = DefaultAzureCredential()\n",
    "    storage_management = StorageManagementClient(credential, subscription_id)\n",
    "    \n",
    "    try:\n",
    "        storage_management.storage_accounts.get_properties(resource_group, account_name)\n",
    "    except ResourceNotFoundError:\n",
    "        params = StorageAccountCreateParameters(\n",
    "            sku=Sku(name=SkuName.STANDARD_LRS),\n",
    "            kind=Kind.STORAGE_V2,\n",
    "            location=location,\n",
    "            access_tier=AccessTier.HOT,\n",
    "        )\n",
    "        storage_management.storage_accounts.begin_create(resource_group, account_name, params).result()\n",
    "    \n",
    "    keys = storage_management.storage_accounts.list_keys(resource_group, account_name)\n",
    "    connection_string = build_connection_string(account_name, keys.keys[0].value)\n",
    "    blob_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    \n",
    "    for container_config in config[\"storage\"][\"containers\"]:\n",
    "        container_name = container_config[\"name\"]\n",
    "        public_access_str = container_config.get(\"public_access\", \"None\")\n",
    "        \n",
    "        if public_access_str is None or public_access_str.lower() == \"none\":\n",
    "            public_access = None\n",
    "        else:\n",
    "            public_access = getattr(PublicAccess, public_access_str.upper(), None)\n",
    "            if public_access is None:\n",
    "                raise ValueError(f\"Invalid public_access value: {public_access_str}\")\n",
    "        \n",
    "        container = blob_client.get_container_client(container_name)\n",
    "        if not container.exists():\n",
    "            container.create_container(public_access=public_access)\n",
    "    \n",
    "    return blob_client\n",
    "\n",
    "\n",
    "blob_client = create_or_get_storage(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create/Verify Compute Clusters\n",
    "\n",
    "Create or retrieve GPU and CPU compute clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_get_compute_cluster(\n",
    "    ml_client: MLClient,\n",
    "    cluster_name: str,\n",
    "    vm_size: str,\n",
    "    min_nodes: int,\n",
    "    max_nodes: int,\n",
    "    idle_time_before_scale_down: int,\n",
    ") -> AmlCompute:\n",
    "    \"\"\"\n",
    "    Create or retrieve a single compute cluster.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        cluster_name: Name of the compute cluster\n",
    "        vm_size: VM size (e.g., \"Standard_NC6s_v3\")\n",
    "        min_nodes: Minimum number of nodes (0 for cost savings)\n",
    "        max_nodes: Maximum number of nodes\n",
    "        idle_time_before_scale_down: Idle time in seconds before scaling down\n",
    "        \n",
    "    Returns:\n",
    "        AmlCompute instance\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If cluster creation or update fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        compute = ml_client.compute.get(cluster_name)\n",
    "        \n",
    "        needs_update = (\n",
    "            compute.size != vm_size\n",
    "            or compute.min_instances != min_nodes\n",
    "            or compute.max_instances != max_nodes\n",
    "        )\n",
    "        \n",
    "        if needs_update:\n",
    "            compute.size = vm_size\n",
    "            compute.min_instances = min_nodes\n",
    "            compute.max_instances = max_nodes\n",
    "            compute.idle_time_before_scale_down = idle_time_before_scale_down\n",
    "            \n",
    "            if hasattr(compute, 'network_settings') and compute.network_settings is not None:\n",
    "                if compute.network_settings.subnet is None:\n",
    "                    compute.network_settings = None\n",
    "            \n",
    "            ml_client.compute.begin_create_or_update(compute).wait()\n",
    "        \n",
    "        return compute\n",
    "        \n",
    "    except ResourceNotFoundError:\n",
    "        compute = AmlCompute(\n",
    "            name=cluster_name,\n",
    "            size=vm_size,\n",
    "            min_instances=min_nodes,\n",
    "            max_instances=max_nodes,\n",
    "            idle_time_before_scale_down=idle_time_before_scale_down,\n",
    "        )\n",
    "        \n",
    "        ml_client.compute.begin_create_or_update(compute).wait()\n",
    "        return compute\n",
    "\n",
    "\n",
    "def create_or_get_compute_clusters(ml_client: MLClient, config: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Create or retrieve compute clusters based on configuration.\n",
    "    \n",
    "    GPU cluster is optional and only created if present in config.\n",
    "    CPU cluster is required.\n",
    "    \n",
    "    Args:\n",
    "        ml_client: MLClient instance\n",
    "        config: Infrastructure configuration dictionary\n",
    "        \n",
    "    Raises:\n",
    "        KeyError: If compute config or CPU cluster config is missing\n",
    "    \"\"\"\n",
    "    if \"compute\" not in config or not config[\"compute\"]:\n",
    "        raise KeyError(\"'compute' section not found in config. Please ensure config is loaded correctly.\")\n",
    "    \n",
    "    compute_config = config[\"compute\"]\n",
    "    \n",
    "    if \"gpu_cluster\" in compute_config and compute_config[\"gpu_cluster\"] is not None:\n",
    "        gpu_config = compute_config[\"gpu_cluster\"]\n",
    "        create_or_get_compute_cluster(\n",
    "            ml_client=ml_client,\n",
    "            cluster_name=gpu_config[\"name\"],\n",
    "            vm_size=gpu_config[\"vm_size\"],\n",
    "            min_nodes=gpu_config[\"min_nodes\"],\n",
    "            max_nodes=gpu_config[\"max_nodes\"],\n",
    "            idle_time_before_scale_down=gpu_config[\"idle_time_before_scale_down\"],\n",
    "        )\n",
    "    \n",
    "    if \"cpu_cluster\" not in compute_config:\n",
    "        raise KeyError(\"'cpu_cluster' configuration is required but not found in config.\")\n",
    "    \n",
    "    cpu_config = compute_config[\"cpu_cluster\"]\n",
    "    create_or_get_compute_cluster(\n",
    "        ml_client=ml_client,\n",
    "        cluster_name=cpu_config[\"name\"],\n",
    "        vm_size=cpu_config[\"vm_size\"],\n",
    "        min_nodes=cpu_config[\"min_nodes\"],\n",
    "        max_nodes=cpu_config[\"max_nodes\"],\n",
    "        idle_time_before_scale_down=cpu_config[\"idle_time_before_scale_down\"],\n",
    "    )\n",
    "\n",
    "\n",
    "create_or_get_compute_clusters(ml_client, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: (Optional) Validate Infrastructure\n",
    "\n",
    "Validate that all infrastructure components exist and are accessible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current LoggerProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current LoggerProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "def validate_workspace(config: Dict[str, Any]) -> Tuple[bool, list]:\n",
    "    \"\"\"\n",
    "    Validate Azure ML Workspace exists and is accessible.\n",
    "    \n",
    "    Args:\n",
    "        config: Infrastructure configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success, list of errors)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    subscription_id = config[\"azure\"][\"subscription_id\"]\n",
    "    resource_group = config[\"azure\"][\"resource_group\"]\n",
    "    workspace_name = config[\"workspace\"][\"name\"]\n",
    "    \n",
    "    try:\n",
    "        ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace_name)\n",
    "        ml_client.workspaces.get(workspace_name)\n",
    "        return True, errors\n",
    "    except ResourceNotFoundError:\n",
    "        errors.append(f\"Workspace '{workspace_name}' not found\")\n",
    "        return False, errors\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Error accessing workspace: {e}\")\n",
    "        return False, errors\n",
    "\n",
    "\n",
    "def validate_storage(config: Dict[str, Any]) -> Tuple[bool, list]:\n",
    "    \"\"\"\n",
    "    Validate Storage Account and Containers exist.\n",
    "    \n",
    "    Args:\n",
    "        config: Infrastructure configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success, list of errors)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    subscription_id = config[\"azure\"][\"subscription_id\"]\n",
    "    resource_group = config[\"azure\"][\"resource_group\"]\n",
    "    account_name = config[\"storage\"][\"account_name\"]\n",
    "    \n",
    "    try:\n",
    "        storage_management = StorageManagementClient(DefaultAzureCredential(), subscription_id)\n",
    "        storage_management.storage_accounts.get_properties(resource_group, account_name)\n",
    "        \n",
    "        keys = storage_management.storage_accounts.list_keys(resource_group, account_name)\n",
    "        connection_string = build_connection_string(account_name, keys.keys[0].value)\n",
    "        blob_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "        \n",
    "        for container_config in config[\"storage\"][\"containers\"]:\n",
    "            container_name = container_config[\"name\"]\n",
    "            if not blob_client.get_container_client(container_name).exists():\n",
    "                errors.append(f\"Container '{container_name}' not found\")\n",
    "        \n",
    "        return len(errors) == 0, errors\n",
    "    except ResourceNotFoundError:\n",
    "        errors.append(f\"Storage account '{account_name}' not found\")\n",
    "        return False, errors\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Error accessing storage: {e}\")\n",
    "        return False, errors\n",
    "\n",
    "\n",
    "def validate_compute(config: Dict[str, Any]) -> Tuple[bool, list]:\n",
    "    \"\"\"\n",
    "    Validate Compute Clusters exist and are accessible.\n",
    "    \n",
    "    Only validates clusters that are present in the configuration.\n",
    "    GPU cluster is optional, CPU cluster is required.\n",
    "    \n",
    "    Args:\n",
    "        config: Infrastructure configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success, list of errors)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    subscription_id = config[\"azure\"][\"subscription_id\"]\n",
    "    resource_group = config[\"azure\"][\"resource_group\"]\n",
    "    workspace_name = config[\"workspace\"][\"name\"]\n",
    "    \n",
    "    try:\n",
    "        ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace_name)\n",
    "        compute_config = config.get(\"compute\", {})\n",
    "        \n",
    "        if \"gpu_cluster\" in compute_config and compute_config[\"gpu_cluster\"] is not None:\n",
    "            gpu_cluster_name = compute_config[\"gpu_cluster\"][\"name\"]\n",
    "            try:\n",
    "                ml_client.compute.get(gpu_cluster_name)\n",
    "            except ResourceNotFoundError:\n",
    "                errors.append(f\"GPU cluster '{gpu_cluster_name}' not found\")\n",
    "            except Exception as e:\n",
    "                errors.append(f\"Error accessing GPU cluster '{gpu_cluster_name}': {e}\")\n",
    "        \n",
    "        if \"cpu_cluster\" in compute_config:\n",
    "            cpu_cluster_name = compute_config[\"cpu_cluster\"][\"name\"]\n",
    "            try:\n",
    "                ml_client.compute.get(cpu_cluster_name)\n",
    "            except ResourceNotFoundError:\n",
    "                errors.append(f\"CPU cluster '{cpu_cluster_name}' not found\")\n",
    "            except Exception as e:\n",
    "                errors.append(f\"Error accessing CPU cluster '{cpu_cluster_name}': {e}\")\n",
    "        else:\n",
    "            errors.append(\"CPU cluster configuration is required but not found\")\n",
    "        \n",
    "        return len(errors) == 0, errors\n",
    "    except Exception as e:\n",
    "        errors.append(f\"Error accessing workspace: {e}\")\n",
    "        return False, errors\n",
    "\n",
    "\n",
    "all_errors = []\n",
    "_, errors = validate_workspace(config)\n",
    "all_errors.extend(errors)\n",
    "_, errors = validate_storage(config)\n",
    "all_errors.extend(errors)\n",
    "_, errors = validate_compute(config)\n",
    "all_errors.extend(errors)\n",
    "\n",
    "if all_errors:\n",
    "    raise ValueError(f\"Validation failed: {', '.join(all_errors)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
