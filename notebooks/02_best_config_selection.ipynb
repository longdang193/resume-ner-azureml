{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Best Configuration Selection (Local, Google Colab & Kaggle)\n",
    "\n",
    "This notebook automates the selection of the best model configuration from MLflow\n",
    "based on metrics and benchmarking results, then performs final training and model conversion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "1. **Best Model Selection**: Query MLflow benchmark runs, join to training runs via grouping tags (`code.study_key_hash`, `code.trial_key_hash`), select best using normalized composite scoring\n",
    "2. **Artifact Acquisition**: Download the best model's checkpoint using fallback strategy (local disk ‚Üí drive restore ‚Üí MLflow download)\n",
    "3. **Final Training**: Optionally retrain with best config on full dataset (if not already final training)\n",
    "4. **Model Conversion**: Convert the final model to ONNX format using canonical path structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important\n",
    "\n",
    "- This notebook **executes on Local, Google Colab, or Kaggle** (not on Azure ML compute)\n",
    "- Requires MLflow tracking to be set up (Azure ML workspace or local SQLite)\n",
    "- All computation happens on the platform's GPU (if available) or CPU\n",
    "- **Storage & Persistence**:\n",
    "  - **Local**: Outputs saved to `outputs/` directory in repository root\n",
    "  - **Google Colab**: Checkpoints are automatically saved to Google Drive for persistence across sessions\n",
    "  - **Kaggle**: Outputs in `/kaggle/working/` are automatically persisted - no manual backup needed\n",
    "- The notebook must be **re-runnable end-to-end**\n",
    "- Uses the dataset path specified in the data config (from `config/data/*.yaml`), typically pointing to a local folder included in the repository\n",
    "- **Session Management**:\n",
    "  - **Local**: No session limits, outputs persist in repository\n",
    "  - **Colab**: Sessions timeout after 12-24 hours (depending on Colab plan). Checkpoints are saved to Drive automatically.\n",
    "  - **Kaggle**: Sessions have time limits based on your plan. All outputs are automatically saved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Detection\n",
    "\n",
    "The notebook automatically detects the execution environment (local, Google Colab, or Kaggle) and adapts its behavior accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Detected environment: LOCAL\n",
      "Platform: local\n",
      "Base directory: Current working directory\n",
      "Backup enabled: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "# Detect execution environment\n",
    "IN_COLAB = \"COLAB_GPU\" in os.environ or \"COLAB_TPU\" in os.environ\n",
    "IN_KAGGLE = \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "IS_LOCAL = not IN_COLAB and not IN_KAGGLE\n",
    "# Set platform-specific constants\n",
    "if IN_COLAB:\n",
    "    PLATFORM = \"colab\"\n",
    "    BASE_DIR = Path(\"/content\")\n",
    "    BACKUP_ENABLED = True\n",
    "elif IN_KAGGLE:\n",
    "    PLATFORM = \"kaggle\"\n",
    "    BASE_DIR = Path(\"/kaggle/working\")\n",
    "    BACKUP_ENABLED = False\n",
    "else:\n",
    "    PLATFORM = \"local\"\n",
    "    BASE_DIR = None\n",
    "    BACKUP_ENABLED = False\n",
    "print(f\"‚úì Detected environment: {PLATFORM.upper()}\")\n",
    "print(f\"Platform: {PLATFORM}\")\n",
    "print(\n",
    "    f\"Base directory: {BASE_DIR if BASE_DIR else 'Current working directory'}\")\n",
    "print(f\"Backup enabled: {BACKUP_ENABLED}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Packages\n",
    "\n",
    "Install required packages based on the execution environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For local environment, please:\n",
      "1. Create conda environment: conda env create -f config/environment/conda.yaml\n",
      "2. Activate: conda activate resume-ner-training\n",
      "3. Restart kernel after activation\n",
      "\n",
      "If you've already done this, you can continue to the next cell.\n",
      "\n",
      "Installing Azure ML SDK (required for imports)...\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "if IS_LOCAL:\n",
    "    print(\"For local environment, please:\")\n",
    "    print(\"1. Create conda environment: conda env create -f config/environment/conda.yaml\")\n",
    "    print(\"2. Activate: conda activate resume-ner-training\")\n",
    "    print(\"3. Restart kernel after activation\")\n",
    "    print(\"\\nIf you've already done this, you can continue to the next cell.\")\n",
    "    print(\"\\nInstalling Azure ML SDK (required for imports)...\")\n",
    "    # Install Azure ML packages even for local (in case conda env not activated)\n",
    "    %pip install \"azure-ai-ml>=1.0.0\" --quiet\n",
    "    %pip install \"azure-identity>=1.12.0\" --quiet\n",
    "    %pip install azureml-defaults --quiet\n",
    "    %pip install azureml-mlflow --quiet\n",
    "else:\n",
    "    # Core ML libraries\n",
    "    %pip install \"transformers>=4.35.0,<5.0.0\" --quiet\n",
    "    %pip install \"safetensors>=0.4.0\" --quiet\n",
    "    %pip install \"datasets>=2.12.0\" --quiet\n",
    "\n",
    "    # ML utilities\n",
    "    %pip install \"numpy>=1.24.0,<2.0.0\" --quiet\n",
    "    %pip install \"pandas>=2.0.0\" --quiet\n",
    "    %pip install \"scikit-learn>=1.3.0\" --quiet\n",
    "\n",
    "    # Utilities\n",
    "    %pip install \"pyyaml>=6.0\" --quiet\n",
    "    %pip install \"tqdm>=4.65.0\" --quiet\n",
    "    %pip install \"seqeval>=1.2.2\" --quiet\n",
    "    %pip install \"sentencepiece>=0.1.99\" --quiet\n",
    "\n",
    "    # Experiment tracking\n",
    "    %pip install mlflow --quiet\n",
    "    %pip install optuna --quiet\n",
    "\n",
    "    # Azure ML SDK (required for orchestration imports)\n",
    "    %pip install \"azure-ai-ml>=1.0.0\" --quiet\n",
    "    %pip install \"azure-identity>=1.12.0\" --quiet\n",
    "    %pip install azureml-defaults --quiet\n",
    "    %pip install azureml-mlflow --quiet\n",
    "\n",
    "    # ONNX support\n",
    "    %pip install onnxruntime --quiet\n",
    "    %pip install \"onnx>=1.16.0\" --quiet\n",
    "    %pip install \"onnxscript>=0.1.0\" --quiet\n",
    "\n",
    "    print(\"‚úì All dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Repository Setup\n",
    "\n",
    "**Note**: Repository setup is only needed for Colab/Kaggle environments. Local environments should already have the repository cloned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Local environment detected - detecting repository root...\n",
      "‚úì Repository: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml (config=config, src=src)\n",
      "‚úì Repository structure verified\n"
     ]
    }
   ],
   "source": [
    "# Repository setup - only needed for Colab/Kaggle\n",
    "if not IS_LOCAL:\n",
    "    if IN_KAGGLE:\n",
    "        !git clone -b gg_final_training_2 https://github.com/longdang193/resume-ner-azureml.git /kaggle/working/resume-ner-azureml\n",
    "    elif IN_COLAB:\n",
    "        !git clone -b gg_final_training_2 https://github.com/longdang193/resume-ner-azureml.git /content/resume-ner-azureml\n",
    "else:\n",
    "    print(\"‚úì Local environment detected - detecting repository root...\")\n",
    "\n",
    "# Set up paths\n",
    "if not IS_LOCAL:\n",
    "    ROOT_DIR = BASE_DIR / \"resume-ner-azureml\"\n",
    "else:\n",
    "    # For local, detect repo root by searching for config/ and src/ directories\n",
    "    # Start from current working directory and search up\n",
    "    current_dir = Path.cwd()\n",
    "    ROOT_DIR = None\n",
    "    \n",
    "    # Check current directory first\n",
    "    if (current_dir / \"config\").exists() and (current_dir / \"src\").exists():\n",
    "        ROOT_DIR = current_dir\n",
    "    else:\n",
    "        # Search up the directory tree\n",
    "        for parent in current_dir.parents:\n",
    "            if (parent / \"config\").exists() and (parent / \"src\").exists():\n",
    "                ROOT_DIR = parent\n",
    "                break\n",
    "    \n",
    "    if ROOT_DIR is None:\n",
    "        raise ValueError(\n",
    "            f\"Could not find repository root. Searched from: {current_dir}\\n\"\n",
    "            \"Please ensure you're running from within the repository or a subdirectory.\"\n",
    "        )\n",
    "\n",
    "CONFIG_DIR = ROOT_DIR / \"config\"\n",
    "SRC_DIR = ROOT_DIR / \"src\"\n",
    "\n",
    "# Add src to path\n",
    "import sys\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "print(f\"‚úì Repository: {ROOT_DIR} (config={CONFIG_DIR.name}, src={SRC_DIR.name})\")\n",
    "\n",
    "# Verify repository structure\n",
    "required_dirs = [CONFIG_DIR, SRC_DIR]\n",
    "for dir_path in required_dirs:\n",
    "    if not dir_path.exists():\n",
    "        raise ValueError(f\"Required directory not found: {dir_path}\")\n",
    "print(\"‚úì Repository structure verified\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Configuration\n",
    "\n",
    "Load experiment configuration and define experiment naming convention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded configs: experiment=resume_ner_baseline, tags, selection, conversion, acquisition\n",
      "‚úì Experiment names: benchmark=resume_ner_baseline-benchmark, training=resume_ner_baseline-training, conversion=resume_ner_baseline-conversion\n"
     ]
    }
   ],
   "source": [
    "from orchestration.config_loader import load_experiment_config\n",
    "from orchestration import EXPERIMENT_NAME\n",
    "from shared.yaml_utils import load_yaml\n",
    "from orchestration.jobs.tracking.naming.tags_registry import load_tags_registry\n",
    "\n",
    "# Load experiment config\n",
    "experiment_config = load_experiment_config(CONFIG_DIR, EXPERIMENT_NAME)\n",
    "\n",
    "# Load best model selection configs\n",
    "tags_config = load_tags_registry(CONFIG_DIR)\n",
    "selection_config = load_yaml(CONFIG_DIR / \"best_model_selection.yaml\")\n",
    "conversion_config = load_yaml(CONFIG_DIR / \"conversion.yaml\")\n",
    "acquisition_config = load_yaml(CONFIG_DIR / \"artifact_acquisition.yaml\")\n",
    "\n",
    "print(f\"‚úì Loaded configs: experiment={experiment_config.name}, tags, selection, conversion, acquisition\")\n",
    "\n",
    "# Define experiment names (discovery happens after MLflow setup in Cell 4)\n",
    "experiment_name = experiment_config.name\n",
    "benchmark_experiment_name = f\"{experiment_name}-benchmark\"\n",
    "training_experiment_name = f\"{experiment_name}-training\"  # For final training runs\n",
    "conversion_experiment_name = f\"{experiment_name}-conversion\"\n",
    "\n",
    "print(f\"‚úì Experiment names: benchmark={benchmark_experiment_name}, training={training_experiment_name}, conversion={conversion_experiment_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Setup MLflow\n",
    "\n",
    "Setup MLflow tracking with fallback to local if Azure ML is unavailable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 21:35:38,056 - shared.mlflow_setup - INFO - Azure ML enabled in config, attempting to connect...\n",
      "2026-01-07 21:35:38,057 - shared.mlflow_setup - WARNING - [DEBUG] Initial env check - subscription_id: False, resource_group: False, client_id: False, client_secret: False, tenant_id: False\n",
      "2026-01-07 21:35:38,058 - shared.mlflow_setup - INFO - Attempting to load credentials from config.env at: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config.env\n",
      "2026-01-07 21:35:38,058 - shared.mlflow_setup - INFO - Loading credentials from c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config.env\n",
      "2026-01-07 21:35:38,060 - shared.mlflow_setup - INFO - Loaded subscription/resource group from config.env\n",
      "2026-01-07 21:35:38,060 - shared.mlflow_setup - INFO - Loaded service principal credentials from config.env\n",
      "2026-01-07 21:35:38,061 - shared.mlflow_setup - WARNING - [DEBUG] Platform detected: local\n",
      "2026-01-07 21:35:38,061 - shared.mlflow_setup - WARNING - [DEBUG] Service Principal check - client_id present: True, client_secret present: True, tenant_id present: True, has_service_principal: True\n",
      "2026-01-07 21:35:38,062 - shared.mlflow_setup - INFO - Using Service Principal authentication (from config.env)\n",
      "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "2026-01-07 21:35:41,163 - shared.mlflow_setup - INFO - Successfully connected to Azure ML workspace: resume-ner-ws\n",
      "2026-01-07 21:35:42,699 - shared.mlflow_setup - INFO - Using Azure ML workspace tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì MLflow tracking URI: azureml://germanywestcentral.api.azureml.ms/mlflow/v2.0/subscriptions/50c06ef8-627b-46d5-b779-d07c9b398f75/resourceGroups/resume_ner_2026-01-02-16-47-05/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws\n",
      "‚úì MLflow experiment: resume_ner_baseline-training\n",
      "‚úì Experiments: 2 HPO (distilbert, distilroberta), benchmark=found, training=resume_ner_baseline-training, conversion=resume_ner_baseline-conversion\n"
     ]
    }
   ],
   "source": [
    "from shared.mlflow_setup import setup_mlflow_from_config\n",
    "import mlflow\n",
    "\n",
    "# Setup MLflow tracking (use training experiment for setup - actual queries use discovered experiments)\n",
    "tracking_uri = setup_mlflow_from_config(\n",
    "    experiment_name=training_experiment_name,\n",
    "    config_dir=CONFIG_DIR,\n",
    "    fallback_to_local=True,\n",
    ")\n",
    "\n",
    "print(f\"‚úì MLflow tracking URI: {tracking_uri}\")\n",
    "print(f\"‚úì MLflow experiment: {training_experiment_name}\")\n",
    "\n",
    "# Discover HPO and benchmark experiments from MLflow (after setup)\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "all_experiments = client.search_experiments()\n",
    "\n",
    "# Find HPO experiments (format: {experiment_name}-hpo-{backbone})\n",
    "hpo_experiments = {}\n",
    "for exp in all_experiments:\n",
    "    if exp.name.startswith(f\"{experiment_name}-hpo-\"):\n",
    "        backbone = exp.name.replace(f\"{experiment_name}-hpo-\", \"\")\n",
    "        hpo_experiments[backbone] = {\n",
    "            \"name\": exp.name,\n",
    "            \"id\": exp.experiment_id\n",
    "        }\n",
    "\n",
    "# Find benchmark experiment\n",
    "benchmark_experiment = None\n",
    "for exp in all_experiments:\n",
    "    if exp.name == benchmark_experiment_name:\n",
    "        benchmark_experiment = {\n",
    "            \"name\": exp.name,\n",
    "            \"id\": exp.experiment_id\n",
    "        }\n",
    "        break\n",
    "\n",
    "hpo_backbones = \", \".join(hpo_experiments.keys())\n",
    "print(f\"‚úì Experiments: {len(hpo_experiments)} HPO ({hpo_backbones}), benchmark={'found' if benchmark_experiment else 'not found'}, training={training_experiment_name}, conversion={conversion_experiment_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Drive Backup Setup (Colab Only)\n",
    "\n",
    "Setup Google Drive backup/restore for Colab environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Local environment detected - outputs will be saved to repository (no Drive backup needed)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Fix numpy/pandas compatibility before importing orchestration modules\n",
    "try:\n",
    "    from orchestration.drive_backup import create_colab_store\n",
    "except (ValueError, ImportError) as e:\n",
    "    if \"numpy.dtype size changed\" in str(e) or \"numpy\" in str(e).lower():\n",
    "        print(\"‚ö† Numpy/pandas compatibility issue detected. Fixing...\")\n",
    "        import subprocess\n",
    "        import sys\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"--force-reinstall\", \"--no-cache-dir\", \"numpy>=1.24.0,<2.0.0\", \"pandas>=2.0.0\", \"--quiet\"])\n",
    "        print(\"‚úì Numpy/pandas reinstalled. Please restart the kernel and re-run this cell.\")\n",
    "        raise RuntimeError(\"Please restart kernel after numpy/pandas fix\")\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Mount Google Drive and create backup store (Colab only - Kaggle doesn't need this)\n",
    "DRIVE_BACKUP_DIR = None\n",
    "drive_store = None\n",
    "restore_from_drive = None\n",
    "\n",
    "if IN_COLAB:\n",
    "    drive_store = create_colab_store(ROOT_DIR, CONFIG_DIR)\n",
    "    if drive_store:\n",
    "        BACKUP_ENABLED = True\n",
    "        DRIVE_BACKUP_DIR = drive_store.backup_root\n",
    "        # Create restore function wrapper\n",
    "        def restore_from_drive(local_path: Path, is_directory: bool = False) -> bool:\n",
    "            \"\"\"Restore file/directory from Drive backup.\"\"\"\n",
    "            try:\n",
    "                expect = \"dir\" if is_directory else \"file\"\n",
    "                result = drive_store.restore(local_path, expect=expect)\n",
    "                return result.ok\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† Drive restore failed: {e}\")\n",
    "                return False\n",
    "        print(f\"‚úì Google Drive mounted\")\n",
    "        print(f\"‚úì Backup base directory: {DRIVE_BACKUP_DIR}\")\n",
    "        print(f\"\\nNote: All outputs/ will be mirrored to: {DRIVE_BACKUP_DIR / 'outputs'}\")\n",
    "    else:\n",
    "        BACKUP_ENABLED = False\n",
    "        print(\"‚ö† Warning: Could not mount Google Drive. Backup to Google Drive will be disabled.\")\n",
    "elif IN_KAGGLE:\n",
    "    print(\"‚úì Kaggle environment detected - outputs are automatically persisted (no Drive mount needed)\")\n",
    "    BACKUP_ENABLED = False\n",
    "else:\n",
    "    # Local environment\n",
    "    print(\"‚úì Local environment detected - outputs will be saved to repository (no Drive backup needed)\")\n",
    "    BACKUP_ENABLED = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Best Model Selection\n",
    "\n",
    "Query MLflow benchmark runs, join to training runs via grouping tags, and select the best model using normalized composite scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 21:35:42,873 - orchestration.jobs.selection.mlflow_selection - INFO - Finding best model from MLflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 21:35:42,874 - orchestration.jobs.selection.mlflow_selection - INFO -   Benchmark experiment: resume_ner_baseline-benchmark\n",
      "2026-01-07 21:35:42,875 - orchestration.jobs.selection.mlflow_selection - INFO -   HPO experiments: 2\n",
      "2026-01-07 21:35:42,876 - orchestration.jobs.selection.mlflow_selection - INFO -   Objective metric: macro-f1\n",
      "2026-01-07 21:35:42,877 - orchestration.jobs.selection.mlflow_selection - INFO -   Composite weights: F1=0.70, Latency=0.30\n",
      "2026-01-07 21:35:42,878 - orchestration.jobs.selection.mlflow_selection - INFO - Querying benchmark runs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Best Model Selection Mode: force_new\n",
      "  Mode is 'force_new' - skipping cache, querying MLflow...\n",
      "üîç Finding best model from MLflow...\n",
      "   Benchmark experiment: resume_ner_baseline-benchmark\n",
      "   HPO experiments: 2\n",
      "   Objective metric: macro-f1\n",
      "   Composite weights: F1=0.70, Latency=0.30\n",
      "\n",
      "üìä Querying benchmark runs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 21:35:43,159 - orchestration.jobs.selection.mlflow_selection - INFO - Found 18 finished benchmark runs\n",
      "2026-01-07 21:35:43,160 - orchestration.jobs.selection.mlflow_selection - INFO - Found 18 benchmark runs with required metrics and grouping tags\n",
      "2026-01-07 21:35:43,161 - orchestration.jobs.selection.mlflow_selection - INFO - Preloading trial and refit runs from HPO experiments...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Found 18 benchmark runs with required metrics and grouping tags\n",
      "\n",
      "üîó Preloading trial runs (metrics) and refit runs (artifacts) from HPO experiments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 21:35:43,668 - orchestration.jobs.selection.mlflow_selection - INFO - Built trial lookup with 25 unique (study_hash, trial_hash) pairs\n",
      "2026-01-07 21:35:43,669 - orchestration.jobs.selection.mlflow_selection - INFO - Built refit lookup with 17 unique (study_hash, trial_hash) pairs\n",
      "2026-01-07 21:35:43,670 - orchestration.jobs.selection.mlflow_selection - INFO - Joining benchmark runs with trial runs and refit runs...\n",
      "2026-01-07 21:35:43,671 - orchestration.jobs.selection.mlflow_selection - INFO - Found 10 candidate(s) with both benchmark and training metrics\n",
      "2026-01-07 21:35:43,672 - orchestration.jobs.selection.mlflow_selection - INFO - Computing composite scores...\n",
      "2026-01-07 21:35:43,672 - orchestration.jobs.selection.mlflow_selection - INFO - Best model selected:\n",
      "2026-01-07 21:35:43,674 - orchestration.jobs.selection.mlflow_selection - INFO -   Artifact Run ID: 03e958c7-f1b7-4318-879e-b12bdc88ea86\n",
      "2026-01-07 21:35:43,674 - orchestration.jobs.selection.mlflow_selection - INFO -   Trial Run ID: 61776a49-5d21-4753-99f2-bc133655c1d1\n",
      "2026-01-07 21:35:43,675 - orchestration.jobs.selection.mlflow_selection - INFO -   Backbone: distilbert\n",
      "2026-01-07 21:35:43,675 - orchestration.jobs.selection.mlflow_selection - INFO -   F1 Score: 0.4899\n",
      "2026-01-07 21:35:43,676 - orchestration.jobs.selection.mlflow_selection - INFO -   Latency: 5.05 ms\n",
      "2026-01-07 21:35:43,676 - orchestration.jobs.selection.mlflow_selection - INFO -   Composite Score: 0.7830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   resume_ner_baseline-hpo-distilbert: 96 finished runs, 36 trial runs, 15 refit runs\n",
      "   resume_ner_baseline-hpo-distilroberta: 16 finished runs, 6 trial runs, 2 refit runs\n",
      "   Built trial lookup with 25 unique (study_hash, trial_hash) pairs\n",
      "   Built refit lookup with 17 unique (study_hash, trial_hash) pairs\n",
      "\n",
      "üîó Joining benchmark runs with trial runs (metrics) and refit runs (artifacts)...\n",
      "   Found 10 candidate(s) with both benchmark and training metrics\n",
      "\n",
      "‚úÖ Best model selected:\n",
      "   Run ID: 03e958c7-f1b7-4318-879e-b12bdc88ea86\n",
      "   Experiment: resume_ner_baseline-hpo-distilbert\n",
      "   Backbone: distilbert\n",
      "   F1 Score: 0.4899\n",
      "   Latency: 5.05 ms\n",
      "   Composite Score: 0.7830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 21:35:43,963 - orchestration.jobs.selection.cache - INFO - Saved best model selection cache: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\cache\\best_model_selection\\latest_best_model_selection_cache.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved best model selection to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [15:38<00:00, 938.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Best model checkpoint available at: C:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\best_model_selection\\local\\distilbert\\sel_350a79aa_9d4153fb\\best_trial_checkpoint\\best_trial_checkpoint\n"
     ]
    }
   ],
   "source": [
    "from orchestration.jobs.selection.mlflow_selection import find_best_model_from_mlflow\n",
    "from orchestration.jobs.selection.artifact_acquisition import acquire_best_model_checkpoint\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, Dict, Any\n",
    "\n",
    "# Validate experiments\n",
    "if benchmark_experiment is None:\n",
    "    raise ValueError(f\"Benchmark experiment '{benchmark_experiment_name}' not found. Run benchmark jobs first.\")\n",
    "if not hpo_experiments:\n",
    "    raise ValueError(f\"No HPO experiments found. Run HPO jobs first.\")\n",
    "\n",
    "# Check if we should reuse cached selection\n",
    "run_mode = selection_config.get(\"run\", {}).get(\"mode\", \"reuse_if_exists\")\n",
    "best_model = None\n",
    "cache_data = None\n",
    "\n",
    "print(f\"\\nüìã Best Model Selection Mode: {run_mode}\")\n",
    "\n",
    "if run_mode == \"reuse_if_exists\":\n",
    "    from orchestration.jobs.selection.cache import load_cached_best_model\n",
    "    \n",
    "    tracking_uri = mlflow.get_tracking_uri()\n",
    "    cache_data = load_cached_best_model(\n",
    "        root_dir=ROOT_DIR,\n",
    "        config_dir=CONFIG_DIR,\n",
    "        experiment_name=experiment_name,\n",
    "        selection_config=selection_config,\n",
    "        tags_config=tags_config,\n",
    "        benchmark_experiment_id=benchmark_experiment[\"id\"],\n",
    "        tracking_uri=tracking_uri,\n",
    "    )\n",
    "    \n",
    "    if cache_data:\n",
    "        best_model = cache_data[\"best_model\"]\n",
    "        # Success message already printed by load_cached_best_model\n",
    "    else:\n",
    "        print(f\"\\n‚Ñπ Cache not available or invalid - will query MLflow for fresh selection\")\n",
    "elif run_mode == \"force_new\":\n",
    "    print(f\"  Mode is 'force_new' - skipping cache, querying MLflow...\")\n",
    "else:\n",
    "    print(f\"  ‚ö† Unknown run mode '{run_mode}', defaulting to querying MLflow...\")\n",
    "\n",
    "if best_model is None:\n",
    "    # Find best model\n",
    "    best_model = find_best_model_from_mlflow(\n",
    "        benchmark_experiment=benchmark_experiment,\n",
    "        hpo_experiments=hpo_experiments,\n",
    "        tags_config=tags_config,\n",
    "        selection_config=selection_config,\n",
    "        use_python_filtering=True,\n",
    "    )\n",
    "    \n",
    "    if best_model is None:\n",
    "        raise ValueError(\"Could not find best model from MLflow.\")\n",
    "    \n",
    "    # Save to cache\n",
    "    from orchestration.jobs.selection.cache import save_best_model_cache\n",
    "    \n",
    "    tracking_uri = mlflow.get_tracking_uri()\n",
    "    # Note: inputs_summary could be enhanced if find_best_model_from_mlflow returns it\n",
    "    inputs_summary = {}\n",
    "    \n",
    "    timestamped_file, latest_file, index_file = save_best_model_cache(\n",
    "        root_dir=ROOT_DIR,\n",
    "        config_dir=CONFIG_DIR,\n",
    "        best_model=best_model,\n",
    "        experiment_name=experiment_name,\n",
    "        selection_config=selection_config,\n",
    "        tags_config=tags_config,\n",
    "        benchmark_experiment=benchmark_experiment,\n",
    "        hpo_experiments=hpo_experiments,\n",
    "        tracking_uri=tracking_uri,\n",
    "        inputs_summary=inputs_summary,\n",
    "    )\n",
    "    print(f\"‚úì Saved best model selection to cache\")\n",
    "\n",
    "# Extract lineage information from best_model for final training tags\n",
    "from orchestration.jobs.final_training import extract_lineage_from_best_model\n",
    "lineage = extract_lineage_from_best_model(best_model)\n",
    "\n",
    "# Lineage extracted for final training tags\n",
    "\n",
    "# Acquire checkpoint\n",
    "best_checkpoint_dir = acquire_best_model_checkpoint(\n",
    "    best_run_info=best_model,\n",
    "    root_dir=ROOT_DIR,\n",
    "    config_dir=CONFIG_DIR,\n",
    "    acquisition_config=acquisition_config,\n",
    "    selection_config=selection_config,\n",
    "    platform=PLATFORM,\n",
    "    restore_from_drive=restore_from_drive if \"restore_from_drive\" in locals() else None,\n",
    "    drive_store=drive_store if \"drive_store\" in locals() else None,\n",
    "    in_colab=IN_COLAB,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Best model checkpoint available at: {best_checkpoint_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if selected run is already final training (skip retraining if so)\n",
    "stage_tag = tags_config.key(\"process\", \"stage\")\n",
    "trained_on_full_data_tag = tags_config.key(\"training\", \"trained_on_full_data\")\n",
    "\n",
    "is_final_training = best_model[\"tags\"].get(stage_tag) == \"final_training\"\n",
    "used_full_data = (\n",
    "    best_model[\"tags\"].get(trained_on_full_data_tag) == \"true\" or\n",
    "    best_model[\"params\"].get(\"use_combined_data\", \"false\").lower() == \"true\"\n",
    ")\n",
    "\n",
    "SKIP_FINAL_TRAINING = is_final_training and used_full_data\n",
    "\n",
    "if SKIP_FINAL_TRAINING:\n",
    "    final_checkpoint_dir = best_checkpoint_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Final Training\n",
    "\n",
    "Run final training with best configuration if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Starting final training with best configuration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 21:51:30,871 - orchestration.jobs.tracking.config.loader - INFO - [Auto-Increment Config] Loading from config_dir=c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config, raw_auto_inc_config={'enabled': True, 'processes': {'hpo': True, 'benchmarking': True}, 'format': '{base}.{version}'}\n",
      "2026-01-07 21:51:30,872 - orchestration.jobs.tracking.config.loader - INFO - [Auto-Increment Config] Validated config: {'enabled': True, 'processes': {'hpo': True, 'benchmarking': True}, 'format': '{base}.{version}'}, process_type=final_training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Final training config loaded from final_training.yaml\n",
      "‚úì Output directory: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\final_training\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 21:51:31,444 - orchestration.jobs.tracking.index.run_index - WARNING - Could not acquire lock for c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\cache\\mlflow_index.json, proceeding with non-atomic write\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created MLflow run: local_distilbert_final_training_spec-1e6acb58_exec-13bac0dc_v2 (350bd12a-f42...)\n",
      "üîÑ Running final training...\n",
      "üèÉ View run local_distilbert_final_training_spec-1e6acb58_exec-13bac0dc_v2 at: https://germanywestcentral.api.azureml.ms/mlflow/v2.0/subscriptions/50c06ef8-627b-46d5-b779-d07c9b398f75/resourceGroups/resume_ner_2026-01-02-16-47-05/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/#/experiments/801daa4d-3a56-4952-a374-cf2c5a9c2846/runs/350bd12a-f427-49b1-ae38-0458a29de794\n",
      "üß™ View experiment at: https://germanywestcentral.api.azureml.ms/mlflow/v2.0/subscriptions/50c06ef8-627b-46d5-b779-d07c9b398f75/resourceGroups/resume_ner_2026-01-02-16-47-05/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/#/experiments/801daa4d-3a56-4952-a374-cf2c5a9c2846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\azureml\\core\\__init__.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "  [Training] Set MLflow tracking URI: azureml://germanywestcentral.api.azureml.ms/mlflow...\n",
      "  [Training] Set MLflow experiment: resume_ner_baseline-training\n",
      "  [Training] Using existing run: 350bd12a-f42... (final training)\n",
      "  [Training] ‚úì Started run for artifact logging\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SKILL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  [Training] Active MLflow run detected: 350bd12a-f42...\n",
      "  [Training] Logging checkpoint artifacts from: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\final_training\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v2\\checkpoint\n",
      "  [Training] ‚úì Logged checkpoint artifacts to MLflow\n",
      "  [Training] Ended independent run\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved metadata to: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\final_training\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v2\\metadata.json\n",
      "‚úì Final training completed. Checkpoint: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\final_training\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v2\\checkpoint\n",
      "‚úì MLflow run: 350bd12a-f42...\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_FINAL_TRAINING:\n",
    "    print(\"üîÑ Starting final training with best configuration...\")\n",
    "    from orchestration.jobs.final_training import execute_final_training\n",
    "    # Execute final training (uses final_training.yaml via load_final_training_config)\n",
    "    # Will automatically reuse existing complete runs if run.mode: reuse_if_exists in final_training.yaml\n",
    "    final_checkpoint_dir = execute_final_training(\n",
    "        root_dir=ROOT_DIR,\n",
    "        config_dir=CONFIG_DIR,\n",
    "        best_model=best_model,\n",
    "        experiment_config=experiment_config,\n",
    "        lineage=lineage,\n",
    "        training_experiment_name=training_experiment_name,\n",
    "        platform=PLATFORM,\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úì Skipping final training - using selected checkpoint\")\n",
    "\n",
    "# Backup final checkpoint to Google Drive if in Colab\n",
    "if IN_COLAB and drive_store and final_checkpoint_dir:\n",
    "    checkpoint_path = Path(final_checkpoint_dir).resolve()\n",
    "    # Check if checkpoint is already in Drive\n",
    "    if str(checkpoint_path).startswith(\"/content/drive\"):\n",
    "        print(f\"\\n‚úì Final training checkpoint is already in Google Drive\")\n",
    "        print(f\"  Drive path: {checkpoint_path}\")\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"\\nüì¶ Backing up final training checkpoint to Google Drive...\")\n",
    "            result = drive_store.backup(checkpoint_path, expect=\"dir\")\n",
    "            if result.ok:\n",
    "                print(f\"‚úì Successfully backed up final checkpoint to Google Drive\")\n",
    "                print(f\"  Drive path: {result.dst}\")\n",
    "            else:\n",
    "                print(f\"‚ö† Drive backup failed: {result.reason}\")\n",
    "                if result.error:\n",
    "                    print(f\"  Error: {result.error}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Drive backup error: {e}\")\n",
    "            print(f\"  Checkpoint is still available locally at: {final_checkpoint_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Model Conversion & Optimization\n",
    "\n",
    "Convert the final trained model to ONNX format with optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 21:57:38,608 - orchestration.jobs.tracking.config.loader - INFO - [Auto-Increment Config] Loading from config_dir=c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config, raw_auto_inc_config={'enabled': True, 'processes': {'hpo': True, 'benchmarking': True}, 'format': '{base}.{version}'}\n",
      "2026-01-07 21:57:38,609 - orchestration.jobs.tracking.config.loader - INFO - [Auto-Increment Config] Validated config: {'enabled': True, 'processes': {'hpo': True, 'benchmarking': True}, 'format': '{base}.{version}'}, process_type=conversion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Parent training: spec_fp=1e6acb58..., exec_fp=13bac0dc..., run_id=350bd12a-f42...\n",
      "\n",
      "üîÑ Starting model conversion...\n",
      "‚úì Conversion config loaded from conversion.yaml\n",
      "‚úì Output directory: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\conversion\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v1\\conv-788d8835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 21:57:38,902 - orchestration.jobs.tracking.index.run_index - WARNING - Could not acquire lock for c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\cache\\mlflow_index.json, proceeding with non-atomic write\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created MLflow run: local_distilbert_conversion_spec-1e6acb58_exec-13bac0dc_v2_conv-788d8835 (7d41834b-760...)\n",
      "üîÑ Running model conversion...\n",
      "[convert_to_onnx] Starting model conversion job with arguments: checkpoint_path='c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\final_training\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v2\\checkpoint', config_dir='c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config', backbone='distilbert', output_dir='c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\conversion\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v1\\conv-788d8835', quantize_int8=False, run_smoke_test=True, opset_version=18\n",
      "[convert_to_onnx] Using config directory: 'c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config'\n",
      "[convert_to_onnx] Resolving checkpoint directory from 'c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\final_training\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v2\\checkpoint'\n",
      "[convert_to_onnx] Resolved checkpoint directory to 'c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\final_training\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v2\\checkpoint', output directory to 'c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\conversion\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v1\\conv-788d8835\\onnx_model'\n",
      "[convert_to_onnx] Using existing MLflow run: 7d41834b-760...\n",
      "[convert_to_onnx] Starting ONNX export. quantize_int8=False\n",
      "[convert_to_onnx] Output directory created at 'c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\conversion\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v1\\conv-788d8835\\onnx_model'\n",
      "[convert_to_onnx] Loading tokenizer and model from checkpoint directory 'c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\final_training\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v2\\checkpoint'\n",
      "[convert_to_onnx] Model and tokenizer successfully loaded; building example inputs for tracing\n",
      "[convert_to_onnx] Exporting FP32 ONNX model to 'c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\conversion\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v1\\conv-788d8835\\onnx_model\\model.onnx' (opset=18, dynamo=False)\n",
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n",
      "[convert_to_onnx] FP32 ONNX export completed\n",
      "[convert_to_onnx] Int8 quantization not requested; returning FP32 model\n",
      "[convert_to_onnx] Conversion completed. ONNX model written to 'c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\conversion\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v1\\conv-788d8835\\onnx_model\\model.onnx'\n",
      "[convert_to_onnx] Running ONNX smoke test for 'c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\conversion\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v1\\conv-788d8835\\onnx_model\\model.onnx'\n",
      "[convert_to_onnx] ONNX smoke test completed successfully\n",
      "[convert_to_onnx] Smoke test passed\n",
      "[convert_to_onnx] Logged ONNX model to MLflow: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\conversion\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v1\\conv-788d8835\\onnx_model\\model.onnx\n",
      "üèÉ View run local_distilbert_conversion_spec-1e6acb58_exec-13bac0dc_v2_conv-788d8835 at: https://germanywestcentral.api.azureml.ms/mlflow/v2.0/subscriptions/50c06ef8-627b-46d5-b779-d07c9b398f75/resourceGroups/resume_ner_2026-01-02-16-47-05/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/#/experiments/d97bba48-87dd-4664-a64f-ccb63be0279f/runs/7d41834b-7601-4c00-a4fe-fbf8b5dd06d7\n",
      "üß™ View experiment at: https://germanywestcentral.api.azureml.ms/mlflow/v2.0/subscriptions/50c06ef8-627b-46d5-b779-d07c9b398f75/resourceGroups/resume_ner_2026-01-02-16-47-05/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/#/experiments/d97bba48-87dd-4664-a64f-ccb63be0279f\n",
      "[convert_to_onnx] Ended MLflow run\n",
      "‚úì Model conversion completed. ONNX model: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\conversion\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v1\\conv-788d8835\\onnx_model\\model.onnx\n",
      "‚úì MLflow run: 7d41834b-760...\n",
      "\n",
      "‚úì Conversion completed successfully!\n",
      "  ONNX model: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\conversion\\local\\distilbert\\spec-1e6acb58_exec-13bac0dc\\v1\\conv-788d8835\\onnx_model\\model.onnx\n",
      "  Model size: 253.29 MB\n"
     ]
    }
   ],
   "source": [
    "# Extract parent training information for conversion\n",
    "from shared.json_cache import load_json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load metadata from final training output directory\n",
    "final_training_metadata_path = final_checkpoint_dir.parent / \"metadata.json\"\n",
    "\n",
    "if not final_training_metadata_path.exists():\n",
    "    raise ValueError(\n",
    "        f\"Metadata file not found: {final_training_metadata_path}\\n\"\n",
    "        \"Please ensure final training completed successfully.\"\n",
    "    )\n",
    "\n",
    "metadata = load_json(final_training_metadata_path)\n",
    "parent_spec_fp = metadata.get(\"spec_fp\")\n",
    "parent_exec_fp = metadata.get(\"exec_fp\")\n",
    "parent_training_run_id = metadata.get(\"mlflow\", {}).get(\"run_id\")\n",
    "\n",
    "if not parent_spec_fp or not parent_exec_fp:\n",
    "    raise ValueError(\n",
    "        f\"Missing required fingerprints in metadata: spec_fp={parent_spec_fp}, exec_fp={parent_exec_fp}\\n\"\n",
    "        \"Please ensure final training completed successfully.\"\n",
    "    )\n",
    "\n",
    "if parent_training_run_id:\n",
    "    print(f\"‚úì Parent training: spec_fp={parent_spec_fp[:8]}..., exec_fp={parent_exec_fp[:8]}..., run_id={parent_training_run_id[:12]}...\")\n",
    "else:\n",
    "    print(f\"‚úì Parent training: spec_fp={parent_spec_fp[:8]}..., exec_fp={parent_exec_fp[:8]}... (run_id not found)\")\n",
    "\n",
    "# Get parent training output directory (checkpoint parent)\n",
    "parent_training_output_dir = final_checkpoint_dir.parent\n",
    "\n",
    "print(f\"\\nüîÑ Starting model conversion...\")\n",
    "from orchestration.jobs.conversion import execute_conversion\n",
    "\n",
    "# Execute conversion (uses conversion.yaml via load_conversion_config)\n",
    "conversion_output_dir = execute_conversion(\n",
    "    root_dir=ROOT_DIR,\n",
    "    config_dir=CONFIG_DIR,\n",
    "    parent_training_output_dir=parent_training_output_dir,\n",
    "    parent_spec_fp=parent_spec_fp,\n",
    "    parent_exec_fp=parent_exec_fp,\n",
    "    experiment_config=experiment_config,\n",
    "    conversion_experiment_name=conversion_experiment_name,\n",
    "    platform=PLATFORM,\n",
    "    parent_training_run_id=parent_training_run_id,  # May be None, that's OK\n",
    ")\n",
    "\n",
    "# Find ONNX model file (search recursively, as model may be in onnx_model/ subdirectory)\n",
    "onnx_files = list(conversion_output_dir.rglob(\"*.onnx\"))\n",
    "if onnx_files:\n",
    "    onnx_model_path = onnx_files[0]\n",
    "    print(f\"\\n‚úì Conversion completed successfully!\")\n",
    "    print(f\"  ONNX model: {onnx_model_path}\")\n",
    "    print(f\"  Model size: {onnx_model_path.stat().st_size / (1024 * 1024):.2f} MB\")\n",
    "else:\n",
    "    print(f\"\\n‚ö† Warning: No ONNX model file found in {conversion_output_dir} (searched recursively)\")\n",
    "\n",
    "# Backup conversion output to Google Drive if in Colab\n",
    "if IN_COLAB and drive_store and conversion_output_dir:\n",
    "    output_path = Path(conversion_output_dir).resolve()\n",
    "    # Check if output is already in Drive\n",
    "    if str(output_path).startswith(\"/content/drive\"):\n",
    "        print(f\"\\n‚úì Conversion output is already in Google Drive\")\n",
    "        print(f\"  Drive path: {output_path}\")\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"\\nüì¶ Backing up conversion output to Google Drive...\")\n",
    "            result = drive_store.backup(output_path, expect=\"dir\")\n",
    "            if result.ok:\n",
    "                print(f\"‚úì Successfully backed up conversion output to Google Drive\")\n",
    "                print(f\"  Drive path: {result.dst}\")\n",
    "            else:\n",
    "                print(f\"‚ö† Drive backup failed: {result.reason}\")\n",
    "                if result.error:\n",
    "                    print(f\"  Error: {result.error}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Drive backup error: {e}\")\n",
    "            print(f\"  Output is still available locally at: {conversion_output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}