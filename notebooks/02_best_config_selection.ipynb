{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Best Configuration Selection (Local, Google Colab & Kaggle)\n",
    "\n",
    "This notebook automates the selection of the best model configuration from MLflow\n",
    "based on metrics and benchmarking results, then performs final training and model conversion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "1. **Best Model Selection**: Query MLflow benchmark runs, join to training runs via grouping tags (`code.study_key_hash`, `code.trial_key_hash`), select best using normalized composite scoring\n",
    "2. **Artifact Acquisition**: Download the best model's checkpoint using fallback strategy (local disk ‚Üí drive restore ‚Üí MLflow download)\n",
    "3. **Final Training**: Optionally retrain with best config on full dataset (if not already final training)\n",
    "4. **Model Conversion**: Convert the final model to ONNX format using canonical path structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important\n",
    "\n",
    "- This notebook **executes on Local, Google Colab, or Kaggle** (not on Azure ML compute)\n",
    "- Requires MLflow tracking to be set up (Azure ML workspace or local SQLite)\n",
    "- All computation happens on the platform's GPU (if available) or CPU\n",
    "- **Storage & Persistence**:\n",
    "  - **Local**: Outputs saved to `outputs/` directory in repository root\n",
    "  - **Google Colab**: Checkpoints are automatically saved to Google Drive for persistence across sessions\n",
    "  - **Kaggle**: Outputs in `/kaggle/working/` are automatically persisted - no manual backup needed\n",
    "- The notebook must be **re-runnable end-to-end**\n",
    "- Uses the dataset path specified in the data config (from `config/data/*.yaml`), typically pointing to a local folder included in the repository\n",
    "- **Session Management**:\n",
    "  - **Local**: No session limits, outputs persist in repository\n",
    "  - **Colab**: Sessions timeout after 12-24 hours (depending on Colab plan). Checkpoints are saved to Drive automatically.\n",
    "  - **Kaggle**: Sessions have time limits based on your plan. All outputs are automatically saved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Detection\n",
    "\n",
    "The notebook automatically detects the execution environment (local, Google Colab, or Kaggle) and adapts its behavior accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Detected environment: LOCAL\n",
      "Platform: local\n",
      "Base directory: Current working directory\n",
      "Backup enabled: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "# Detect execution environment\n",
    "IN_COLAB = \"COLAB_GPU\" in os.environ or \"COLAB_TPU\" in os.environ\n",
    "IN_KAGGLE = \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "IS_LOCAL = not IN_COLAB and not IN_KAGGLE\n",
    "# Set platform-specific constants\n",
    "if IN_COLAB:\n",
    "    PLATFORM = \"colab\"\n",
    "    BASE_DIR = Path(\"/content\")\n",
    "    BACKUP_ENABLED = True\n",
    "elif IN_KAGGLE:\n",
    "    PLATFORM = \"kaggle\"\n",
    "    BASE_DIR = Path(\"/kaggle/working\")\n",
    "    BACKUP_ENABLED = False\n",
    "else:\n",
    "    PLATFORM = \"local\"\n",
    "    BASE_DIR = None\n",
    "    BACKUP_ENABLED = False\n",
    "print(f\"‚úì Detected environment: {PLATFORM.upper()}\")\n",
    "print(f\"Platform: {PLATFORM}\")\n",
    "print(\n",
    "    f\"Base directory: {BASE_DIR if BASE_DIR else 'Current working directory'}\")\n",
    "print(f\"Backup enabled: {BACKUP_ENABLED}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Packages\n",
    "\n",
    "Install required packages based on the execution environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For local environment, please:\n",
      "1. Create conda environment: conda env create -f config/environment/conda.yaml\n",
      "2. Activate: conda activate resume-ner-training\n",
      "3. Restart kernel after activation\n",
      "\n",
      "If you've already done this, you can continue to the next cell.\n",
      "\n",
      "Installing Azure ML SDK (required for imports)...\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "if IS_LOCAL:\n",
    "    print(\"For local environment, please:\")\n",
    "    print(\"1. Create conda environment: conda env create -f config/environment/conda.yaml\")\n",
    "    print(\"2. Activate: conda activate resume-ner-training\")\n",
    "    print(\"3. Restart kernel after activation\")\n",
    "    print(\"\\nIf you've already done this, you can continue to the next cell.\")\n",
    "    print(\"\\nInstalling Azure ML SDK (required for imports)...\")\n",
    "    # Install Azure ML packages even for local (in case conda env not activated)\n",
    "    %pip install \"azure-ai-ml>=1.0.0\" --quiet\n",
    "    %pip install \"azure-identity>=1.12.0\" --quiet\n",
    "    %pip install azureml-defaults --quiet\n",
    "    %pip install azureml-mlflow --quiet\n",
    "else:\n",
    "    # Core ML libraries\n",
    "    %pip install \"transformers>=4.35.0,<5.0.0\" --quiet\n",
    "    %pip install \"safetensors>=0.4.0\" --quiet\n",
    "    %pip install \"datasets>=2.12.0\" --quiet\n",
    "\n",
    "    # ML utilities\n",
    "    %pip install \"numpy>=1.24.0,<2.0.0\" --quiet\n",
    "    %pip install \"pandas>=2.0.0\" --quiet\n",
    "    %pip install \"scikit-learn>=1.3.0\" --quiet\n",
    "\n",
    "    # Utilities\n",
    "    %pip install \"pyyaml>=6.0\" --quiet\n",
    "    %pip install \"tqdm>=4.65.0\" --quiet\n",
    "    %pip install \"seqeval>=1.2.2\" --quiet\n",
    "    %pip install \"sentencepiece>=0.1.99\" --quiet\n",
    "\n",
    "    # Experiment tracking\n",
    "    %pip install mlflow --quiet\n",
    "    %pip install optuna --quiet\n",
    "\n",
    "    # Azure ML SDK (required for orchestration imports)\n",
    "    %pip install \"azure-ai-ml>=1.0.0\" --quiet\n",
    "    %pip install \"azure-identity>=1.12.0\" --quiet\n",
    "    %pip install azureml-defaults --quiet\n",
    "    %pip install azureml-mlflow --quiet\n",
    "\n",
    "    # ONNX support\n",
    "    %pip install onnxruntime --quiet\n",
    "    %pip install \"onnx>=1.16.0\" --quiet\n",
    "    %pip install \"onnxscript>=0.1.0\" --quiet\n",
    "\n",
    "    print(\"‚úì All dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Repository Setup\n",
    "\n",
    "**Note**: Repository setup is only needed for Colab/Kaggle environments. Local environments should already have the repository cloned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Local environment detected - assuming repository already exists\n",
      "‚úì Repository root: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\n",
      "‚úì Config directory: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config\n",
      "‚úì Source directory: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\src\n",
      "‚úì Repository structure verified\n"
     ]
    }
   ],
   "source": [
    "# Repository setup - only needed for Colab/Kaggle\n",
    "if not IS_LOCAL:\n",
    "    if IN_KAGGLE:\n",
    "        # For Kaggle\n",
    "        !git clone -b gg_final_training_2 https://github.com/longdang193/resume-ner-azureml.git /kaggle/working/resume-ner-azureml\n",
    "    elif IN_COLAB:\n",
    "        # For Google Colab\n",
    "        !git clone -b gg_final_training_2 https://github.com/longdang193/resume-ner-azureml.git /content/resume-ner-azureml\n",
    "else:\n",
    "    print(\"‚úì Local environment detected - assuming repository already exists\")\n",
    "\n",
    "# Set up paths\n",
    "if not IS_LOCAL:\n",
    "    ROOT_DIR = BASE_DIR / \"resume-ner-azureml\"\n",
    "else:\n",
    "    # For local, try to find repo root\n",
    "    ROOT_DIR = Path.cwd()\n",
    "    # Try to find the repo root by looking for config directory\n",
    "    while ROOT_DIR.parent != ROOT_DIR:\n",
    "        if (ROOT_DIR / \"config\").exists() and (ROOT_DIR / \"src\").exists():\n",
    "            break\n",
    "        ROOT_DIR = ROOT_DIR.parent\n",
    "\n",
    "CONFIG_DIR = ROOT_DIR / \"config\"\n",
    "SRC_DIR = ROOT_DIR / \"src\"\n",
    "\n",
    "# Add src to path\n",
    "import sys\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "print(f\"‚úì Repository root: {ROOT_DIR}\")\n",
    "print(f\"‚úì Config directory: {CONFIG_DIR}\")\n",
    "print(f\"‚úì Source directory: {SRC_DIR}\")\n",
    "\n",
    "# Verify repository structure\n",
    "required_dirs = [CONFIG_DIR, SRC_DIR]\n",
    "for dir_path in required_dirs:\n",
    "    if not dir_path.exists():\n",
    "        raise ValueError(f\"Required directory not found: {dir_path}\")\n",
    "print(\"‚úì Repository structure verified\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Configuration\n",
    "\n",
    "Load experiment configuration and define experiment naming convention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded experiment config: resume_ner_baseline\n",
      "‚úì Loaded tags config\n",
      "‚úì Loaded best model selection config\n",
      "‚úì Loaded conversion config\n",
      "‚úì Loaded artifact acquisition config\n",
      "\n",
      "‚úì Experiment names defined:\n",
      "  - Benchmark: resume_ner_baseline-benchmark\n",
      "  - Training: resume_ner_baseline-training\n",
      "  - Conversion: resume_ner_baseline-conversion\n",
      "\n",
      "Note: Experiment discovery will happen after MLflow setup (Cell 4)\n"
     ]
    }
   ],
   "source": [
    "from orchestration.config_loader import load_experiment_config\n",
    "from orchestration import EXPERIMENT_NAME\n",
    "from shared.yaml_utils import load_yaml\n",
    "\n",
    "# Load experiment config\n",
    "experiment_config = load_experiment_config(CONFIG_DIR, EXPERIMENT_NAME)\n",
    "print(f\"‚úì Loaded experiment config: {experiment_config.name}\")\n",
    "\n",
    "# Load best model selection configs\n",
    "tags_config = load_yaml(CONFIG_DIR / \"tags.yaml\")\n",
    "selection_config = load_yaml(CONFIG_DIR / \"best_model_selection.yaml\")\n",
    "conversion_config = load_yaml(CONFIG_DIR / \"conversion.yaml\")\n",
    "acquisition_config = load_yaml(CONFIG_DIR / \"artifact_acquisition.yaml\")\n",
    "\n",
    "print(f\"‚úì Loaded tags config\")\n",
    "print(f\"‚úì Loaded best model selection config\")\n",
    "print(f\"‚úì Loaded conversion config\")\n",
    "print(f\"‚úì Loaded artifact acquisition config\")\n",
    "\n",
    "# Define experiment names (discovery happens after MLflow setup in Cell 4)\n",
    "experiment_name = experiment_config.name\n",
    "benchmark_experiment_name = f\"{experiment_name}-benchmark\"\n",
    "training_experiment_name = f\"{experiment_name}-training\"  # For final training runs\n",
    "conversion_experiment_name = f\"{experiment_name}-conversion\"\n",
    "\n",
    "print(f\"\\n‚úì Experiment names defined:\")\n",
    "print(f\"  - Benchmark: {benchmark_experiment_name}\")\n",
    "print(f\"  - Training: {training_experiment_name}\")\n",
    "print(f\"  - Conversion: {conversion_experiment_name}\")\n",
    "print(f\"\\nNote: Experiment discovery will happen after MLflow setup (Cell 4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Setup MLflow\n",
    "\n",
    "Setup MLflow tracking with fallback to local if Azure ML is unavailable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-05 16:44:15,817 - shared.mlflow_setup - INFO - Azure ML enabled in config, attempting to connect...\n",
      "2026-01-05 16:44:18,865 - shared.mlflow_setup - WARNING - [DEBUG] Initial env check - subscription_id: False, resource_group: False, client_id: False, client_secret: False, tenant_id: False\n",
      "2026-01-05 16:44:18,866 - shared.mlflow_setup - INFO - Attempting to load credentials from config.env at: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config.env\n",
      "2026-01-05 16:44:18,867 - shared.mlflow_setup - INFO - Loading credentials from c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config.env\n",
      "2026-01-05 16:44:18,868 - shared.mlflow_setup - INFO - Loaded subscription/resource group from config.env\n",
      "2026-01-05 16:44:18,869 - shared.mlflow_setup - INFO - Loaded service principal credentials from config.env\n",
      "2026-01-05 16:44:18,870 - shared.mlflow_setup - WARNING - [DEBUG] Platform detected: local\n",
      "2026-01-05 16:44:18,870 - shared.mlflow_setup - WARNING - [DEBUG] Service Principal check - client_id present: True, client_secret present: True, tenant_id present: True, has_service_principal: True\n",
      "2026-01-05 16:44:18,871 - shared.mlflow_setup - INFO - Using Service Principal authentication (from config.env)\n",
      "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "2026-01-05 16:44:22,050 - shared.mlflow_setup - INFO - Successfully connected to Azure ML workspace: resume-ner-ws\n",
      "2026-01-05 16:44:23,626 - shared.mlflow_setup - INFO - Using Azure ML workspace tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì MLflow tracking URI: azureml://germanywestcentral.api.azureml.ms/mlflow/v2.0/subscriptions/50c06ef8-627b-46d5-b779-d07c9b398f75/resourceGroups/resume_ner_2026-01-02-16-47-05/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws\n",
      "‚úì MLflow experiment: resume_ner_baseline-training\n",
      "\n",
      "‚úì Found 2 HPO experiment(s):\n",
      "  - resume_ner_baseline-hpo-distilbert (backbone: distilbert)\n",
      "  - resume_ner_baseline-hpo-distilroberta (backbone: distilroberta)\n",
      "‚úì Benchmark experiment: resume_ner_baseline-benchmark\n",
      "‚úì Training experiment: resume_ner_baseline-training (for final training runs)\n",
      "‚úì Conversion experiment: resume_ner_baseline-conversion\n"
     ]
    }
   ],
   "source": [
    "from shared.mlflow_setup import setup_mlflow_from_config\n",
    "import mlflow\n",
    "\n",
    "# Setup MLflow tracking (use training experiment for setup - actual queries use discovered experiments)\n",
    "tracking_uri = setup_mlflow_from_config(\n",
    "    experiment_name=training_experiment_name,\n",
    "    config_dir=CONFIG_DIR,\n",
    "    fallback_to_local=True,\n",
    ")\n",
    "\n",
    "print(f\"‚úì MLflow tracking URI: {tracking_uri}\")\n",
    "print(f\"‚úì MLflow experiment: {training_experiment_name}\")\n",
    "\n",
    "# Discover HPO and benchmark experiments from MLflow (after setup)\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "all_experiments = client.search_experiments()\n",
    "\n",
    "# Find HPO experiments (format: {experiment_name}-hpo-{backbone})\n",
    "hpo_experiments = {}\n",
    "for exp in all_experiments:\n",
    "    if exp.name.startswith(f\"{experiment_name}-hpo-\"):\n",
    "        backbone = exp.name.replace(f\"{experiment_name}-hpo-\", \"\")\n",
    "        hpo_experiments[backbone] = {\n",
    "            \"name\": exp.name,\n",
    "            \"id\": exp.experiment_id\n",
    "        }\n",
    "\n",
    "# Find benchmark experiment\n",
    "benchmark_experiment = None\n",
    "for exp in all_experiments:\n",
    "    if exp.name == benchmark_experiment_name:\n",
    "        benchmark_experiment = {\n",
    "            \"name\": exp.name,\n",
    "            \"id\": exp.experiment_id\n",
    "        }\n",
    "        break\n",
    "\n",
    "print(f\"\\n‚úì Found {len(hpo_experiments)} HPO experiment(s):\")\n",
    "for backbone, exp_info in hpo_experiments.items():\n",
    "    print(f\"  - {exp_info['name']} (backbone: {backbone})\")\n",
    "\n",
    "if benchmark_experiment:\n",
    "    print(f\"‚úì Benchmark experiment: {benchmark_experiment['name']}\")\n",
    "else:\n",
    "    print(f\"‚ö† Benchmark experiment not found: {benchmark_experiment_name}\")\n",
    "\n",
    "print(f\"‚úì Training experiment: {training_experiment_name} (for final training runs)\")\n",
    "print(f\"‚úì Conversion experiment: {conversion_experiment_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Drive Backup Setup (Colab Only)\n",
    "\n",
    "Setup Google Drive backup/restore for Colab environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Local environment detected - outputs will be saved to repository (no Drive backup needed)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Fix numpy/pandas compatibility before importing orchestration modules\n",
    "try:\n",
    "    from orchestration.drive_backup import create_colab_store\n",
    "except (ValueError, ImportError) as e:\n",
    "    if \"numpy.dtype size changed\" in str(e) or \"numpy\" in str(e).lower():\n",
    "        print(\"‚ö† Numpy/pandas compatibility issue detected. Fixing...\")\n",
    "        import subprocess\n",
    "        import sys\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"--force-reinstall\", \"--no-cache-dir\", \"numpy>=1.24.0,<2.0.0\", \"pandas>=2.0.0\", \"--quiet\"])\n",
    "        print(\"‚úì Numpy/pandas reinstalled. Please restart the kernel and re-run this cell.\")\n",
    "        raise RuntimeError(\"Please restart kernel after numpy/pandas fix\")\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Mount Google Drive and create backup store (Colab only - Kaggle doesn't need this)\n",
    "DRIVE_BACKUP_DIR = None\n",
    "drive_store = None\n",
    "restore_from_drive = None\n",
    "\n",
    "if IN_COLAB:\n",
    "    drive_store = create_colab_store(ROOT_DIR, CONFIG_DIR)\n",
    "    if drive_store:\n",
    "        BACKUP_ENABLED = True\n",
    "        DRIVE_BACKUP_DIR = drive_store.backup_root\n",
    "        # Create restore function wrapper\n",
    "        def restore_from_drive(local_path: Path, is_directory: bool = False) -> bool:\n",
    "            \"\"\"Restore file/directory from Drive backup.\"\"\"\n",
    "            try:\n",
    "                expect = \"dir\" if is_directory else \"file\"\n",
    "                result = drive_store.restore(local_path, expect=expect)\n",
    "                return result.ok\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† Drive restore failed: {e}\")\n",
    "                return False\n",
    "        print(f\"‚úì Google Drive mounted\")\n",
    "        print(f\"‚úì Backup base directory: {DRIVE_BACKUP_DIR}\")\n",
    "        print(f\"\\nNote: All outputs/ will be mirrored to: {DRIVE_BACKUP_DIR / 'outputs'}\")\n",
    "    else:\n",
    "        BACKUP_ENABLED = False\n",
    "        print(\"‚ö† Warning: Could not mount Google Drive. Backup to Google Drive will be disabled.\")\n",
    "elif IN_KAGGLE:\n",
    "    print(\"‚úì Kaggle environment detected - outputs are automatically persisted (no Drive mount needed)\")\n",
    "    BACKUP_ENABLED = False\n",
    "else:\n",
    "    # Local environment\n",
    "    print(\"‚úì Local environment detected - outputs will be saved to repository (no Drive backup needed)\")\n",
    "    BACKUP_ENABLED = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Best Model Selection\n",
    "\n",
    "Query MLflow benchmark runs, join to training runs via grouping tags, and select the best model using normalized composite scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-05 16:44:23,914 - orchestration.jobs.selection.mlflow_selection - INFO - Finding best model from MLflow\n",
      "2026-01-05 16:44:23,915 - orchestration.jobs.selection.mlflow_selection - INFO -   Benchmark experiment: resume_ner_baseline-benchmark\n",
      "2026-01-05 16:44:23,916 - orchestration.jobs.selection.mlflow_selection - INFO -   HPO experiments: 2\n",
      "2026-01-05 16:44:23,917 - orchestration.jobs.selection.mlflow_selection - INFO -   Objective metric: macro-f1\n",
      "2026-01-05 16:44:23,917 - orchestration.jobs.selection.mlflow_selection - INFO -   Composite weights: F1=0.70, Latency=0.30\n",
      "2026-01-05 16:44:23,918 - orchestration.jobs.selection.mlflow_selection - INFO - Querying benchmark runs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Finding best model from MLflow...\n",
      "   Benchmark experiment: resume_ner_baseline-benchmark\n",
      "   HPO experiments: 2\n",
      "   Objective metric: macro-f1\n",
      "   Composite weights: F1=0.70, Latency=0.30\n",
      "\n",
      "üìä Querying benchmark runs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-05 16:44:24,047 - orchestration.jobs.selection.mlflow_selection - INFO - Found 2 finished benchmark runs\n",
      "2026-01-05 16:44:24,048 - orchestration.jobs.selection.mlflow_selection - INFO - Found 2 benchmark runs with required metrics and grouping tags\n",
      "2026-01-05 16:44:24,049 - orchestration.jobs.selection.mlflow_selection - INFO - Preloading trial and refit runs from HPO experiments...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Found 2 benchmark runs with required metrics and grouping tags\n",
      "\n",
      "üîó Preloading trial runs (metrics) and refit runs (artifacts) from HPO experiments...\n",
      "   resume_ner_baseline-hpo-distilbert: 10 finished runs, 4 trial runs, 2 refit runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-05 16:44:24,284 - orchestration.jobs.selection.mlflow_selection - INFO - Built trial lookup with 2 unique (study_hash, trial_hash) pairs\n",
      "2026-01-05 16:44:24,284 - orchestration.jobs.selection.mlflow_selection - INFO - Built refit lookup with 2 unique (study_hash, trial_hash) pairs\n",
      "2026-01-05 16:44:24,285 - orchestration.jobs.selection.mlflow_selection - INFO - Joining benchmark runs with trial runs and refit runs...\n",
      "2026-01-05 16:44:24,286 - orchestration.jobs.selection.mlflow_selection - INFO - Found 2 candidate(s) with both benchmark and training metrics\n",
      "2026-01-05 16:44:24,286 - orchestration.jobs.selection.mlflow_selection - INFO - Computing composite scores...\n",
      "2026-01-05 16:44:24,286 - orchestration.jobs.selection.mlflow_selection - INFO - Best model selected:\n",
      "2026-01-05 16:44:24,287 - orchestration.jobs.selection.mlflow_selection - INFO -   Artifact Run ID: 63f2e01b-ccc3-4b91-b708-0c5907ed819b\n",
      "2026-01-05 16:44:24,287 - orchestration.jobs.selection.mlflow_selection - INFO -   Trial Run ID: d23ca1ad-9410-496e-955b-3b6c35463462\n",
      "2026-01-05 16:44:24,288 - orchestration.jobs.selection.mlflow_selection - INFO -   Backbone: distilbert\n",
      "2026-01-05 16:44:24,288 - orchestration.jobs.selection.mlflow_selection - INFO -   F1 Score: 0.4316\n",
      "2026-01-05 16:44:24,289 - orchestration.jobs.selection.mlflow_selection - INFO -   Latency: 6.00 ms\n",
      "2026-01-05 16:44:24,289 - orchestration.jobs.selection.mlflow_selection - INFO -   Composite Score: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   resume_ner_baseline-hpo-distilroberta: 0 finished runs, 0 trial runs, 0 refit runs\n",
      "   Built trial lookup with 2 unique (study_hash, trial_hash) pairs\n",
      "   Built refit lookup with 2 unique (study_hash, trial_hash) pairs\n",
      "\n",
      "üîó Joining benchmark runs with trial runs (metrics) and refit runs (artifacts)...\n",
      "   Found 2 candidate(s) with both benchmark and training metrics\n",
      "\n",
      "‚úÖ Best model selected:\n",
      "   Run ID: 63f2e01b-ccc3-4b91-b708-0c5907ed819b\n",
      "   Experiment: resume_ner_baseline-hpo-distilbert\n",
      "   Backbone: distilbert\n",
      "   F1 Score: 0.4316\n",
      "   Latency: 6.00 ms\n",
      "   Composite Score: 0.7000\n",
      "‚úì Extracted lineage information: ['hpo_study_key_hash', 'hpo_trial_key_hash', 'hpo_trial_run_id', 'hpo_refit_run_id']\n",
      "\n",
      "‚úì Best model checkpoint available at: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\best_model_selection\\local\\distilbert\\sel_350a79aa_f349f4af\n"
     ]
    }
   ],
   "source": [
    "from orchestration.jobs.selection.mlflow_selection import find_best_model_from_mlflow\n",
    "from orchestration.jobs.selection.artifact_acquisition import acquire_best_model_checkpoint\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, Dict, Any\n",
    "\n",
    "# Validate experiments\n",
    "if benchmark_experiment is None:\n",
    "    raise ValueError(f\"Benchmark experiment '{benchmark_experiment_name}' not found. Run benchmark jobs first.\")\n",
    "\n",
    "if not hpo_experiments:\n",
    "    raise ValueError(f\"No HPO experiments found. Run HPO jobs first.\")\n",
    "\n",
    "# Find best model\n",
    "best_model = find_best_model_from_mlflow(\n",
    "    benchmark_experiment=benchmark_experiment,\n",
    "    hpo_experiments=hpo_experiments,\n",
    "    tags_config=tags_config,\n",
    "    selection_config=selection_config,\n",
    "    use_python_filtering=True,\n",
    ")\n",
    "\n",
    "if best_model is None:\n",
    "    raise ValueError(\"Could not find best model from MLflow.\")\n",
    "\n",
    "# Extract lineage information from best_model for final training tags\n",
    "from orchestration.jobs.final_training import extract_lineage_from_best_model\n",
    "lineage = extract_lineage_from_best_model(best_model)\n",
    "print(f\"‚úì Extracted lineage information: {list(lineage.keys())}\")\n",
    "\n",
    "# Acquire checkpoint\n",
    "best_checkpoint_dir = acquire_best_model_checkpoint(\n",
    "    best_run_info=best_model,\n",
    "    root_dir=ROOT_DIR,\n",
    "    config_dir=CONFIG_DIR,\n",
    "    acquisition_config=acquisition_config,\n",
    "    selection_config=selection_config,\n",
    "    platform=PLATFORM,\n",
    "    restore_from_drive=restore_from_drive if \"restore_from_drive\" in locals() else None,\n",
    "    drive_store=drive_store if \"drive_store\" in locals() else None,\n",
    "    in_colab=IN_COLAB,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Best model checkpoint available at: {best_checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if selected run is already final training (skip retraining if so)\n",
    "stage_tag = tags_config[\"process\"][\"stage\"]\n",
    "trained_on_full_data_tag = tags_config[\"training\"][\"trained_on_full_data\"]\n",
    "\n",
    "is_final_training = best_model[\"tags\"].get(stage_tag) == \"final_training\"\n",
    "used_full_data = (\n",
    "    best_model[\"tags\"].get(trained_on_full_data_tag) == \"true\" or\n",
    "    best_model[\"params\"].get(\"use_combined_data\", \"false\").lower() == \"true\"\n",
    ")\n",
    "\n",
    "SKIP_FINAL_TRAINING = is_final_training and used_full_data\n",
    "\n",
    "if SKIP_FINAL_TRAINING:\n",
    "    final_checkpoint_dir = best_checkpoint_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Final Training\n",
    "\n",
    "Run final training with best configuration if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Starting final training with best configuration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-05 16:44:30,635 - orchestration.jobs.tracking.config.loader - INFO - [MLflow Config] Loaded config from c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\config\\mlflow.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Final training config loaded from final_training.yaml\n",
      "‚úì Output directory: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\final_training\\local\\distilbert\\spec_81710c3324325ad0_exec_39a8e5a80c86d2eb\\v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-05 16:44:32,047 - orchestration.jobs.tracking.index.run_index - WARNING - Could not acquire lock for c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\cache\\mlflow_index.json, proceeding with non-atomic write\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created MLflow run: final_training_distilbert_spec_81710c33_exec_39a8e5a8_v1 (e260be22-406...)\n",
      "üîÑ Running final training...\n",
      "Attempted to log scalar metric param_learning_rate:\n",
      "3.272307764760585e-05\n",
      "Attempted to log scalar metric param_batch_size:\n",
      "2\n",
      "Attempted to log scalar metric param_dropout:\n",
      "0.12172869616088591\n",
      "Attempted to log scalar metric param_weight_decay:\n",
      "0.008691291284606174\n",
      "Attempted to log scalar metric param_epochs:\n",
      "1\n",
      "Attempted to log scalar metric param_backbone:\n",
      "distilbert-base-uncased\n",
      "Attempted to log scalar metric macro-f1:\n",
      "0.41860465116279066\n",
      "Attempted to log scalar metric macro-f1-span:\n",
      "0.0\n",
      "Attempted to log scalar metric loss:\n",
      "1.7254383563995361\n",
      "üèÉ View run final_training_distilbert_spec_81710c33_exec_39a8e5a8_v1 at: https://germanywestcentral.api.azureml.ms/mlflow/v2.0/subscriptions/50c06ef8-627b-46d5-b779-d07c9b398f75/resourceGroups/resume_ner_2026-01-02-16-47-05/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/#/experiments/801daa4d-3a56-4952-a374-cf2c5a9c2846/runs/e260be22-4068-47ff-86e2-06a88702f040\n",
      "üß™ View experiment at: https://germanywestcentral.api.azureml.ms/mlflow/v2.0/subscriptions/50c06ef8-627b-46d5-b779-d07c9b398f75/resourceGroups/resume_ner_2026-01-02-16-47-05/providers/Microsoft.MachineLearningServices/workspaces/resume-ner-ws/#/experiments/801daa4d-3a56-4952-a374-cf2c5a9c2846\n",
      "\n",
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\azureml\\core\\__init__.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "  [Training] Set MLflow tracking URI: azureml://germanywestcentral.api.azureml.ms/mlflow...\n",
      "  [Training] Set MLflow experiment: resume_ner_baseline-training\n",
      "  [Training] Using existing run: e260be22-406... (final training)\n",
      "  [Training] ‚úì Started run for artifact logging\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: SKILL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: EMAIL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: NAME seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\HOANG PHI LONG DANG\\Miniconda3\\envs\\resume-ner-training\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  [Training] Active MLflow run detected: e260be22-406...\n",
      "  [Training] Logging checkpoint artifacts from: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\final_training\\local\\distilbert\\spec_81710c3324325ad0_exec_39a8e5a80c86d2eb\\v1\\checkpoint\n",
      "  [Training] ‚úì Logged checkpoint artifacts to MLflow\n",
      "  [Training] Ended independent run\n",
      "\n",
      "‚úì Final training completed. Checkpoint: c:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\\outputs\\final_training\\local\\distilbert\\spec_81710c3324325ad0_exec_39a8e5a80c86d2eb\\v1\\checkpoint\n",
      "‚úì MLflow run: e260be22-406...\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_FINAL_TRAINING:\n",
    "    print(\"üîÑ Starting final training with best configuration...\")\n",
    "    from orchestration.jobs.final_training import execute_final_training\n",
    "    # Execute final training (uses final_training.yaml via load_final_training_config)\n",
    "    final_checkpoint_dir = execute_final_training(\n",
    "        root_dir=ROOT_DIR,\n",
    "        config_dir=CONFIG_DIR,\n",
    "        best_model=best_model,\n",
    "        experiment_config=experiment_config,\n",
    "        lineage=lineage,\n",
    "        training_experiment_name=training_experiment_name,\n",
    "        platform=PLATFORM,\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úì Skipping final training - using selected checkpoint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Starting model conversion to ONNX...\")\n",
    "\n",
    "from orchestration.jobs.tracking.trackers.conversion_tracker import MLflowConversionTracker\n",
    "from orchestration.naming_centralized import create_naming_context, build_output_path\n",
    "from orchestration.fingerprints import build_parent_training_id, compute_conv_fp\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup conversion tracker\n",
    "conversion_tracker = MLflowConversionTracker(conversion_experiment_name)\n",
    "\n",
    "# Determine checkpoint path\n",
    "checkpoint_path = final_checkpoint_dir\n",
    "\n",
    "if not checkpoint_path.exists():\n",
    "    raise ValueError(f\"Checkpoint not found at: {checkpoint_path}\")\n",
    "\n",
    "# Extract backbone from best model\n",
    "backbone = best_model[\"backbone\"]\n",
    "\n",
    "# Conversion settings\n",
    "# Load conversion settings from config\n",
    "quantization = conversion_config[\"onnx\"][\"quantization\"]\n",
    "opset_version = conversion_config[\"onnx\"][\"opset_version\"]\n",
    "conversion_target = conversion_config[\"target\"][\"format\"]\n",
    "\n",
    "print(f\"‚úì Checkpoint path: {checkpoint_path}\")\n",
    "print(f\"‚úì Backbone: {backbone}\")\n",
    "print(f\"‚úì Conversion target: {conversion_target}\")\n",
    "print(f\"‚úì Quantization: {quantization}\")\n",
    "print(f\"‚úì ONNX opset version: {opset_version}\")\n",
    "\n",
    "# Extract or compute fingerprints for conversion context\n",
    "# Try to get from best model tags first\n",
    "spec_fp = best_model[\"tags\"].get(\"code.spec_fp\")\n",
    "exec_fp = best_model[\"tags\"].get(\"code.exec_fp\")\n",
    "variant = int(best_model[\"tags\"].get(\"code.variant\", \"1\")) if best_model[\"tags\"].get(\"code.variant\") else 1\n",
    "\n",
    "# If not in tags, compute from config\n",
    "if not spec_fp or not exec_fp:\n",
    "    from orchestration.fingerprints import compute_spec_fp, compute_exec_fp\n",
    "    from orchestration.config_loader import load_all_configs\n",
    "    import subprocess\n",
    "    \n",
    "    all_configs = load_all_configs(experiment_config)\n",
    "    \n",
    "    spec_fp = compute_spec_fp(\n",
    "        model_config=all_configs.get(\"model\", {}),\n",
    "        data_config=all_configs.get(\"data\", {}),\n",
    "        train_config=all_configs.get(\"train\", {}),\n",
    "        seed=int(best_model[\"params\"].get(\"random_seed\", 42)),\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        git_sha = subprocess.check_output(\n",
    "            [\"git\", \"rev-parse\", \"HEAD\"],\n",
    "            cwd=ROOT_DIR,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "        ).decode().strip()\n",
    "    except Exception:\n",
    "        git_sha = None\n",
    "    \n",
    "    exec_fp = compute_exec_fp(\n",
    "        git_sha=git_sha,\n",
    "        env_config=all_configs.get(\"env\", {}),\n",
    "    )\n",
    "\n",
    "# Build parent_training_id\n",
    "parent_training_id = build_parent_training_id(spec_fp, exec_fp, variant)\n",
    "\n",
    "# Compute conversion fingerprint\n",
    "conv_fp = compute_conv_fp(backbone, quantization, opset_version)\n",
    "\n",
    "# Create conversion context\n",
    "conversion_context = create_naming_context(\n",
    "    process_type=\"conversion\",\n",
    "    model=backbone.split(\"-\")[0] if \"-\" in backbone else backbone,\n",
    "    environment=PLATFORM,\n",
    "    parent_training_id=parent_training_id,\n",
    "    conv_fp=conv_fp,\n",
    ")\n",
    "\n",
    "# Build conversion output path using canonical structure\n",
    "conversion_output_dir = build_output_path(ROOT_DIR, conversion_context)\n",
    "conversion_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"‚úì Conversion output: {conversion_output_dir}\")\n",
    "\n",
    "# Run conversion\n",
    "try:\n",
    "    # Import conversion function\n",
    "    from model_conversion.onnx_exporter import export_to_onnx\n",
    "    \n",
    "    # Start conversion run\n",
    "    conversion_run_name = f\"conversion_{backbone}_{conversion_target}\"\n",
    "    \n",
    "    with conversion_tracker.start_conversion_run(\n",
    "        run_name=conversion_run_name,\n",
    "        conversion_type=conversion_target,\n",
    "        source_training_run=best_model[\"run_id\"],\n",
    "        output_dir=conversion_output_dir,\n",
    "    ) as conversion_handle:\n",
    "        \n",
    "        # Log conversion parameters\n",
    "        conversion_tracker.log_conversion_parameters(\n",
    "            checkpoint_path=str(checkpoint_path),\n",
    "            conversion_target=conversion_target,\n",
    "            quantization=quantization,\n",
    "            opset_version=opset_version,\n",
    "            backbone=backbone,\n",
    "        )\n",
    "        \n",
    "        # Perform conversion\n",
    "        onnx_model_path = export_to_onnx(\n",
    "            checkpoint_dir=checkpoint_path,\n",
    "            output_dir=conversion_output_dir,\n",
    "            quantize_int8=(quantization == \"int8\"),\n",
    "        )\n",
    "        \n",
    "        # Calculate original checkpoint size for compression ratio\n",
    "        original_size = None\n",
    "        if checkpoint_path.exists():\n",
    "            total_size = sum(f.stat().st_size for f in checkpoint_path.rglob(\"*\") if f.is_file())\n",
    "            original_size = total_size / (1024 * 1024)  # MB\n",
    "        \n",
    "        # Log conversion results\n",
    "        conversion_tracker.log_conversion_results(\n",
    "            conversion_success=True,\n",
    "            onnx_model_path=onnx_model_path,\n",
    "            original_checkpoint_size=original_size,\n",
    "            smoke_test_passed=True,  # Could add actual smoke test\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Model converted successfully!\")\n",
    "        print(f\"‚úì ONNX model saved to: {onnx_model_path}\")\n",
    "        \n",
    "        if conversion_handle:\n",
    "            print(f\"‚úì Conversion logged to MLflow run: {conversion_handle.run_id}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Conversion failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
