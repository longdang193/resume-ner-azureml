{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Local Training Orchestration (Google Colab Compatible)\n",
        "\n",
        "This notebook orchestrates all training activities for **local execution** with Google Colab GPU compute support.\n",
        "\n",
        "## Overview\n",
        "\n",
        "- **Step 1**: Load Centralized Configs\n",
        "- **Step 2**: Download Dataset from Kaggle & Create dataset-tiny\n",
        "- **Step 3**: Setup Local Environment\n",
        "- **Step 4**: The Dry Run\n",
        "- **Step 5**: The Sweep (HPO) - Local with Optuna\n",
        "- **Step 6**: Best Configuration Selection (Automated)\n",
        "- **Step 7**: Final Training (Post-HPO, Single Run)\n",
        "- **Step 8**: Model Conversion & Optimization\n",
        "\n",
        "## Important\n",
        "\n",
        "- This notebook **executes training locally** (not on Azure ML)\n",
        "- All computation happens on the local machine or Google Colab GPU\n",
        "- The notebook must be **re-runnable end-to-end**\n",
        "- Uses Kaggle dataset download instead of Azure ML data assets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step P1-3.1: Load Centralized Configs\n",
        "\n",
        "Load and validate all configuration files. Configs are immutable and will be logged with each job for reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.7/774.7 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required packages for local execution\n",
        "%pip install kagglehub optuna mlflow --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning repository in Colab...\n",
            "✓ Repository cloned to /content/resume-ner-azureml\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = 'COLAB_GPU' in os.environ or 'COLAB_TPU' in os.environ\n",
        "REPO_URL = \"https://github.com/longdang193/resume-ner-azureml.git\"\n",
        "COLAB_REPO_DIR = Path(\"/content/resume-ner-azureml\")\n",
        "\n",
        "if IN_COLAB and not COLAB_REPO_DIR.exists():\n",
        "    print(\"Cloning repository in Colab...\")\n",
        "    subprocess.run(\n",
        "        [\"git\", \"clone\", REPO_URL, str(COLAB_REPO_DIR)],\n",
        "        check=True\n",
        "    )\n",
        "    print(f\"✓ Repository cloned to {COLAB_REPO_DIR}\")\n",
        "elif IN_COLAB and COLAB_REPO_DIR.exists():\n",
        "    print(f\"✓ Repository already exists at {COLAB_REPO_DIR}\")\n",
        "    os.chdir(COLAB_REPO_DIR)\n",
        "    subprocess.run([\"git\", \"pull\"], check=False, capture_output=True)\n",
        "    print(\"✓ Repository updated\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/resume-ner-azureml'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3022439359.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mIN_COLAB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Running in Google Colab. Changed to directory: {ROOT_DIR}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/resume-ner-azureml'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any\n",
        "\n",
        "COLAB_ROOT_DIR = Path(\"/content/resume-ner-azureml\")\n",
        "LOCAL_ROOT_DIR = Path(\"..\").resolve()\n",
        "\n",
        "ROOT_DIR = LOCAL_ROOT_DIR if not IN_COLAB else COLAB_ROOT_DIR.resolve()\n",
        "\n",
        "if not ROOT_DIR.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Repository directory not found: {ROOT_DIR}\\n\"\n",
        "        f\"In Colab, make sure the repository was cloned in the previous cell.\"\n",
        "    )\n",
        "\n",
        "SRC_DIR = ROOT_DIR / \"src\"\n",
        "sys.path.append(str(ROOT_DIR))\n",
        "sys.path.append(str(SRC_DIR))\n",
        "\n",
        "if IN_COLAB:\n",
        "    os.chdir(ROOT_DIR)\n",
        "    print(f\"Running in Google Colab. Changed to directory: {ROOT_DIR}\")\n",
        "\n",
        "from shared.yaml_utils import load_yaml\n",
        "from shared.json_cache import save_json, load_json\n",
        "from orchestration import (\n",
        "    STAGE_SMOKE,\n",
        "    STAGE_HPO,\n",
        "    STAGE_TRAINING,\n",
        "    EXPERIMENT_NAME,\n",
        "    MODEL_NAME,\n",
        "    PROD_STAGE,\n",
        ")\n",
        "from orchestration.config_loader import (\n",
        "    ExperimentConfig,\n",
        "    create_config_metadata,\n",
        "    load_all_configs,\n",
        "    load_experiment_config,\n",
        "    compute_config_hashes,\n",
        "    snapshot_configs,\n",
        "    validate_config_immutability,\n",
        ")\n",
        "\n",
        "print(f\"Root directory: {ROOT_DIR}\")\n",
        "print(f\"Source directory: {SRC_DIR}\")\n",
        "print(f\"In Colab: {IN_COLAB}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CONFIG_DIR = ROOT_DIR / \"config\" if IN_COLAB else Path(\"../config\")\n",
        "\n",
        "experiment_config: ExperimentConfig = load_experiment_config(CONFIG_DIR, EXPERIMENT_NAME)\n",
        "configs = load_all_configs(experiment_config)\n",
        "config_hashes = compute_config_hashes(configs)\n",
        "original_configs = snapshot_configs(configs)\n",
        "\n",
        "print(f\"Loaded experiment: {experiment_config.name}\")\n",
        "print(f\"Config hashes: {config_hashes}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validate_config_immutability(configs, original_configs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_metadata = create_config_metadata(configs, config_hashes)\n",
        "print(\"Config metadata:\", config_metadata)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step P1-3.2: Download Dataset from Kaggle & Create dataset-tiny\n",
        "\n",
        "Download the dataset from Kaggle and create a tiny subset for smoke testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import shutil\n",
        "\n",
        "KAGGLE_DATASET_NAME = \"yashpwrr/resume-ner-training-dataset\"\n",
        "LOCAL_DATASET_DIR = ROOT_DIR / \"dataset\"\n",
        "LOCAL_DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Downloading dataset from Kaggle...\")\n",
        "kaggle_path = kagglehub.dataset_download(KAGGLE_DATASET_NAME)\n",
        "print(f\"Dataset downloaded to: {kaggle_path}\")\n",
        "\n",
        "dataset_path = Path(kaggle_path)\n",
        "train_json_path = next(dataset_path.rglob(\"train.json\"), None)\n",
        "\n",
        "if train_json_path is None:\n",
        "    raise FileNotFoundError(f\"train.json not found in downloaded dataset at {kaggle_path}\")\n",
        "\n",
        "print(f\"Found train.json at: {train_json_path}\")\n",
        "\n",
        "shutil.copy(train_json_path, LOCAL_DATASET_DIR / \"train.json\")\n",
        "print(f\"Copied train.json to {LOCAL_DATASET_DIR / 'train.json'}\")\n",
        "\n",
        "configs[\"data\"][\"local_path\"] = str(LOCAL_DATASET_DIR.relative_to(ROOT_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import yaml\n",
        "\n",
        "TINY_TRAIN_SAMPLES = 8\n",
        "TINY_VAL_SAMPLES = 2\n",
        "MAX_TEXT_LENGTH_CHARS = 1500\n",
        "\n",
        "RAW_TRAIN_PATH = LOCAL_DATASET_DIR / \"train.json\"\n",
        "TINY_DATA_DIR = ROOT_DIR / \"dataset_tiny\"\n",
        "TINY_TRAIN_PATH = TINY_DATA_DIR / \"train.json\"\n",
        "TINY_VAL_PATH = TINY_DATA_DIR / \"validation.json\"\n",
        "\n",
        "if not RAW_TRAIN_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Raw train.json not found at {RAW_TRAIN_PATH}\")\n",
        "\n",
        "with RAW_TRAIN_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
        "    full_train = json.load(f)\n",
        "\n",
        "if not isinstance(full_train, list) or not full_train:\n",
        "    raise ValueError(\"Expected train.json to be a non-empty list of samples\")\n",
        "\n",
        "TINY_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "short_samples = [\n",
        "    sample for sample in full_train\n",
        "    if isinstance(sample.get(\"text\", \"\"), str) and len(sample.get(\"text\", \"\")) <= MAX_TEXT_LENGTH_CHARS\n",
        "]\n",
        "\n",
        "required_samples = TINY_TRAIN_SAMPLES + TINY_VAL_SAMPLES\n",
        "if len(short_samples) < required_samples:\n",
        "    raise ValueError(\n",
        "        f\"Not enough short samples (<= {MAX_TEXT_LENGTH_CHARS} chars). \"\n",
        "        f\"Found {len(short_samples)}, need at least {required_samples}.\"\n",
        "    )\n",
        "\n",
        "train_slice = short_samples[:TINY_TRAIN_SAMPLES]\n",
        "val_slice = short_samples[TINY_TRAIN_SAMPLES:required_samples]\n",
        "\n",
        "with TINY_TRAIN_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(train_slice, f, ensure_ascii=False, indent=2)\n",
        "with TINY_VAL_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(val_slice, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✓ Created tiny train ({len(train_slice)} samples) at {TINY_TRAIN_PATH}\")\n",
        "print(f\"✓ Created tiny validation ({len(val_slice)} samples) at {TINY_VAL_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TINY_CONFIG_PATH = CONFIG_DIR / \"data\" / \"resume_tiny.yaml\"\n",
        "BASE_CONFIG_PATH = CONFIG_DIR / \"data\" / \"resume_v1.yaml\"\n",
        "\n",
        "if BASE_CONFIG_PATH.exists():\n",
        "    with BASE_CONFIG_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        base_cfg = yaml.safe_load(f)\n",
        "    \n",
        "    base_cfg[\"name\"] = \"resume-ner-data-tiny-short\"\n",
        "    base_cfg[\"version\"] = \"v2\"\n",
        "    base_cfg[\"local_path\"] = str(TINY_DATA_DIR.relative_to(ROOT_DIR))\n",
        "    base_cfg[\"description\"] = \"Tiny smoke-test subset of Resume NER dataset (short-text version for fast orchestration tests)\"\n",
        "    \n",
        "    with TINY_CONFIG_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        yaml.safe_dump(base_cfg, f, sort_keys=False)\n",
        "    \n",
        "    print(f\"✓ Updated tiny data config at {TINY_CONFIG_PATH}\")\n",
        "\n",
        "DATASET_PATH = str(TINY_DATA_DIR)\n",
        "print(f\"Using dataset path: {DATASET_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "LOCAL_REQUIRED_PACKAGES = [\"kagglehub\", \"optuna\", \"mlflow\"]\n",
        "CONDA_YAML_PATH = CONFIG_DIR / \"environment\" / \"conda.yaml\"\n",
        "\n",
        "if not CONDA_YAML_PATH.exists():\n",
        "    print(\"Warning: conda.yaml not found, skipping dependency installation\")\n",
        "else:\n",
        "    with open(CONDA_YAML_PATH, \"r\") as f:\n",
        "        conda_config = yaml.safe_load(f)\n",
        "    \n",
        "    pip_deps = []\n",
        "    for dep in conda_config.get(\"dependencies\", []):\n",
        "        if isinstance(dep, dict) and \"pip\" in dep:\n",
        "            pip_deps = dep[\"pip\"]\n",
        "            break\n",
        "    \n",
        "    pip_deps.extend(LOCAL_REQUIRED_PACKAGES)\n",
        "    \n",
        "    print(\"Installing dependencies...\")\n",
        "    for dep in pip_deps:\n",
        "        if dep and not dep.startswith(\"#\"):\n",
        "            try:\n",
        "                subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep], \n",
        "                             check=False, capture_output=True)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not install {dep}: {e}\")\n",
        "    \n",
        "    print(\"✓ Dependencies installed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"✓ GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"  GPU count: {torch.cuda.device_count()}\")\n",
        "else:\n",
        "    print(\"⚠️  No GPU available. Training will use CPU (will be slow).\")\n",
        "    if IN_COLAB:\n",
        "        print(\"  In Colab, make sure Runtime > Change runtime type > Hardware accelerator = GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "MLFLOW_TRACKING_DIR = ROOT_DIR / \"mlruns\"\n",
        "MLFLOW_TRACKING_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "mlflow.set_tracking_uri(f\"file://{MLFLOW_TRACKING_DIR}\")\n",
        "mlflow.set_experiment(experiment_config.name)\n",
        "\n",
        "print(f\"✓ MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "print(f\"✓ MLflow experiment: {experiment_config.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step P1-3.4: The Dry Run\n",
        "\n",
        "Run a minimal training job to validate the pipeline before launching HPO.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Dry run configuration\n",
        "DRY_RUN_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"dry_run\"\n",
        "DRY_RUN_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Get backbone from HPO config\n",
        "backbone = configs[\"hpo\"][\"search_space\"][\"backbone\"][\"values\"][0]\n",
        "print(f\"Running dry run with backbone: {backbone}\")\n",
        "\n",
        "# Build training command\n",
        "train_script = ROOT_DIR / \"src\" / \"train.py\"\n",
        "args = [\n",
        "    sys.executable,\n",
        "    str(train_script),\n",
        "    \"--data-asset\", DATASET_PATH,\n",
        "    \"--config-dir\", str(CONFIG_DIR),\n",
        "    \"--backbone\", backbone,\n",
        "    \"--epochs\", \"1\",  # Single epoch for dry run\n",
        "    \"--batch-size\", \"4\",  # Small batch for dry run\n",
        "]\n",
        "\n",
        "# Set output directory via environment variable\n",
        "env = os.environ.copy()\n",
        "env[\"AZURE_ML_OUTPUT_checkpoint\"] = str(DRY_RUN_OUTPUT_DIR)\n",
        "\n",
        "print(\"Starting dry run training...\")\n",
        "print(f\"Command: {' '.join(args)}\")\n",
        "\n",
        "result = subprocess.run(\n",
        "    args,\n",
        "    cwd=ROOT_DIR,\n",
        "    env=env,\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        ")\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(f\"❌ Dry run failed with return code {result.returncode}\")\n",
        "    print(f\"STDOUT:\\n{result.stdout}\")\n",
        "    print(f\"STDERR:\\n{result.stderr}\")\n",
        "    raise RuntimeError(\"Dry run training failed\")\n",
        "else:\n",
        "    print(\"✓ Dry run completed successfully\")\n",
        "    print(f\"Checkpoint saved to: {DRY_RUN_OUTPUT_DIR}\")\n",
        "    \n",
        "    # Verify checkpoint exists\n",
        "    checkpoint_dir = DRY_RUN_OUTPUT_DIR / \"checkpoint\"\n",
        "    if checkpoint_dir.exists():\n",
        "        print(f\"✓ Checkpoint directory found: {checkpoint_dir}\")\n",
        "    else:\n",
        "        print(f\"⚠️  Warning: Checkpoint directory not found at {checkpoint_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step P1-3.5: The Sweep (HPO) - Local with Optuna\n",
        "\n",
        "Run hyperparameter optimization using Optuna for local execution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from orchestration.jobs.local_sweeps import run_local_hpo_sweep\n",
        "from orchestration.jobs.local_selection import select_best_configuration_across_studies\n",
        "import optuna\n",
        "\n",
        "# HPO configuration\n",
        "hpo_config = configs[\"hpo\"]\n",
        "backbone_values = hpo_config[\"search_space\"][\"backbone\"][\"values\"]\n",
        "\n",
        "# Output directory for HPO trials\n",
        "HPO_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"hpo\"\n",
        "HPO_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# MLflow experiment name for HPO\n",
        "mlflow_experiment_name = f\"{experiment_config.name}_hpo\"\n",
        "\n",
        "print(f\"Starting HPO sweep for backbones: {backbone_values}\")\n",
        "print(f\"Max trials: {hpo_config['sampling']['max_trials']}\")\n",
        "print(f\"Timeout: {hpo_config['sampling']['timeout_minutes']} minutes\")\n",
        "\n",
        "# Run HPO for each backbone\n",
        "hpo_studies = {}\n",
        "\n",
        "for backbone in backbone_values:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running HPO for backbone: {backbone}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    study = run_local_hpo_sweep(\n",
        "        dataset_path=DATASET_PATH,\n",
        "        config_dir=CONFIG_DIR,\n",
        "        backbone=backbone,\n",
        "        hpo_config=hpo_config,\n",
        "        train_config=configs[\"train\"],\n",
        "        output_dir=HPO_OUTPUT_DIR / backbone,\n",
        "        mlflow_experiment_name=mlflow_experiment_name,\n",
        "    )\n",
        "    \n",
        "    hpo_studies[backbone] = study\n",
        "    \n",
        "    print(f\"\\n✓ Completed HPO for {backbone}\")\n",
        "    print(f\"  Best trial: {study.best_trial.number}\")\n",
        "    print(f\"  Best value: {study.best_value:.4f}\")\n",
        "    print(f\"  Best params: {study.best_params}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"HPO completed for all backbones\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step P1-3.6: Best Configuration Selection (Automated)\n",
        "\n",
        "Select the best configuration across all HPO studies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select best configuration across all studies\n",
        "best_configuration = select_best_configuration_across_studies(\n",
        "    studies=hpo_studies,\n",
        "    hpo_config=hpo_config,\n",
        "    dataset_version=configs[\"data\"][\"version\"],\n",
        ")\n",
        "\n",
        "print(\"✓ Best configuration selected:\")\n",
        "print(f\"  Backbone: {best_configuration['backbone']}\")\n",
        "print(f\"  Best metric value: {best_configuration['selection_criteria']['best_value']:.4f}\")\n",
        "print(f\"  Hyperparameters: {best_configuration['hyperparameters']}\")\n",
        "\n",
        "# Save best configuration\n",
        "best_config_cache_file = ROOT_DIR / \"notebooks\" / \"best_configuration_cache.json\"\n",
        "save_json(best_config_cache_file, best_configuration)\n",
        "print(f\"✓ Saved best configuration to {best_config_cache_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_script = ROOT_DIR / \"src\" / \"train.py\"\n",
        "args = [\n",
        "    sys.executable,\n",
        "    str(train_script),\n",
        "    \"--data-asset\", DATASET_PATH,\n",
        "    \"--config-dir\", str(CONFIG_DIR),\n",
        "    \"--backbone\", final_training_config[\"backbone\"],\n",
        "    \"--learning-rate\", str(final_training_config[\"learning_rate\"]),\n",
        "    \"--batch-size\", str(final_training_config[\"batch_size\"]),\n",
        "    \"--dropout\", str(final_training_config[\"dropout\"]),\n",
        "    \"--weight-decay\", str(final_training_config[\"weight_decay\"]),\n",
        "    \"--epochs\", str(final_training_config[\"epochs\"]),\n",
        "    \"--random-seed\", str(final_training_config[\"random_seed\"]),\n",
        "    \"--early-stopping-enabled\", str(final_training_config[\"early_stopping_enabled\"]).lower(),\n",
        "    \"--use-combined-data\", str(final_training_config[\"use_combined_data\"]).lower(),\n",
        "]\n",
        "\n",
        "env = os.environ.copy()\n",
        "env[\"AZURE_ML_OUTPUT_checkpoint\"] = str(FINAL_TRAINING_OUTPUT_DIR)\n",
        "\n",
        "print(\"Starting final training...\")\n",
        "print(f\"Command: {' '.join(args)}\")\n",
        "\n",
        "result = subprocess.run(\n",
        "    args,\n",
        "    cwd=ROOT_DIR,\n",
        "    env=env,\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        ")\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(f\"❌ Final training failed with return code {result.returncode}\")\n",
        "    print(f\"STDOUT:\\n{result.stdout}\")\n",
        "    print(f\"STDERR:\\n{result.stderr}\")\n",
        "    raise RuntimeError(\"Final training failed\")\n",
        "\n",
        "print(\"✓ Final training completed successfully\")\n",
        "print(f\"Checkpoint saved to: {FINAL_TRAINING_OUTPUT_DIR}\")\n",
        "\n",
        "checkpoint_dir = FINAL_TRAINING_OUTPUT_DIR / \"checkpoint\"\n",
        "if checkpoint_dir.exists():\n",
        "    FINAL_CHECKPOINT_PATH = checkpoint_dir\n",
        "elif (FINAL_TRAINING_OUTPUT_DIR / \"pytorch_model.bin\").exists():\n",
        "    FINAL_CHECKPOINT_PATH = FINAL_TRAINING_OUTPUT_DIR\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Checkpoint not found in {FINAL_TRAINING_OUTPUT_DIR}\")\n",
        "\n",
        "print(f\"✓ Checkpoint directory found: {FINAL_CHECKPOINT_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step P1-3.7: Final Training (Post-HPO, Single Run)\n",
        "\n",
        "Train the final production model using the best configuration from HPO.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from orchestration.jobs.training import build_final_training_config\n",
        "\n",
        "# Build final training config from best HPO result\n",
        "final_training_config = build_final_training_config(\n",
        "    best_configuration,\n",
        "    configs[\"train\"],\n",
        "    random_seed=42,\n",
        ")\n",
        "\n",
        "print(\"Final training configuration:\")\n",
        "for key, value in final_training_config.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Output directory for final training\n",
        "FINAL_TRAINING_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"final_training\"\n",
        "FINAL_TRAINING_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Build training command\n",
        "args = [\n",
        "    sys.executable,\n",
        "    str(ROOT_DIR / \"src\" / \"train.py\"),\n",
        "    \"--data-asset\", DATASET_PATH,\n",
        "    \"--config-dir\", str(CONFIG_DIR),\n",
        "    \"--backbone\", final_training_config[\"backbone\"],\n",
        "    \"--learning-rate\", str(final_training_config[\"learning_rate\"]),\n",
        "    \"--batch-size\", str(final_training_config[\"batch_size\"]),\n",
        "    \"--dropout\", str(final_training_config[\"dropout\"]),\n",
        "    \"--weight-decay\", str(final_training_config[\"weight_decay\"]),\n",
        "    \"--epochs\", str(final_training_config[\"epochs\"]),\n",
        "    \"--random-seed\", str(final_training_config[\"random_seed\"]),\n",
        "    \"--early-stopping-enabled\", str(final_training_config[\"early_stopping_enabled\"]).lower(),\n",
        "    \"--use-combined-data\", str(final_training_config[\"use_combined_data\"]).lower(),\n",
        "]\n",
        "\n",
        "# Set output directory\n",
        "env = os.environ.copy()\n",
        "env[\"AZURE_ML_OUTPUT_checkpoint\"] = str(FINAL_TRAINING_OUTPUT_DIR)\n",
        "\n",
        "print(\"\\nStarting final training...\")\n",
        "print(f\"Command: {' '.join(args)}\")\n",
        "\n",
        "result = subprocess.run(\n",
        "    args,\n",
        "    cwd=ROOT_DIR,\n",
        "    env=env,\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        ")\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(f\"❌ Final training failed with return code {result.returncode}\")\n",
        "    print(f\"STDOUT:\\n{result.stdout}\")\n",
        "    print(f\"STDERR:\\n{result.stderr}\")\n",
        "    raise RuntimeError(\"Final training failed\")\n",
        "else:\n",
        "    print(\"✓ Final training completed successfully\")\n",
        "    print(f\"Checkpoint saved to: {FINAL_TRAINING_OUTPUT_DIR}\")\n",
        "    \n",
        "    # Verify checkpoint exists\n",
        "    checkpoint_dir = FINAL_TRAINING_OUTPUT_DIR / \"checkpoint\"\n",
        "    if checkpoint_dir.exists():\n",
        "        print(f\"✓ Checkpoint directory found: {checkpoint_dir}\")\n",
        "        FINAL_CHECKPOINT_PATH = checkpoint_dir\n",
        "    else:\n",
        "        # Try alternative location\n",
        "        if (FINAL_TRAINING_OUTPUT_DIR / \"pytorch_model.bin\").exists():\n",
        "            FINAL_CHECKPOINT_PATH = FINAL_TRAINING_OUTPUT_DIR\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Checkpoint not found in {FINAL_TRAINING_OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step P1-4: Model Conversion & Optimization\n",
        "\n",
        "Convert the final training checkpoint to an optimized ONNX model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Conversion output directory\n",
        "CONVERSION_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"onnx_model\"\n",
        "CONVERSION_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Build conversion command\n",
        "conversion_script = ROOT_DIR / \"src\" / \"convert_to_onnx.py\"\n",
        "args = [\n",
        "    sys.executable,\n",
        "    str(conversion_script),\n",
        "    \"--checkpoint-path\", str(FINAL_CHECKPOINT_PATH),\n",
        "    \"--config-dir\", str(CONFIG_DIR),\n",
        "    \"--backbone\", best_configuration[\"backbone\"],\n",
        "    \"--output-dir\", str(CONVERSION_OUTPUT_DIR),\n",
        "    \"--quantize-int8\",\n",
        "    \"--run-smoke-test\",\n",
        "]\n",
        "\n",
        "print(\"Starting model conversion...\")\n",
        "print(f\"Checkpoint: {FINAL_CHECKPOINT_PATH}\")\n",
        "print(f\"Output: {CONVERSION_OUTPUT_DIR}\")\n",
        "print(f\"Command: {' '.join(args)}\")\n",
        "\n",
        "result = subprocess.run(\n",
        "    args,\n",
        "    cwd=ROOT_DIR,\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        ")\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print(f\"❌ Conversion failed with return code {result.returncode}\")\n",
        "    print(f\"STDOUT:\\n{result.stdout}\")\n",
        "    print(f\"STDERR:\\n{result.stderr}\")\n",
        "    raise RuntimeError(\"Model conversion failed\")\n",
        "else:\n",
        "    print(\"✓ Model conversion completed successfully\")\n",
        "    \n",
        "    # Check for ONNX model\n",
        "    onnx_model_path = CONVERSION_OUTPUT_DIR / \"model_int8.onnx\"\n",
        "    if not onnx_model_path.exists():\n",
        "        onnx_model_path = CONVERSION_OUTPUT_DIR / \"model.onnx\"\n",
        "    \n",
        "    if onnx_model_path.exists():\n",
        "        print(f\"✓ ONNX model saved to: {onnx_model_path}\")\n",
        "        print(f\"  Model size: {onnx_model_path.stat().st_size / (1024*1024):.2f} MB\")\n",
        "    else:\n",
        "        print(f\"⚠️  Warning: ONNX model not found in {CONVERSION_OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "All steps completed successfully! The trained model has been converted to ONNX format and is ready for deployment.\n",
        "\n",
        "### Outputs:\n",
        "- **Final checkpoint**: `outputs/final_training/checkpoint/`\n",
        "- **ONNX model**: `outputs/onnx_model/model_int8.onnx` (or `model.onnx`)\n",
        "- **MLflow tracking**: `mlruns/` directory\n",
        "\n",
        "### Next Steps:\n",
        "- Review MLflow metrics and training logs\n",
        "- Test the ONNX model with sample inputs\n",
        "- Deploy the model for inference (Phase 2)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
