{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Local Training Orchestration (Google Colab Compatible)\n",
    "\n",
    "This notebook orchestrates all training activities for **local execution** with Google Colab GPU compute support.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Step 1**: Load Centralized Configs\n",
    "- **Step 2**: Verify Local Dataset (from data config)\n",
    "- **Step 3**: Setup Local Environment\n",
    "- **Step 4**: The Dry Run\n",
    "- **Step 5**: The Sweep (HPO) - Local with Optuna\n",
    "- **Step 6**: Best Configuration Selection (Automated)\n",
    "- **Step 7**: Final Training (Post-HPO, Single Run)\n",
    "- **Step 8**: Model Conversion & Optimization\n",
    "\n",
    "## Important\n",
    "\n",
    "- This notebook **executes training locally** (not on Azure ML)\n",
    "- All computation happens on the local machine or Google Colab GPU\n",
    "- The notebook must be **re-runnable end-to-end**\n",
    "- Uses the dataset path specified in the data config (from `config/data/*.yaml`), typically pointing to a local folder included in the repository (no external downloads needed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a local Conda environment\n",
    "\n",
    "\n",
    "### 1. Open a terminal in the project root\n",
    "\n",
    "In PowerShell:\n",
    "\n",
    "```powershell\n",
    "cd \"C:\\Users\\HOANG PHI LONG DANG\\repos\\resume-ner-azureml\"\n",
    "```\n",
    "\n",
    "### 2. Create the Conda environment from the project’s `conda.yaml`\n",
    "\n",
    "```powershell\n",
    "conda env create -f config\\environment\\conda.yaml\n",
    "```\n",
    "\n",
    "- This will create an environment named `resume-ner-training` (from the `name:` field in the YAML).\n",
    "- It installs Python 3.10, PyTorch, transformers, Azure ML SDK, etc.\n",
    "\n",
    "If Conda says the env already exists, use:\n",
    "\n",
    "```powershell\n",
    "conda env update -f config\\environment\\conda.yaml\n",
    "```\n",
    "\n",
    "### 3. Activate the environment\n",
    "\n",
    "```powershell\n",
    "conda activate resume-ner-training\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.1: Load Centralized Configs\n",
    "\n",
    "Load and validate all configuration files. Configs are immutable and will be logged with each job for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = \"COLAB_GPU\" in os.environ or \"COLAB_TPU\" in os.environ\n",
    "\n",
    "# Assume this notebook lives in `notebooks/` under the project root\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent\n",
    "SRC_DIR = ROOT_DIR / \"src\"\n",
    "CONFIG_DIR = ROOT_DIR / \"config\"\n",
    "\n",
    "sys.path.append(str(ROOT_DIR))\n",
    "sys.path.append(str(SRC_DIR))\n",
    "\n",
    "print(\"Notebook directory:\", NOTEBOOK_DIR)\n",
    "print(\"Project root:\", ROOT_DIR)\n",
    "print(\"Source directory:\", SRC_DIR)\n",
    "print(\"Config directory:\", CONFIG_DIR)\n",
    "print(\"In Colab:\", IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "\n",
    "from orchestration import EXPERIMENT_NAME\n",
    "from orchestration.config_loader import (\n",
    "    ExperimentConfig,\n",
    "    compute_config_hashes,\n",
    "    create_config_metadata,\n",
    "    load_all_configs,\n",
    "    load_experiment_config,\n",
    "    snapshot_configs,\n",
    "    validate_config_immutability,\n",
    ")\n",
    "\n",
    "# P1-3.1: Load Centralized Configs (local-only)\n",
    "# Mirrors the Azure orchestration notebook, but does not create an Azure ML client.\n",
    "\n",
    "if not CONFIG_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Config directory not found: {CONFIG_DIR}\")\n",
    "\n",
    "experiment_config: ExperimentConfig = load_experiment_config(CONFIG_DIR, EXPERIMENT_NAME)\n",
    "configs: Dict[str, Any] = load_all_configs(experiment_config)\n",
    "config_hashes = compute_config_hashes(configs)\n",
    "config_metadata = create_config_metadata(configs, config_hashes)\n",
    "\n",
    "# Immutable snapshots for runtime mutation checks\n",
    "original_configs = snapshot_configs(configs)\n",
    "validate_config_immutability(configs, original_configs)\n",
    "\n",
    "print(f\"Loaded experiment: {experiment_config.name}\")\n",
    "print(\"Loaded config domains:\", sorted(configs.keys()))\n",
    "print(\"Config hashes:\", config_hashes)\n",
    "print(\"Config metadata:\", config_metadata)\n",
    "\n",
    "# Get dataset path from data config (centralized configuration)\n",
    "# The local_path in the data config is relative to the config directory\n",
    "data_config = configs[\"data\"]\n",
    "local_path_str = data_config.get(\"local_path\", \"../dataset\")\n",
    "DATASET_LOCAL_PATH = (CONFIG_DIR / local_path_str).resolve()\n",
    "\n",
    "# Check if seed-based dataset structure (for dataset_tiny with seed subdirectories)\n",
    "seed = data_config.get(\"seed\")\n",
    "if seed is not None and \"dataset_tiny\" in str(DATASET_LOCAL_PATH):\n",
    "    DATASET_LOCAL_PATH = DATASET_LOCAL_PATH / f\"seed{seed}\"\n",
    "\n",
    "\n",
    "print(f\"Dataset path (from data config): {DATASET_LOCAL_PATH}\")\n",
    "if seed is not None:\n",
    "    print(f\"Using seed: {seed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use HPO config already loaded in configs (from Step P1-3.1)\n",
    "hpo_config = configs[\"hpo\"]\n",
    "train_config = configs[\"train\"]\n",
    "backbone_values = hpo_config[\"search_space\"][\"backbone\"][\"values\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.2: Verify Local Dataset\n",
    "\n",
    "Verify that the dataset directory (specified by `local_path` in the data config) exists and contains the required files. The dataset path is loaded from the centralized data configuration in Step P1-3.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1-3.2: Verify Local Dataset\n",
    "# The dataset path comes from the data config's local_path field (loaded in Step P1-3.1).\n",
    "# This ensures the dataset location is controlled by centralized configuration.\n",
    "# Note: train.json is required, but validation.json is optional (matches training script behavior).\n",
    "\n",
    "REQUIRED_FILE = \"train.json\"\n",
    "OPTIONAL_FILE = \"validation.json\"\n",
    "\n",
    "if not DATASET_LOCAL_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset directory not found: {DATASET_LOCAL_PATH}\\n\"\n",
    "        f\"This path comes from the data config's 'local_path' field.\\n\"\n",
    "        f\"If you need to create the dataset, run the notebook: notebooks/00_make_tiny_dataset.ipynb\"\n",
    "    )\n",
    "\n",
    "# Check required file\n",
    "train_file = DATASET_LOCAL_PATH / REQUIRED_FILE\n",
    "if not train_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Required dataset file not found: {train_file}\\n\"\n",
    "        f\"This path comes from the data config's 'local_path' field.\\n\"\n",
    "        f\"If you need to create it, run the notebook: notebooks/00_make_tiny_dataset.ipynb\"\n",
    "    )\n",
    "\n",
    "# Check optional file\n",
    "val_file = DATASET_LOCAL_PATH / OPTIONAL_FILE\n",
    "has_validation = val_file.exists()\n",
    "\n",
    "print(f\"✓ Dataset directory found: {DATASET_LOCAL_PATH}\")\n",
    "print(f\"  (from data config: {data_config.get('name', 'unknown')} v{data_config.get('version', 'unknown')})\")\n",
    "\n",
    "train_size = train_file.stat().st_size\n",
    "print(f\"  ✓ {REQUIRED_FILE} ({train_size:,} bytes)\")\n",
    "\n",
    "if has_validation:\n",
    "    val_size = val_file.stat().st_size\n",
    "    print(f\"  ✓ {OPTIONAL_FILE} ({val_size:,} bytes)\")\n",
    "else:\n",
    "    print(f\"  ⚠ {OPTIONAL_FILE} not found (optional - training will proceed without validation set)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.3: Setup Local Environment\n",
    "\n",
    "Verify GPU availability, set up MLflow tracking (local file store), and check that key dependencies are installed. This step ensures the local environment is ready for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "DEFAULT_DEVICE = \"cuda\"\n",
    "\n",
    "env_config = configs[\"env\"]\n",
    "device_type = env_config.get(\"compute\", {}).get(\"device\", DEFAULT_DEVICE)\n",
    "\n",
    "if device_type == \"cuda\" and not torch.cuda.is_available():\n",
    "    raise RuntimeError(\n",
    "        \"CUDA device requested but not available. \"\n",
    "        \"Set device to 'cpu' in env config or ensure CUDA is properly installed.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "MLFLOW_DIR = \"mlruns\"\n",
    "mlflow_tracking_path = ROOT_DIR / MLFLOW_DIR\n",
    "mlflow_tracking_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Convert Windows path to file:// URI format for MLflow\n",
    "mlflow_tracking_uri = mlflow_tracking_path.as_uri()\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "    import optuna\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"Required package not installed: {e}\")\n",
    "\n",
    "REQUIRED_PACKAGES = {\n",
    "    \"torch\": torch,\n",
    "    \"transformers\": transformers,\n",
    "    \"mlflow\": mlflow,\n",
    "    \"optuna\": optuna,\n",
    "}\n",
    "\n",
    "for name, module in REQUIRED_PACKAGES.items():\n",
    "    if not hasattr(module, \"__version__\"):\n",
    "        raise ImportError(f\"Required package '{name}' is not properly installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.4: The Dry Run\n",
    "\n",
    "Run a minimal HPO sweep to validate the training pipeline works correctly before launching the full HPO sweep. Uses the smoke HPO configuration with reduced trials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from orchestration import STAGE_SMOKE\n",
    "from orchestration.jobs.local_sweeps import run_local_hpo_sweep\n",
    "\n",
    "TRAINING_SCRIPT_PATH = SRC_DIR / \"train.py\"\n",
    "DRY_RUN_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"dry_run\"\n",
    "\n",
    "if not TRAINING_SCRIPT_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Training script not found: {TRAINING_SCRIPT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_config = configs[\"hpo\"]\n",
    "train_config = configs[\"train\"]\n",
    "backbone_values = hpo_config[\"search_space\"][\"backbone\"][\"values\"]\n",
    "\n",
    "dry_run_studies = {}\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    mlflow_experiment_name = f\"{experiment_config.name}-{STAGE_SMOKE}-{backbone}\"\n",
    "    backbone_output_dir = DRY_RUN_OUTPUT_DIR / backbone\n",
    "    \n",
    "    study = run_local_hpo_sweep(\n",
    "        dataset_path=str(DATASET_LOCAL_PATH),\n",
    "        config_dir=CONFIG_DIR,\n",
    "        backbone=backbone,\n",
    "        hpo_config=hpo_config,\n",
    "        train_config=train_config,\n",
    "        output_dir=backbone_output_dir,\n",
    "        mlflow_experiment_name=mlflow_experiment_name,\n",
    "    )\n",
    "    \n",
    "    dry_run_studies[backbone] = study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for backbone, study in dry_run_studies.items():\n",
    "    if study.trials:\n",
    "        best_trial = study.best_trial\n",
    "        print(f\"{backbone}: {len(study.trials)} trials completed\")\n",
    "        print(\n",
    "            f\"  Best {hpo_config['objective']['metric']}: {best_trial.value:.4f}\")\n",
    "        print(f\"  Best params: {best_trial.params}\")\n",
    "    else:\n",
    "        print(f\"{backbone}: No trials completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.5: The Sweep (HPO) - Local with Optuna\n",
    "\n",
    "Run the full hyperparameter optimization sweep using Optuna to systematically search for the best model configuration. Uses the production HPO configuration with more trials than the dry run.\n",
    "\n",
    "**Note on K-Fold Cross-Validation:**\n",
    "- When k-fold CV is enabled (`k_fold.enabled: true`), each trial trains **k models** (one per fold) and returns the **average metric** across folds\n",
    "- The number of **trials** is controlled by `sampling.max_trials` (e.g., 2 trials in smoke.yaml)\n",
    "- With k=5 folds and 2 trials: **2 trials × 5 folds = 10 model trainings total**\n",
    "- K-fold CV provides more robust hyperparameter evaluation but increases compute time (k× per trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from orchestration import STAGE_HPO\n",
    "from shared.yaml_utils import load_yaml\n",
    "from orchestration.jobs.local_sweeps import run_local_hpo_sweep\n",
    "\n",
    "DEFAULT_K_FOLDS = 5\n",
    "DEFAULT_RANDOM_SEED = 42\n",
    "HPO_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"hpo\"\n",
    "\n",
    "hpo_stage_config = experiment_config.stages.get(STAGE_HPO, {})\n",
    "hpo_config_override = hpo_stage_config.get(\"hpo_config\")\n",
    "hpo_config_path = CONFIG_DIR / hpo_config_override if hpo_config_override else experiment_config.hpo_config\n",
    "\n",
    "if not hpo_config_path.exists():\n",
    "    raise FileNotFoundError(f\"HPO config not found: {hpo_config_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_config = load_yaml(hpo_config_path)\n",
    "train_config = configs[\"train\"]\n",
    "backbone_values = hpo_config[\"search_space\"][\"backbone\"][\"values\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.cv_utils import create_kfold_splits, save_fold_splits\n",
    "from training.data import load_dataset\n",
    "\n",
    "k_fold_config = hpo_config.get(\"k_fold\", {})\n",
    "k_folds_enabled = k_fold_config.get(\"enabled\", False)\n",
    "fold_splits_file = None\n",
    "\n",
    "if k_folds_enabled:\n",
    "    n_splits = k_fold_config.get(\"n_splits\", DEFAULT_K_FOLDS)\n",
    "    random_seed = k_fold_config.get(\"random_seed\", DEFAULT_RANDOM_SEED)\n",
    "    shuffle = k_fold_config.get(\"shuffle\", True)\n",
    "    \n",
    "    full_dataset = load_dataset(str(DATASET_LOCAL_PATH))\n",
    "    train_data = full_dataset.get(\"train\", [])\n",
    "    \n",
    "    fold_splits = create_kfold_splits(\n",
    "        dataset=train_data,\n",
    "        k=n_splits,\n",
    "        random_seed=random_seed,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    \n",
    "    fold_splits_file = HPO_OUTPUT_DIR / \"fold_splits.json\"\n",
    "    save_fold_splits(\n",
    "        fold_splits,\n",
    "        fold_splits_file,\n",
    "        metadata={\n",
    "            \"k\": n_splits,\n",
    "            \"random_seed\": random_seed,\n",
    "            \"shuffle\": shuffle,\n",
    "            \"dataset_path\": str(DATASET_LOCAL_PATH),\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlflow_experiment_name(experiment_name: str, stage: str, backbone: str) -> str:\n",
    "    return f\"{experiment_name}-{stage}-{backbone}\"\n",
    "\n",
    "hpo_studies = {}\n",
    "k_folds_param = k_fold_config.get(\"n_splits\", DEFAULT_K_FOLDS) if k_folds_enabled else None\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    mlflow_experiment_name = build_mlflow_experiment_name(\n",
    "        experiment_config.name, STAGE_HPO, backbone\n",
    "    )\n",
    "    backbone_output_dir = HPO_OUTPUT_DIR / backbone\n",
    "    \n",
    "    study = run_local_hpo_sweep(\n",
    "        dataset_path=str(DATASET_LOCAL_PATH),\n",
    "        config_dir=CONFIG_DIR,\n",
    "        backbone=backbone,\n",
    "        hpo_config=hpo_config,\n",
    "        train_config=train_config,\n",
    "        output_dir=backbone_output_dir,\n",
    "        mlflow_experiment_name=mlflow_experiment_name,\n",
    "        k_folds=k_folds_param,\n",
    "        fold_splits_file=fold_splits_file,\n",
    "    )\n",
    "    \n",
    "    hpo_studies[backbone] = study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cv_statistics(best_trial):\n",
    "    if not hasattr(best_trial, \"user_attrs\"):\n",
    "        return None\n",
    "    cv_mean = best_trial.user_attrs.get(\"cv_mean\")\n",
    "    cv_std = best_trial.user_attrs.get(\"cv_std\")\n",
    "    return (cv_mean, cv_std) if cv_mean is not None else None\n",
    "\n",
    "objective_metric = hpo_config['objective']['metric']\n",
    "\n",
    "for backbone, study in hpo_studies.items():\n",
    "    if not study.trials:\n",
    "        continue\n",
    "    \n",
    "    best_trial = study.best_trial\n",
    "    cv_stats = extract_cv_statistics(best_trial)\n",
    "    \n",
    "    print(f\"{backbone}: {len(study.trials)} trials completed\")\n",
    "    print(f\"  Best {objective_metric}: {best_trial.value:.4f}\")\n",
    "    print(f\"  Best params: {best_trial.params}\")\n",
    "    \n",
    "    if cv_stats:\n",
    "        cv_mean, cv_std = cv_stats\n",
    "        print(f\"  CV Statistics: Mean: {cv_mean:.4f} ± {cv_std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.6: Best Configuration Selection (Automated)\n",
    "\n",
    "Programmatically select the best configuration from all HPO sweep runs across all backbone models. The best configuration is determined by the objective metric specified in the HPO config.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from shared.json_cache import save_json\n",
    "from orchestration.jobs.local_selection import select_best_configuration_across_studies\n",
    "\n",
    "BEST_CONFIG_CACHE_FILE = ROOT_DIR / \"notebooks\" / \"best_configuration_cache.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_version = data_config.get(\"version\", \"unknown\")\n",
    "\n",
    "best_configuration = select_best_configuration_across_studies(\n",
    "    studies=hpo_studies,\n",
    "    hpo_config=hpo_config,\n",
    "    dataset_version=dataset_version,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(BEST_CONFIG_CACHE_FILE, best_configuration)\n",
    "\n",
    "print(f\"Best configuration selected:\")\n",
    "print(f\"  Backbone: {best_configuration.get('backbone')}\")\n",
    "print(f\"  Trial: {best_configuration.get('trial_name')}\")\n",
    "print(f\"  Best {hpo_config['objective']['metric']}: {best_configuration.get('selection_criteria', {}).get('best_value'):.4f}\")\n",
    "print(f\"  Hyperparameters: {best_configuration.get('hyperparameters')}\")\n",
    "print(f\"\\nSaved to: {BEST_CONFIG_CACHE_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.7: Final Training (Post-HPO, Single Run)\n",
    "\n",
    "Train the final production model using the best configuration from HPO with stable, controlled conditions. This uses the full training epochs (no early stopping) and the best hyperparameters found during HPO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import mlflow\n",
    "from shared.json_cache import load_json, save_json\n",
    "from orchestration import STAGE_TRAINING\n",
    "from orchestration.jobs.training import build_final_training_config\n",
    "\n",
    "DEFAULT_RANDOM_SEED = 42\n",
    "BEST_CONFIG_CACHE_FILE = ROOT_DIR / \"notebooks\" / \"best_configuration_cache.json\"\n",
    "FINAL_TRAINING_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"final_training\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_configuration = load_json(BEST_CONFIG_CACHE_FILE, default=None)\n",
    "\n",
    "if best_configuration is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Best configuration cache not found: {BEST_CONFIG_CACHE_FILE}\\n\"\n",
    "        f\"Please run Step P1-3.6: Best Configuration Selection first.\"\n",
    "    )\n",
    "\n",
    "final_training_config = build_final_training_config(\n",
    "    best_config=best_configuration,\n",
    "    train_config=configs[\"train\"],\n",
    "    random_seed=DEFAULT_RANDOM_SEED,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_experiment_name = f\"{experiment_config.name}-{STAGE_TRAINING}-{final_training_config['backbone']}\"\n",
    "final_output_dir = FINAL_TRAINING_OUTPUT_DIR / final_training_config['backbone']\n",
    "final_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mlflow.set_experiment(mlflow_experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_script_path = SRC_DIR / \"train.py\"\n",
    "training_args = [\n",
    "    sys.executable,\n",
    "    str(training_script_path),\n",
    "    \"--data-asset\",\n",
    "    str(DATASET_LOCAL_PATH),\n",
    "    \"--config-dir\",\n",
    "    str(CONFIG_DIR),\n",
    "    \"--backbone\",\n",
    "    final_training_config[\"backbone\"],\n",
    "    \"--learning-rate\",\n",
    "    str(final_training_config[\"learning_rate\"]),\n",
    "    \"--batch-size\",\n",
    "    str(final_training_config[\"batch_size\"]),\n",
    "    \"--dropout\",\n",
    "    str(final_training_config[\"dropout\"]),\n",
    "    \"--weight-decay\",\n",
    "    str(final_training_config[\"weight_decay\"]),\n",
    "    \"--epochs\",\n",
    "    str(final_training_config[\"epochs\"]),\n",
    "    \"--random-seed\",\n",
    "    str(final_training_config[\"random_seed\"]),\n",
    "    \"--early-stopping-enabled\",\n",
    "    str(final_training_config[\"early_stopping_enabled\"]).lower(),\n",
    "    \"--use-combined-data\",\n",
    "    str(final_training_config[\"use_combined_data\"]).lower(),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_env = os.environ.copy()\n",
    "training_env[\"AZURE_ML_OUTPUT_checkpoint\"] = str(final_output_dir)\n",
    "\n",
    "mlflow_tracking_uri = mlflow.get_tracking_uri()\n",
    "if mlflow_tracking_uri:\n",
    "    training_env[\"MLFLOW_TRACKING_URI\"] = mlflow_tracking_uri\n",
    "training_env[\"MLFLOW_EXPERIMENT_NAME\"] = mlflow_experiment_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(\n",
    "    training_args,\n",
    "    cwd=ROOT_DIR,\n",
    "    env=training_env,\n",
    "    capture_output=False,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "if result.returncode != 0:\n",
    "    raise RuntimeError(f\"Final training failed with return code {result.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "METRICS_FILENAME = \"metrics.json\"\n",
    "FINAL_TRAINING_CACHE_FILE = ROOT_DIR / \"notebooks\" / \"final_training_cache.json\"\n",
    "\n",
    "metrics_file = final_output_dir / METRICS_FILENAME\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "    print(f\"✓ Training completed. Checkpoint: {final_output_dir}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Training metrics not found: {metrics_file}\")\n",
    "\n",
    "save_json(FINAL_TRAINING_CACHE_FILE, {\n",
    "    \"output_dir\": str(final_output_dir),\n",
    "    \"backbone\": final_training_config[\"backbone\"],\n",
    "    \"config\": final_training_config,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-4: Model Conversion & Optimization\n",
    "\n",
    "Convert the final training checkpoint to an optimized ONNX model (int8 quantized) for production inference.\n",
    "\n",
    "**Platform Adapter Note**: The conversion script (`src/convert_to_onnx.py`) uses the platform adapter to automatically handle output paths and logging appropriately for local execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import mlflow\n",
    "from shared.json_cache import load_json\n",
    "\n",
    "CONVERSION_SCRIPT_PATH = SRC_DIR / \"convert_to_onnx.py\"\n",
    "FINAL_TRAINING_CACHE_FILE = ROOT_DIR / \"notebooks\" / \"final_training_cache.json\"\n",
    "CONVERSION_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"conversion\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cache = load_json(FINAL_TRAINING_CACHE_FILE, default=None)\n",
    "\n",
    "if training_cache is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Final training cache not found: {FINAL_TRAINING_CACHE_FILE}\\n\"\n",
    "        f\"Please run Step P1-3.7: Final Training first.\"\n",
    "    )\n",
    "\n",
    "checkpoint_dir = Path(training_cache[\"output_dir\"]) / \"checkpoint\"\n",
    "if not checkpoint_dir.exists():\n",
    "    raise FileNotFoundError(f\"Checkpoint directory not found: {checkpoint_dir}\")\n",
    "\n",
    "backbone = training_cache[\"backbone\"]\n",
    "conversion_output_dir = CONVERSION_OUTPUT_DIR / backbone\n",
    "conversion_output_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_args = [\n",
    "    sys.executable,\n",
    "    str(CONVERSION_SCRIPT_PATH),\n",
    "    \"--checkpoint-path\",\n",
    "    str(checkpoint_dir),\n",
    "    \"--config-dir\",\n",
    "    str(CONFIG_DIR),\n",
    "    \"--backbone\",\n",
    "    backbone,\n",
    "    \"--output-dir\",\n",
    "    str(conversion_output_dir),\n",
    "    \"--quantize-int8\",\n",
    "    \"--run-smoke-test\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_env = os.environ.copy()\n",
    "conversion_env[\"AZURE_ML_OUTPUT_onnx_model\"] = str(conversion_output_dir)\n",
    "\n",
    "mlflow_tracking_uri = mlflow.get_tracking_uri()\n",
    "if mlflow_tracking_uri:\n",
    "    conversion_env[\"MLFLOW_TRACKING_URI\"] = mlflow_tracking_uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(\n",
    "    conversion_args,\n",
    "    cwd=ROOT_DIR,\n",
    "    env=conversion_env,\n",
    "    capture_output=False,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "if result.returncode != 0:\n",
    "    raise RuntimeError(f\"Model conversion failed with return code {result.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.json_cache import save_json\n",
    "\n",
    "ONNX_MODEL_FILENAME = \"model_int8.onnx\"\n",
    "FALLBACK_ONNX_MODEL_FILENAME = \"model.onnx\"\n",
    "CONVERSION_CACHE_FILE = ROOT_DIR / \"notebooks\" / \"conversion_cache.json\"\n",
    "\n",
    "onnx_model_path = conversion_output_dir / ONNX_MODEL_FILENAME\n",
    "if not onnx_model_path.exists():\n",
    "    onnx_model_path = conversion_output_dir / FALLBACK_ONNX_MODEL_FILENAME\n",
    "\n",
    "if not onnx_model_path.exists():\n",
    "    raise FileNotFoundError(f\"ONNX model not found in {conversion_output_dir}\")\n",
    "\n",
    "print(f\"✓ Conversion completed. ONNX model: {onnx_model_path}\")\n",
    "\n",
    "save_json(CONVERSION_CACHE_FILE, {\n",
    "    \"onnx_model_path\": str(onnx_model_path),\n",
    "    \"backbone\": backbone,\n",
    "    \"checkpoint_dir\": str(checkpoint_dir),\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
