{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# API Testing Notebook - Entity Extraction from Real Files\n",
        "\n",
        "This notebook tests the Resume NER API with actual test files and visualizes extracted entities.\n",
        "\n",
        "**Note:** This notebook focuses on testing real files and visualizing results. For comprehensive error handling and edge case testing, see the integration tests in `tests/integration/api/test_api_local_server.py`.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before running this notebook, start the API server with:\n",
        "\n",
        "```bash\n",
        "python -m src.api.cli.run_api \\\n",
        "  --onnx-model outputs/final_training/distilroberta/distilroberta_model.onnx \\\n",
        "  --checkpoint outputs/final_training/distilroberta/checkpoint\n",
        "```\n",
        "\n",
        "The server should be running on `http://localhost:8000` by default.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import time\n",
        "from typing import Dict, Any, Optional, List\n",
        "import requests\n",
        "from IPython.display import display, Markdown, JSON\n",
        "import pandas as pd\n",
        "\n",
        "# Add project root to path to import fixtures\n",
        "# Find project root by looking for tests directory\n",
        "current_dir = Path.cwd()\n",
        "project_root = current_dir\n",
        "\n",
        "# If we're in notebooks/, go up one level\n",
        "if current_dir.name == \"notebooks\":\n",
        "    project_root = current_dir.parent\n",
        "else:\n",
        "    # Try to find project root by looking for tests directory\n",
        "    for parent in current_dir.parents:\n",
        "        if (parent / \"tests\" / \"test_data\").exists():\n",
        "            project_root = parent\n",
        "            break\n",
        "\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Import test fixtures\n",
        "from tests.test_data.fixtures import (\n",
        "    get_text_fixture,\n",
        "    get_file_fixture,\n",
        "    get_batch_text_fixture,\n",
        "    get_batch_file_fixture,\n",
        "    TEXT_FIXTURES,\n",
        "    FILE_FIXTURES\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# API Configuration\n",
        "API_BASE_URL = \"http://localhost:8000\"\n",
        "API_TIMEOUT = 30  # seconds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Server is healthy and ready\n",
            "  Status: ok\n",
            "  Model loaded: True\n"
          ]
        }
      ],
      "source": [
        "def make_request(method: str, endpoint: str, **kwargs) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Make HTTP request to API and return response data.\n",
        "    \n",
        "    Args:\n",
        "        method: HTTP method (GET, POST)\n",
        "        endpoint: API endpoint path\n",
        "        **kwargs: Additional arguments for requests\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with status_code, data, latency_ms, and error (if any)\n",
        "    \"\"\"\n",
        "    url = f\"{API_BASE_URL}{endpoint}\"\n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        if method.upper() == \"GET\":\n",
        "            response = requests.get(url, timeout=API_TIMEOUT, **kwargs)\n",
        "        elif method.upper() == \"POST\":\n",
        "            response = requests.post(url, timeout=API_TIMEOUT, **kwargs)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported method: {method}\")\n",
        "        \n",
        "        latency_ms = (time.time() - start_time) * 1000\n",
        "        \n",
        "        result = {\n",
        "            \"status_code\": response.status_code,\n",
        "            \"latency_ms\": latency_ms,\n",
        "            \"error\": None\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            result[\"data\"] = response.json()\n",
        "        except:\n",
        "            result[\"data\"] = {\"text\": response.text}\n",
        "        \n",
        "        return result\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        latency_ms = (time.time() - start_time) * 1000\n",
        "        return {\n",
        "            \"status_code\": None,\n",
        "            \"latency_ms\": latency_ms,\n",
        "            \"data\": None,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "def check_server_health() -> bool:\n",
        "    \"\"\"Check if server is running and healthy.\"\"\"\n",
        "    try:\n",
        "        result = make_request(\"GET\", \"/health\")\n",
        "        if result[\"status_code\"] == 200:\n",
        "            print(\"✓ Server is healthy and ready\")\n",
        "            print(f\"  Status: {result['data'].get('status', 'unknown')}\")\n",
        "            print(f\"  Model loaded: {result['data'].get('model_loaded', False)}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"✗ Server health check failed: {result['status_code']}\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Cannot connect to server: {e}\")\n",
        "        print(f\"  Make sure the server is running on {API_BASE_URL}\")\n",
        "        return False\n",
        "\n",
        "# Check server health\n",
        "if not check_server_health():\n",
        "    print(\"\\n⚠️  Please start the server before continuing!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_entities(entities: List[Dict[str, Any]], source_text: Optional[str] = None):\n",
        "    \"\"\"Display extracted entities in a formatted way.\"\"\"\n",
        "    if not entities:\n",
        "        return\n",
        "    \n",
        "    # Group by label\n",
        "    by_label = {}\n",
        "    for entity in entities:\n",
        "        label = entity.get(\"label\", \"UNKNOWN\")\n",
        "        if label not in by_label:\n",
        "            by_label[label] = []\n",
        "        by_label[label].append(entity)\n",
        "    \n",
        "    # Display by label\n",
        "    for label, label_entities in sorted(by_label.items()):\n",
        "        print(f\"{label} ({len(label_entities)}):\")\n",
        "        for entity in label_entities:\n",
        "            text = entity.get(\"text\", \"\")\n",
        "            confidence = entity.get(\"confidence\")\n",
        "            conf_str = f\" (confidence: {confidence:.3f})\" if confidence else \"\"\n",
        "            print(f\"  - '{text}'{conf_str}\")\n",
        "    \n",
        "    # Show entities in context if source_text provided\n",
        "    if source_text:\n",
        "        highlighted_text = source_text\n",
        "        sorted_entities = sorted(entities, key=lambda e: e.get(\"start\", 0), reverse=True)\n",
        "        for entity in sorted_entities:\n",
        "            start = entity.get(\"start\", 0)\n",
        "            end = entity.get(\"end\", 0)\n",
        "            text = entity.get(\"text\", \"\")\n",
        "            label = entity.get(\"label\", \"UNKNOWN\")\n",
        "            highlighted_text = (\n",
        "                highlighted_text[:start] + \n",
        "                f\"[{text}]({label})\" + \n",
        "                highlighted_text[end:]\n",
        "            )\n",
        "        print(f\"\\nContext: {highlighted_text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Single Text Prediction\n",
        "\n",
        "Test entity extraction from individual text inputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Test with Sample Text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input text: Amazon Web Services, Austin, TX. Lead Machine Learning Engineer with 7 years of experience in NLP, recommender systems, and deep learning. Skills: Python, PyTorch, Spark.\n",
            "\n",
            "Processing time: 375.0ms\n",
            "\n",
            "Extracted 7 entities:\n",
            "================================================================================\n",
            "\n",
            "DESIGNATION (1):\n",
            "  - 'Lead Machine Learning Engineer' at [33:63] (confidence: 0.832)\n",
            "\n",
            "EXPERIENCE (1):\n",
            "  - '7 years of experience' at [69:90] (confidence: 0.662)\n",
            "\n",
            "LOCATION (1):\n",
            "  - 'Austin, TX' at [21:31] (confidence: 0.970)\n",
            "\n",
            "SKILL (4):\n",
            "  - 'Web Services' at [7:19] (confidence: 0.751)\n",
            "  - 'NLP' at [94:97] (confidence: 0.942)\n",
            "  - 'recommender systems' at [99:118] (confidence: 0.963)\n",
            "  - 'deep learning' at [124:137] (confidence: 0.908)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Amazon [Web Services](SKILL), [Austin, TX](LOCATION). [Lead Machine Learning Engineer](DESIGNATION) with [7 years of experience](EXPERIENCE) in [NLP](SKILL), [recommender systems](SKILL), and [deep learning](SKILL). Skills: Python, PyTorch, Spark.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test with text_1\n",
        "text_1 = get_text_fixture(\"text_1\")\n",
        "result = make_request(\"POST\", \"/predict\", json={\"text\": text_1})\n",
        "if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "    entities = result[\"data\"].get(\"entities\", [])\n",
        "    display_entities(entities, source_text=text_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Input text: Alice Johnson is a data analyst at Meta Platforms. Email: alice.johnson@meta.com. Phone: +1-408-555-7890. Location: Menlo Park, CA.\n",
            "\n",
            "Processing time: 422.1ms\n",
            "\n",
            "Extracted 6 entities:\n",
            "================================================================================\n",
            "\n",
            "DESIGNATION (1):\n",
            "  - 'data analyst' at [19:31] (confidence: 0.945)\n",
            "\n",
            "EMAIL (2):\n",
            "  - 'alice.johnson@' at [58:72] (confidence: 0.772)\n",
            "  - 'com' at [77:80] (confidence: 0.401)\n",
            "\n",
            "SKILL (3):\n",
            "  - 'Email' at [51:56] (confidence: 0.755)\n",
            "  - 'Phone' at [82:87] (confidence: 0.973)\n",
            "  - 'Location' at [106:114] (confidence: 0.907)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Alice Johnson is a [data analyst](DESIGNATION) at Meta Platforms. [Email](SKILL): [alice.johnson@](EMAIL)meta.[com](EMAIL). [Phone](SKILL): +1-408-555-7890. [Location](SKILL): Menlo Park, CA.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test with text_2 (contains email, phone, location)\n",
        "text_2 = get_text_fixture(\"text_2\")\n",
        "result = make_request(\"POST\", \"/predict\", json={\"text\": text_2})\n",
        "if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "    entities = result[\"data\"].get(\"entities\", [])\n",
        "    display_entities(entities, source_text=text_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Input text: Email: test@example.com, Phone: +1-555-123-4567, URL: https://example.com\n",
            "\n",
            "Processing time: 401.0ms\n",
            "\n",
            "Extracted 4 entities:\n",
            "================================================================================\n",
            "\n",
            "EMAIL (1):\n",
            "  - 'example' at [12:19] (confidence: 0.473)\n",
            "\n",
            "SKILL (3):\n",
            "  - 'Email' at [0:5] (confidence: 0.996)\n",
            "  - 'com' at [20:23] (confidence: 0.491)\n",
            "  - 'Phone' at [25:30] (confidence: 0.995)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "[Email](SKILL): test@[example](EMAIL).[com](SKILL), [Phone](SKILL): +1-555-123-4567, URL: https://example.com\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test with text_special (contains email, phone, URL)\n",
        "text_special = get_text_fixture(\"text_special\")\n",
        "result = make_request(\"POST\", \"/predict\", json={\"text\": text_special})\n",
        "if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "    entities = result[\"data\"].get(\"entities\", [])\n",
        "    display_entities(entities, source_text=text_special)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Single PDF File Prediction\n",
        "\n",
        "Test entity extraction from PDF files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: test_resume_ner_1.pdf\n",
            "Size: 1122 bytes\n",
            "\n",
            "Processing time: 461.1ms\n",
            "\n",
            "Extracted text length: 170 characters\n",
            "Extracted text preview (first 200 chars):\n",
            "Amazon Web Services, Austin, TX. Lead Machine Learning Engineer with 7 years of experience in NLP, recommender systems, and deep learning. Skills: Python, PyTorch, Spark....\n",
            "\n",
            "\n",
            "Extracted 7 entities:\n",
            "================================================================================\n",
            "\n",
            "DESIGNATION (1):\n",
            "  - 'Lead Machine Learning Engineer' at [33:63] (confidence: 0.832)\n",
            "\n",
            "EXPERIENCE (1):\n",
            "  - '7 years of experience' at [69:90] (confidence: 0.662)\n",
            "\n",
            "LOCATION (1):\n",
            "  - 'Austin, TX' at [21:31] (confidence: 0.970)\n",
            "\n",
            "SKILL (4):\n",
            "  - 'Web Services' at [7:19] (confidence: 0.751)\n",
            "  - 'NLP' at [94:97] (confidence: 0.942)\n",
            "  - 'recommender systems' at [99:118] (confidence: 0.963)\n",
            "  - 'deep learning' at [124:137] (confidence: 0.908)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Amazon [Web Services](SKILL), [Austin, TX](LOCATION). [Lead Machine Learning Engineer](DESIGNATION) with [7 years of experience](EXPERIENCE) in [NLP](SKILL), [recommender systems](SKILL), and [deep learning](SKILL). Skills: Python, PyTorch, Spark.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test with PDF file\n",
        "file_path = get_file_fixture(\"file_1\", \"pdf\")\n",
        "try:\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        file_content = f.read()\n",
        "    files = {\"file\": (file_path.name, file_content, \"application/pdf\")}\n",
        "    result = make_request(\"POST\", \"/predict/file\", files=files)\n",
        "    \n",
        "    if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "        extracted_text = result[\"data\"].get(\"extracted_text\", \"\")\n",
        "        entities = result[\"data\"].get(\"entities\", [])\n",
        "        display_entities(entities, source_text=extracted_text)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "File: test_resume.pdf\n",
            "Size: 57267 bytes\n",
            "\n",
            "Processing time: 451.0ms\n",
            "\n",
            "Extracted text length: 117 characters\n",
            "Extracted text preview (first 300 chars):\n",
            "John Doe is a software engineer at Google. Email: john.doe@example.com. Phone: +1-555-123-4567 Location: Seattle, WA....\n",
            "\n",
            "\n",
            "Extracted 5 entities:\n",
            "================================================================================\n",
            "\n",
            "EMAIL (1):\n",
            "  - 'john.doe@example.com' at [50:70] (confidence: 0.741)\n",
            "\n",
            "SKILL (4):\n",
            "  - 'is' at [9:11] (confidence: 0.557)\n",
            "  - 'software engineer' at [14:31] (confidence: 0.859)\n",
            "  - 'Email' at [43:48] (confidence: 0.850)\n",
            "  - 'Phone' at [72:77] (confidence: 0.932)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "John Doe [is](SKILL) a [software engineer](SKILL) at Google. [Email](SKILL): [john.doe@example.com](EMAIL). [Phone](SKILL): +1-555-123-4567 Location: Seattle, WA.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test with larger PDF file\n",
        "file_path = get_file_fixture(\"file_resume_1\", \"pdf\")\n",
        "try:\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        file_content = f.read()\n",
        "    files = {\"file\": (file_path.name, file_content, \"application/pdf\")}\n",
        "    result = make_request(\"POST\", \"/predict/file\", files=files)\n",
        "    \n",
        "    if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "        extracted_text = result[\"data\"].get(\"extracted_text\", \"\")\n",
        "        entities = result[\"data\"].get(\"entities\", [])\n",
        "        display_entities(entities, source_text=extracted_text)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Single Image File Prediction\n",
        "\n",
        "Test entity extraction from image files (PNG) using OCR.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: test_resume_ner_1.png\n",
            "Size: 16294 bytes\n",
            "\n",
            "Processing time: 5343.3ms\n",
            "\n",
            "Extracted text length: 168 characters\n",
            "Extracted text preview (first 200 chars):\n",
            "Amazon Web Services, Austin; TX. Lead Machine Learning Engineer with\n",
            "years of\n",
            "experience in NLP;\n",
            "recommender systems, and deep learning: Skills: Python, PyTorch, Spark:...\n",
            "\n",
            "\n",
            "Extracted 9 entities:\n",
            "================================================================================\n",
            "\n",
            "SKILL (9):\n",
            "  - 'Amazon Web Services' at [0:19] (confidence: 0.978)\n",
            "  - 'Machine Learning Engineer' at [38:63] (confidence: 0.993)\n",
            "  - 'NLP' at [92:95] (confidence: 0.966)\n",
            "  - 'recommender systems' at [97:116] (confidence: 0.943)\n",
            "  - 'deep learning' at [122:135] (confidence: 0.992)\n",
            "  - 'Skills' at [137:143] (confidence: 0.997)\n",
            "  - 'Python' at [145:151] (confidence: 0.996)\n",
            "  - 'PyTorch' at [153:160] (confidence: 0.943)\n",
            "  - 'Spark' at [162:167] (confidence: 0.953)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "[Amazon Web Services](SKILL), Austin; TX. Lead [Machine Learning Engineer](SKILL) with\n",
            "years of\n",
            "experience in [NLP](SKILL);\n",
            "[recommender systems](SKILL), and [deep learning](SKILL): [Skills](SKILL): [Python](SKILL), [PyTorch](SKILL), [Spark](SKILL):\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test with PNG image file\n",
        "file_path = get_file_fixture(\"file_1\", \"png\")\n",
        "try:\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        file_content = f.read()\n",
        "    files = {\"file\": (file_path.name, file_content, \"image/png\")}\n",
        "    result = make_request(\"POST\", \"/predict/file\", files=files)\n",
        "    \n",
        "    if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "        extracted_text = result[\"data\"].get(\"extracted_text\", \"\")\n",
        "        entities = result[\"data\"].get(\"entities\", [])\n",
        "        if extracted_text:\n",
        "            display_entities(entities, source_text=extracted_text)\n",
        "    elif result.get(\"status_code\") == 400:\n",
        "        error_detail = result.get(\"data\", {}).get(\"detail\", \"\")\n",
        "        if \"EasyOCR\" in error_detail or \"pytesseract\" in error_detail or \"Pillow\" in error_detail:\n",
        "            print(f\"⚠️  OCR dependencies not installed\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Batch Text Prediction\n",
        "\n",
        "Test entity extraction from multiple text inputs in a single batch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Batch with Multiple Texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size: 3 texts\n",
            "\n",
            "Text 1: Amazon Web Services, Austin, TX. Lead Machine Learning Engineer with 7 years of ...\n",
            "Text 2: Alice Johnson is a data analyst at Meta Platforms. Email: alice.johnson@meta.com...\n",
            "Text 3: Robert Lee holds a PhD in Artificial Intelligence from Stanford University. His ...\n",
            "\n",
            "================================================================================\n",
            "Total processing time: 879.7ms\n",
            "Average per text: 293.2ms\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Result 1/3:\n",
            "Text: Amazon Web Services, Austin, TX. Lead Machine Learning Engineer with 7 years of experience in NLP, r...\n",
            "Processing time: 743.7ms\n",
            "\n",
            "Extracted 7 entities:\n",
            "================================================================================\n",
            "\n",
            "DESIGNATION (1):\n",
            "  - 'Lead Machine Learning Engineer' at [33:63] (confidence: 0.832)\n",
            "\n",
            "EXPERIENCE (1):\n",
            "  - '7 years of experience' at [69:90] (confidence: 0.662)\n",
            "\n",
            "LOCATION (1):\n",
            "  - 'Austin, TX' at [21:31] (confidence: 0.970)\n",
            "\n",
            "SKILL (4):\n",
            "  - 'Web Services' at [7:19] (confidence: 0.751)\n",
            "  - 'NLP' at [94:97] (confidence: 0.942)\n",
            "  - 'recommender systems' at [99:118] (confidence: 0.963)\n",
            "  - 'deep learning' at [124:137] (confidence: 0.908)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Amazon [Web Services](SKILL), [Austin, TX](LOCATION). [Lead Machine Learning Engineer](DESIGNATION) with [7 years of experience](EXPERIENCE) in [NLP](SKILL), [recommender systems](SKILL), and [deep learning](SKILL). Skills: Python, PyTorch, Spark.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "Result 2/3:\n",
            "Text: Alice Johnson is a data analyst at Meta Platforms. Email: alice.johnson@meta.com. Phone: +1-408-555-...\n",
            "Processing time: 877.7ms\n",
            "\n",
            "Extracted 6 entities:\n",
            "================================================================================\n",
            "\n",
            "DESIGNATION (1):\n",
            "  - 'data analyst' at [19:31] (confidence: 0.945)\n",
            "\n",
            "EMAIL (2):\n",
            "  - 'alice.johnson@' at [58:72] (confidence: 0.772)\n",
            "  - 'com' at [77:80] (confidence: 0.401)\n",
            "\n",
            "SKILL (3):\n",
            "  - 'Email' at [51:56] (confidence: 0.755)\n",
            "  - 'Phone' at [82:87] (confidence: 0.973)\n",
            "  - 'Location' at [106:114] (confidence: 0.907)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Alice Johnson is a [data analyst](DESIGNATION) at Meta Platforms. [Email](SKILL): [alice.johnson@](EMAIL)meta.[com](EMAIL). [Phone](SKILL): +1-408-555-7890. [Location](SKILL): Menlo Park, CA.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "Result 3/3:\n",
            "Text: Robert Lee holds a PhD in Artificial Intelligence from Stanford University. His expertise includes c...\n",
            "Processing time: 609.7ms\n",
            "\n",
            "Extracted 5 entities:\n",
            "================================================================================\n",
            "\n",
            "EDUCATION (1):\n",
            "  - 'PhD in Artificial' at [19:36] (confidence: 0.696)\n",
            "\n",
            "SKILL (4):\n",
            "  - 'Intelligence' at [37:49] (confidence: 0.937)\n",
            "  - 'computer vision' at [99:114] (confidence: 0.983)\n",
            "  - 'transform' at [116:125] (confidence: 0.691)\n",
            "  - 'TensorFlow' at [134:144] (confidence: 0.977)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Robert Lee holds a [PhD in Artificial](EDUCATION) [Intelligence](SKILL) from Stanford University. His expertise includes [computer vision](SKILL), [transform](SKILL)ers, and [TensorFlow](SKILL).\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test batch with multiple texts\n",
        "texts = get_batch_text_fixture(\"batch_text_small\")\n",
        "result = make_request(\"POST\", \"/predict/batch\", json={\"texts\": texts})\n",
        "\n",
        "if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "    predictions = result[\"data\"].get(\"predictions\", [])\n",
        "    for i, (text, prediction) in enumerate(zip(texts, predictions), 1):\n",
        "        entities = prediction.get(\"entities\", [])\n",
        "        display_entities(entities, source_text=text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Batch File Prediction\n",
        "\n",
        "Test entity extraction from multiple files in a single batch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Batch with PDF Files Only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size: 3 PDF files\n",
            "\n",
            "File 1: test_resume_ner_1.pdf (1122 bytes)\n",
            "File 2: test_resume_ner_2.pdf (1093 bytes)\n",
            "File 3: test_resume_ner_3.pdf (1105 bytes)\n",
            "\n",
            "================================================================================\n",
            "Total processing time: 1266.1ms\n",
            "Average per file: 422.0ms\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Result 1/3: test_resume_ner_1.pdf\n",
            "Processing time: 430.0ms\n",
            "Extracted text length: 170 characters\n",
            "Text preview: Amazon Web Services, Austin, TX. Lead Machine Learning Engineer with 7 years of experience in NLP, recommender systems, and deep learning. Skills: Pyt...\n",
            "\n",
            "Extracted 7 entities:\n",
            "================================================================================\n",
            "\n",
            "DESIGNATION (1):\n",
            "  - 'Lead Machine Learning Engineer' at [33:63] (confidence: 0.832)\n",
            "\n",
            "EXPERIENCE (1):\n",
            "  - '7 years of experience' at [69:90] (confidence: 0.662)\n",
            "\n",
            "LOCATION (1):\n",
            "  - 'Austin, TX' at [21:31] (confidence: 0.970)\n",
            "\n",
            "SKILL (4):\n",
            "  - 'Web Services' at [7:19] (confidence: 0.751)\n",
            "  - 'NLP' at [94:97] (confidence: 0.942)\n",
            "  - 'recommender systems' at [99:118] (confidence: 0.963)\n",
            "  - 'deep learning' at [124:137] (confidence: 0.908)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Amazon [Web Services](SKILL), [Austin, TX](LOCATION). [Lead Machine Learning Engineer](DESIGNATION) with [7 years of experience](EXPERIENCE) in [NLP](SKILL), [recommender systems](SKILL), and [deep learning](SKILL). Skills: Python, PyTorch, Spark.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "Result 2/3: test_resume_ner_2.pdf\n",
            "Processing time: 416.2ms\n",
            "Extracted text length: 131 characters\n",
            "Text preview: Alice Johnson is a data analyst at Meta Platforms. Email: alice.johnson@meta.com. Phone: +1-408-555-7890. Location: Menlo Park, CA....\n",
            "\n",
            "Extracted 6 entities:\n",
            "================================================================================\n",
            "\n",
            "DESIGNATION (1):\n",
            "  - 'data analyst' at [19:31] (confidence: 0.945)\n",
            "\n",
            "EMAIL (2):\n",
            "  - 'alice.johnson@' at [58:72] (confidence: 0.772)\n",
            "  - 'com' at [77:80] (confidence: 0.401)\n",
            "\n",
            "SKILL (3):\n",
            "  - 'Email' at [51:56] (confidence: 0.755)\n",
            "  - 'Phone' at [82:87] (confidence: 0.973)\n",
            "  - 'Location' at [106:114] (confidence: 0.907)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Alice Johnson is a [data analyst](DESIGNATION) at Meta Platforms. [Email](SKILL): [alice.johnson@](EMAIL)meta.[com](EMAIL). [Phone](SKILL): +1-408-555-7890. [Location](SKILL): Menlo Park, CA.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "Result 3/3: test_resume_ner_3.pdf\n",
            "Processing time: 420.0ms\n",
            "Extracted text length: 145 characters\n",
            "Text preview: Robert Lee holds a PhD in Artificial Intelligence from Stanford University. His expertise includes computer vision, transformers, and TensorFlow....\n",
            "\n",
            "Extracted 5 entities:\n",
            "================================================================================\n",
            "\n",
            "EDUCATION (1):\n",
            "  - 'PhD in Artificial' at [19:36] (confidence: 0.696)\n",
            "\n",
            "SKILL (4):\n",
            "  - 'Intelligence' at [37:49] (confidence: 0.937)\n",
            "  - 'computer vision' at [99:114] (confidence: 0.983)\n",
            "  - 'transform' at [116:125] (confidence: 0.691)\n",
            "  - 'TensorFlow' at [134:144] (confidence: 0.977)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Robert Lee holds a [PhD in Artificial](EDUCATION) [Intelligence](SKILL) from Stanford University. His expertise includes [computer vision](SKILL), [transform](SKILL)ers, and [TensorFlow](SKILL).\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test batch with PDF files\n",
        "file_paths = get_batch_file_fixture(\"batch_file_small\", \"pdf\")\n",
        "try:\n",
        "    files_list = []\n",
        "    for file_path in file_paths:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            file_content = f.read()\n",
        "        files_list.append((\"files\", (file_path.name, file_content, \"application/pdf\")))\n",
        "    \n",
        "    result = make_request(\"POST\", \"/predict/file/batch\", files=files_list)\n",
        "    \n",
        "    if result.get(\"status_code\") == 200 and result.get(\"data\"):\n",
        "        predictions = result[\"data\"].get(\"predictions\", [])\n",
        "        for i, (file_path, prediction) in enumerate(zip(file_paths, predictions), 1):\n",
        "            extracted_text = prediction.get(\"extracted_text\", \"\")\n",
        "            entities = prediction.get(\"entities\", [])\n",
        "            if extracted_text:\n",
        "                display_entities(entities, source_text=extracted_text)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Mixed Batch Prediction\n",
        "\n",
        "Test entity extraction from a batch containing a mixture of texts, PDF files, and images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing mixed content (texts + PDFs + images)\n",
            "================================================================================\n",
            "\n",
            "Note: API endpoints are separate for texts and files.\n",
            "We'll process them separately and show combined results.\n",
            "\n",
            "Content to process:\n",
            "  - 2 text inputs\n",
            "  - 1 PDF files\n",
            "  - 1 image files\n",
            "  Total: 4 items\n",
            "\n",
            "Processing texts...\n",
            "Processing PDF files...\n",
            "Processing image files...\n",
            "\n",
            "================================================================================\n",
            "COMBINED RESULTS (4 items processed)\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Item 1/4: TEXT\n",
            "Text: Amazon Web Services, Austin, TX. Lead Machine Learning Engineer with 7 years of experience in NLP, r...\n",
            "\n",
            "Extracted 7 entities:\n",
            "================================================================================\n",
            "\n",
            "DESIGNATION (1):\n",
            "  - 'Lead Machine Learning Engineer' at [33:63] (confidence: 0.832)\n",
            "\n",
            "EXPERIENCE (1):\n",
            "  - '7 years of experience' at [69:90] (confidence: 0.662)\n",
            "\n",
            "LOCATION (1):\n",
            "  - 'Austin, TX' at [21:31] (confidence: 0.970)\n",
            "\n",
            "SKILL (4):\n",
            "  - 'Web Services' at [7:19] (confidence: 0.751)\n",
            "  - 'NLP' at [94:97] (confidence: 0.942)\n",
            "  - 'recommender systems' at [99:118] (confidence: 0.963)\n",
            "  - 'deep learning' at [124:137] (confidence: 0.908)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Amazon [Web Services](SKILL), [Austin, TX](LOCATION). [Lead Machine Learning Engineer](DESIGNATION) with [7 years of experience](EXPERIENCE) in [NLP](SKILL), [recommender systems](SKILL), and [deep learning](SKILL). Skills: Python, PyTorch, Spark.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "Item 2/4: TEXT\n",
            "Text: Alice Johnson is a data analyst at Meta Platforms. Email: alice.johnson@meta.com. Phone: +1-408-555-...\n",
            "\n",
            "Extracted 6 entities:\n",
            "================================================================================\n",
            "\n",
            "DESIGNATION (1):\n",
            "  - 'data analyst' at [19:31] (confidence: 0.945)\n",
            "\n",
            "EMAIL (2):\n",
            "  - 'alice.johnson@' at [58:72] (confidence: 0.772)\n",
            "  - 'com' at [77:80] (confidence: 0.401)\n",
            "\n",
            "SKILL (3):\n",
            "  - 'Email' at [51:56] (confidence: 0.755)\n",
            "  - 'Phone' at [82:87] (confidence: 0.973)\n",
            "  - 'Location' at [106:114] (confidence: 0.907)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Alice Johnson is a [data analyst](DESIGNATION) at Meta Platforms. [Email](SKILL): [alice.johnson@](EMAIL)meta.[com](EMAIL). [Phone](SKILL): +1-408-555-7890. [Location](SKILL): Menlo Park, CA.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "Item 3/4: PDF\n",
            "File: test_resume_ner_1.pdf\n",
            "Processing time: 452.2ms\n",
            "Extracted text: Amazon Web Services, Austin, TX. Lead Machine Learning Engineer with 7 years of experience in NLP, recommender systems, and deep learning. Skills: Pyt...\n",
            "\n",
            "Extracted 7 entities:\n",
            "================================================================================\n",
            "\n",
            "DESIGNATION (1):\n",
            "  - 'Lead Machine Learning Engineer' at [33:63] (confidence: 0.832)\n",
            "\n",
            "EXPERIENCE (1):\n",
            "  - '7 years of experience' at [69:90] (confidence: 0.662)\n",
            "\n",
            "LOCATION (1):\n",
            "  - 'Austin, TX' at [21:31] (confidence: 0.970)\n",
            "\n",
            "SKILL (4):\n",
            "  - 'Web Services' at [7:19] (confidence: 0.751)\n",
            "  - 'NLP' at [94:97] (confidence: 0.942)\n",
            "  - 'recommender systems' at [99:118] (confidence: 0.963)\n",
            "  - 'deep learning' at [124:137] (confidence: 0.908)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "Amazon [Web Services](SKILL), [Austin, TX](LOCATION). [Lead Machine Learning Engineer](DESIGNATION) with [7 years of experience](EXPERIENCE) in [NLP](SKILL), [recommender systems](SKILL), and [deep learning](SKILL). Skills: Python, PyTorch, Spark.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "Item 4/4: IMAGE\n",
            "File: test_resume_ner_1.png\n",
            "Processing time: 1636.8ms\n",
            "Extracted text: Amazon Web Services, Austin; TX. Lead Machine Learning Engineer with\n",
            "years of\n",
            "experience in NLP;\n",
            "recommender systems, and deep learning: Skills: Pytho...\n",
            "\n",
            "Extracted 9 entities:\n",
            "================================================================================\n",
            "\n",
            "SKILL (9):\n",
            "  - 'Amazon Web Services' at [0:19] (confidence: 0.978)\n",
            "  - 'Machine Learning Engineer' at [38:63] (confidence: 0.993)\n",
            "  - 'NLP' at [92:95] (confidence: 0.966)\n",
            "  - 'recommender systems' at [97:116] (confidence: 0.943)\n",
            "  - 'deep learning' at [122:135] (confidence: 0.992)\n",
            "  - 'Skills' at [137:143] (confidence: 0.997)\n",
            "  - 'Python' at [145:151] (confidence: 0.996)\n",
            "  - 'PyTorch' at [153:160] (confidence: 0.943)\n",
            "  - 'Spark' at [162:167] (confidence: 0.953)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "[Amazon Web Services](SKILL), Austin; TX. Lead [Machine Learning Engineer](SKILL) with\n",
            "years of\n",
            "experience in [NLP](SKILL);\n",
            "[recommender systems](SKILL), and [deep learning](SKILL): [Skills](SKILL): [Python](SKILL), [PyTorch](SKILL), [Spark](SKILL):\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test mixed content (texts + PDFs + images)\n",
        "# Note: API endpoints are separate, so we process them separately and combine results\n",
        "\n",
        "texts = [get_text_fixture(\"text_1\"), get_text_fixture(\"text_2\")]\n",
        "pdf_files = [get_file_fixture(\"file_1\", \"pdf\")]\n",
        "png_files = [get_file_fixture(\"file_1\", \"png\")]\n",
        "\n",
        "all_results = []\n",
        "\n",
        "# Process texts\n",
        "text_result = make_request(\"POST\", \"/predict/batch\", json={\"texts\": texts})\n",
        "if text_result.get(\"status_code\") == 200:\n",
        "    all_results.extend([\n",
        "        {\"type\": \"text\", \"content\": text, \"result\": pred}\n",
        "        for text, pred in zip(texts, text_result[\"data\"].get(\"predictions\", []))\n",
        "    ])\n",
        "\n",
        "# Process PDF files\n",
        "try:\n",
        "    files_list = []\n",
        "    for file_path in pdf_files:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            file_content = f.read()\n",
        "        files_list.append((\"files\", (file_path.name, file_content, \"application/pdf\")))\n",
        "    \n",
        "    pdf_result = make_request(\"POST\", \"/predict/file/batch\", files=files_list)\n",
        "    if pdf_result.get(\"status_code\") == 200:\n",
        "        all_results.extend([\n",
        "            {\"type\": \"pdf\", \"file\": str(fp), \"result\": pred}\n",
        "            for fp, pred in zip(pdf_files, pdf_result[\"data\"].get(\"predictions\", []))\n",
        "        ])\n",
        "except Exception as e:\n",
        "    print(f\"Error processing PDFs: {e}\")\n",
        "\n",
        "# Process image files\n",
        "try:\n",
        "    files_list = []\n",
        "    for file_path in png_files:\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            file_content = f.read()\n",
        "        files_list.append((\"files\", (file_path.name, file_content, \"image/png\")))\n",
        "    \n",
        "    png_result = make_request(\"POST\", \"/predict/file/batch\", files=files_list)\n",
        "    if png_result.get(\"status_code\") == 200:\n",
        "        all_results.extend([\n",
        "            {\"type\": \"image\", \"file\": str(fp), \"result\": pred}\n",
        "            for fp, pred in zip(png_files, png_result[\"data\"].get(\"predictions\", []))\n",
        "        ])\n",
        "    elif png_result.get(\"status_code\") == 400:\n",
        "        error_detail = png_result.get(\"data\", {}).get(\"detail\", \"\")\n",
        "        if \"EasyOCR\" in error_detail or \"pytesseract\" in error_detail:\n",
        "            print(f\"⚠️  OCR dependencies not installed\")\n",
        "except Exception as e:\n",
        "    print(f\"Error processing images: {e}\")\n",
        "\n",
        "# Display combined results\n",
        "for item in all_results:\n",
        "    result = item[\"result\"]\n",
        "    entities = result.get(\"entities\", [])\n",
        "    \n",
        "    if item[\"type\"] == \"text\":\n",
        "        display_entities(entities, source_text=item[\"content\"])\n",
        "    else:\n",
        "        extracted_text = result.get(\"extracted_text\", \"\")\n",
        "        if extracted_text:\n",
        "            display_entities(entities, source_text=extracted_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Cross-Format Consistency Test\n",
        "\n",
        "Test the same content across different formats (text, PDF, PNG) to verify entity extraction consistency and compare performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracted 6 entities:\n",
            "================================================================================\n",
            "\n",
            "EMAIL (1):\n",
            "  - 'john.doe@example.com' at [50:70] (confidence: 0.763)\n",
            "\n",
            "LOCATION (1):\n",
            "  - 'WA' at [115:117] (confidence: 0.581)\n",
            "\n",
            "SKILL (4):\n",
            "  - 'software engineer' at [14:31] (confidence: 0.884)\n",
            "  - 'Email' at [43:48] (confidence: 0.929)\n",
            "  - 'Phone' at [72:77] (confidence: 0.980)\n",
            "  - 'Location' at [96:104] (confidence: 0.889)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "John Doe is a [software engineer](SKILL) at Google. [Email](SKILL): [john.doe@example.com](EMAIL). [Phone](SKILL): +1-555-123-4567. [Location](SKILL): Seattle, [WA](LOCATION).\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Extracted 5 entities:\n",
            "================================================================================\n",
            "\n",
            "EMAIL (1):\n",
            "  - 'john.doe@example.com' at [50:70] (confidence: 0.741)\n",
            "\n",
            "SKILL (4):\n",
            "  - 'is' at [9:11] (confidence: 0.557)\n",
            "  - 'software engineer' at [14:31] (confidence: 0.859)\n",
            "  - 'Email' at [43:48] (confidence: 0.850)\n",
            "  - 'Phone' at [72:77] (confidence: 0.932)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "John Doe [is](SKILL) a [software engineer](SKILL) at Google. [Email](SKILL): [john.doe@example.com](EMAIL). [Phone](SKILL): +1-555-123-4567 Location: Seattle, WA.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Extracted 5 entities:\n",
            "================================================================================\n",
            "\n",
            "SKILL (5):\n",
            "  - 'software engineer' at [14:31] (confidence: 0.952)\n",
            "  - 'Google' at [35:41] (confidence: 0.563)\n",
            "  - 'Email' at [43:48] (confidence: 0.960)\n",
            "  - 'Phone' at [72:77] (confidence: 0.992)\n",
            "  - 'Location' at [95:103] (confidence: 0.996)\n",
            "\n",
            "================================================================================\n",
            "Entities in context:\n",
            "--------------------------------------------------------------------------------\n",
            "John Doe is a [software engineer](SKILL) at [Google](SKILL): [Email](SKILL): john doe@example com: [Phone](SKILL): +1-555-123-4567\n",
            "[Location](SKILL): Seattle, WA.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Format</th>\n",
              "      <th>Processing Time (ms)</th>\n",
              "      <th>Entities Extracted</th>\n",
              "      <th>Text Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Text</td>\n",
              "      <td>412.0</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PDF</td>\n",
              "      <td>430.7</td>\n",
              "      <td>5</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PNG</td>\n",
              "      <td>2974.7</td>\n",
              "      <td>5</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Format Processing Time (ms)  Entities Extracted  Text Length\n",
              "0   Text                412.0                   6          118\n",
              "1    PDF                430.7                   5          117\n",
              "2    PNG               2974.7                   5          117"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entities in all formats (3):\n",
            "  - 'Email' (SKILL)\n",
            "  - 'Phone' (SKILL)\n",
            "  - 'software engineer' (SKILL)\n",
            "\n",
            "Format-specific entities:\n",
            "  Text & PDF only (1): john.doe@example.com\n",
            "  Text & PNG only (1): Location\n",
            "\n",
            "Performance: Text fastest (412.0ms), PNG slowest (2974.7ms)\n",
            "OCR overhead: 2562.7ms (622.0%)\n"
          ]
        }
      ],
      "source": [
        "# Test the same content in different formats\n",
        "sample_text = \"John Doe is a software engineer at Google. Email: john.doe@example.com. Phone: +1-555-123-4567. Location: Seattle, WA.\"\n",
        "\n",
        "pdf_file = get_file_fixture(\"file_resume_1\", \"pdf\")\n",
        "png_file = get_file_fixture(\"file_resume_1\", \"png\")\n",
        "\n",
        "results = []\n",
        "\n",
        "# Test 1: Text format\n",
        "text_result = make_request(\"POST\", \"/predict\", json={\"text\": sample_text})\n",
        "if text_result.get(\"status_code\") == 200:\n",
        "    text_data = text_result[\"data\"]\n",
        "    results.append({\n",
        "        \"format\": \"Text\",\n",
        "        \"input\": sample_text,\n",
        "        \"extracted_text\": sample_text,\n",
        "        \"entities\": text_data.get(\"entities\", []),\n",
        "        \"processing_time_ms\": text_data.get(\"processing_time_ms\", 0),\n",
        "        \"num_entities\": len(text_data.get(\"entities\", []))\n",
        "    })\n",
        "    display_entities(text_data.get(\"entities\", []), source_text=sample_text)\n",
        "\n",
        "# Test 2: PDF format\n",
        "try:\n",
        "    with open(pdf_file, \"rb\") as f:\n",
        "        pdf_content = f.read()\n",
        "    pdf_files = {\"file\": (pdf_file.name, pdf_content, \"application/pdf\")}\n",
        "    pdf_result = make_request(\"POST\", \"/predict/file\", files=pdf_files)\n",
        "    \n",
        "    if pdf_result.get(\"status_code\") == 200:\n",
        "        pdf_data = pdf_result[\"data\"]\n",
        "        extracted_text = pdf_data.get(\"extracted_text\", \"\")\n",
        "        results.append({\n",
        "            \"format\": \"PDF\",\n",
        "            \"input\": str(pdf_file),\n",
        "            \"extracted_text\": extracted_text,\n",
        "            \"entities\": pdf_data.get(\"entities\", []),\n",
        "            \"processing_time_ms\": pdf_data.get(\"processing_time_ms\", 0),\n",
        "            \"num_entities\": len(pdf_data.get(\"entities\", []))\n",
        "        })\n",
        "        display_entities(pdf_data.get(\"entities\", []), source_text=extracted_text)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading PDF: {e}\")\n",
        "\n",
        "# Test 3: PNG format\n",
        "try:\n",
        "    with open(png_file, \"rb\") as f:\n",
        "        png_content = f.read()\n",
        "    png_files = {\"file\": (png_file.name, png_content, \"image/png\")}\n",
        "    png_result = make_request(\"POST\", \"/predict/file\", files=png_files)\n",
        "    \n",
        "    if png_result.get(\"status_code\") == 200:\n",
        "        png_data = png_result[\"data\"]\n",
        "        extracted_text = png_data.get(\"extracted_text\", \"\")\n",
        "        results.append({\n",
        "            \"format\": \"PNG\",\n",
        "            \"input\": str(png_file),\n",
        "            \"extracted_text\": extracted_text,\n",
        "            \"entities\": png_data.get(\"entities\", []),\n",
        "            \"processing_time_ms\": png_data.get(\"processing_time_ms\", 0),\n",
        "            \"num_entities\": len(png_data.get(\"entities\", []))\n",
        "        })\n",
        "        display_entities(png_data.get(\"entities\", []), source_text=extracted_text)\n",
        "    elif png_result.get(\"status_code\") == 400:\n",
        "        error_detail = png_result.get(\"data\", {}).get(\"detail\", \"\")\n",
        "        if \"EasyOCR\" in error_detail or \"pytesseract\" in error_detail or \"Pillow\" in error_detail:\n",
        "            print(f\"⚠️  OCR dependencies not installed\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading PNG: {e}\")\n",
        "\n",
        "# Comparison Summary\n",
        "if len(results) >= 2:\n",
        "    comparison_data = []\n",
        "    for r in results:\n",
        "        comparison_data.append({\n",
        "            \"Format\": r[\"format\"],\n",
        "            \"Processing Time (ms)\": f\"{r['processing_time_ms']:.1f}\",\n",
        "            \"Entities Extracted\": r[\"num_entities\"],\n",
        "            \"Text Length\": len(r[\"extracted_text\"])\n",
        "        })\n",
        "    \n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "    display(comparison_df)\n",
        "    \n",
        "    # Entity consistency analysis\n",
        "    if len(results) == 3:\n",
        "        text_entities = set((e.get(\"text\", \"\"), e.get(\"label\", \"\")) for e in results[0][\"entities\"])\n",
        "        pdf_entities = set((e.get(\"text\", \"\"), e.get(\"label\", \"\")) for e in results[1][\"entities\"])\n",
        "        png_entities = set((e.get(\"text\", \"\"), e.get(\"label\", \"\")) for e in results[2][\"entities\"])\n",
        "        \n",
        "        common_all = text_entities & pdf_entities & png_entities\n",
        "        text_pdf_only = (text_entities & pdf_entities) - png_entities\n",
        "        text_png_only = (text_entities & png_entities) - pdf_entities\n",
        "        pdf_png_only = (pdf_entities & png_entities) - text_entities\n",
        "        \n",
        "        if common_all:\n",
        "            print(f\"\\nEntities in all formats ({len(common_all)}):\")\n",
        "            for entity in sorted(common_all):\n",
        "                print(f\"  - '{entity[0]}' ({entity[1]})\")\n",
        "        \n",
        "        if text_pdf_only or text_png_only or pdf_png_only:\n",
        "            print(f\"\\nFormat-specific entities:\")\n",
        "            if text_pdf_only:\n",
        "                print(f\"  Text & PDF only ({len(text_pdf_only)}): {', '.join([e[0] for e in sorted(text_pdf_only)])}\")\n",
        "            if text_png_only:\n",
        "                print(f\"  Text & PNG only ({len(text_png_only)}): {', '.join([e[0] for e in sorted(text_png_only)])}\")\n",
        "            if pdf_png_only:\n",
        "                print(f\"  PDF & PNG only ({len(pdf_png_only)}): {', '.join([e[0] for e in sorted(pdf_png_only)])}\")\n",
        "        \n",
        "        # Performance comparison\n",
        "        times = [r[\"processing_time_ms\"] for r in results]\n",
        "        formats = [r[\"format\"] for r in results]\n",
        "        min_time = min(times)\n",
        "        max_time = max(times)\n",
        "        \n",
        "        print(f\"\\nPerformance: {formats[times.index(min_time)]} fastest ({min_time:.1f}ms), {formats[times.index(max_time)]} slowest ({max_time:.1f}ms)\")\n",
        "        \n",
        "        text_time = results[0][\"processing_time_ms\"]\n",
        "        png_time = results[2][\"processing_time_ms\"]\n",
        "        if png_time > text_time:\n",
        "            ocr_overhead = png_time - text_time\n",
        "            print(f\"OCR overhead: {ocr_overhead:.1f}ms ({ocr_overhead / text_time * 100:.1f}%)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
