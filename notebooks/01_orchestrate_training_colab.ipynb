{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Training Orchestration (Google Colab & Kaggle)\n",
    "\n",
    "This notebook orchestrates all training activities for **Google Colab or Kaggle execution** with GPU compute support.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Step 1**: Repository Setup & Environment Configuration\n",
    "- **Step 2**: Load Centralized Configs\n",
    "- **Step 3**: Verify Local Dataset (from data config)\n",
    "- **Step 4**: Setup Local Environment\n",
    "- **Step 5**: The Dry Run\n",
    "- **Step 6**: The Sweep (HPO) - Local with Optuna\n",
    "- **Step 5.5**: Benchmarking Best Trials (NEW)\n",
    "- **Step 7**: Best Configuration Selection (Automated)\n",
    "- **Step 8**: Final Training (Post-HPO, Single Run)\n",
    "- **Step 9**: Model Conversion & Optimization\n",
    "\n",
    "## Important\n",
    "\n",
    "- This notebook **executes training in Google Colab or Kaggle** (not on Azure ML)\n",
    "- All computation happens on the platform's GPU\n",
    "- **Storage & Persistence**:\n",
    "  - **Google Colab**: Checkpoints are automatically saved to Google Drive for persistence across sessions\n",
    "  - **Kaggle**: Outputs in `/kaggle/working/` are automatically persisted - no manual backup needed\n",
    "- The notebook must be **re-runnable end-to-end**\n",
    "- Uses the dataset path specified in the data config (from `config/data/*.yaml`), typically pointing to a local folder included in the repository\n",
    "- **Session Management**:\n",
    "  - **Colab**: Sessions timeout after 12-24 hours (depending on Colab plan). Checkpoints are saved to Drive automatically.\n",
    "  - **Kaggle**: Sessions have time limits based on your plan. All outputs are automatically saved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Repository Setup\n",
    "\n",
    "Set up the repository in Google Colab or Kaggle. Choose one of the following options:\n",
    "\n",
    "### Option A: Clone from Git (Recommended)\n",
    "\n",
    "If your repository is on GitHub/GitLab, clone it:\n",
    "\n",
    "**For Google Colab:**\n",
    "```python\n",
    "!git clone -b feature/google-colab-compute https://github.com/longdang193/resume-ner-azureml.git /content/resume-ner-azureml\n",
    "```\n",
    "\n",
    "**For Kaggle:**\n",
    "```python\n",
    "!git clone -b feature/google-colab-compute https://github.com/longdang193/resume-ner-azureml.git /kaggle/working/resume-ner-azureml\n",
    "```\n",
    "\n",
    "### Option B: Upload Files\n",
    "\n",
    "**For Google Colab:**\n",
    "1. Use the Colab file browser (folder icon on left sidebar)\n",
    "2. Upload your project files to `/content/resume-ner-azureml/`\n",
    "3. Ensure the directory structure matches: `src/`, `config/`, `notebooks/`, etc.\n",
    "\n",
    "**For Kaggle:**\n",
    "1. Use the Kaggle file browser (Data tab)\n",
    "2. Upload your project files to `/kaggle/working/resume-ner-azureml/`\n",
    "3. Ensure the directory structure matches: `src/`, `config/`, `notebooks/`, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone -b feature/google-colab-compute https://github.com/longdang193/resume-ner-azureml.git /content/resume-ner-azureml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Repository Setup\n",
    "\n",
    "After cloning or uploading, verify the repository structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Determine base directory based on environment (will be set in environment detection cell)\n",
    "# This allows the cell to work even if environment detection hasn't run yet\n",
    "if \"BASE_DIR\" not in globals():\n",
    "    if \"COLAB_GPU\" in os.environ or \"COLAB_TPU\" in os.environ:\n",
    "        BASE_DIR = Path(\"/content\")\n",
    "    elif \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n",
    "        BASE_DIR = Path(\"/kaggle/working\")\n",
    "    else:\n",
    "        BASE_DIR = Path(\"/content\")  # Default to Colab path\n",
    "\n",
    "# Set repository root directory\n",
    "# Change this if you used a different path in Step 1\n",
    "ROOT_DIR = BASE_DIR / \"resume-ner-azureml\"\n",
    "\n",
    "# Verify repository structure\n",
    "if not ROOT_DIR.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Repository not found at {ROOT_DIR}\\n\"\n",
    "        f\"Please run Step 1 to clone or upload the repository.\"\n",
    "    )\n",
    "\n",
    "required_dirs = [\"src\", \"config\", \"notebooks\"]\n",
    "missing_dirs = [d for d in required_dirs if not (ROOT_DIR / d).exists()]\n",
    "\n",
    "if missing_dirs:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing required directories: {missing_dirs}\\n\"\n",
    "        f\"Please ensure the repository structure is correct.\"\n",
    "    )\n",
    "\n",
    "print(f\"✓ Repository found at: {ROOT_DIR}\")\n",
    "print(f\"✓ Required directories found: {required_dirs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies\n",
    "\n",
    "Install all required Python packages. PyTorch is usually pre-installed in Colab, but we'll verify the version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check PyTorch version (usually pre-installed in Colab)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(f\"Visible GPUs: {device_count}\")\n",
    "    for i in range(device_count):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# Verify PyTorch version meets requirements (>=2.6.0)\n",
    "torch_version = tuple(map(int, torch.__version__.split('.')[:2]))\n",
    "if torch_version < (2, 6):\n",
    "    print(f\"⚠ Warning: PyTorch {torch.__version__} may not meet requirements (>=2.6.0)\")\n",
    "    print(\"Consider upgrading: !pip install torch>=2.6.0 --upgrade\")\n",
    "else:\n",
    "    print(\"✓ PyTorch version meets requirements\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Core ML libraries\n",
    "%pip install transformers>=4.35.0,<5.0.0 --quiet\n",
    "%pip install safetensors>=0.4.0 --quiet\n",
    "%pip install datasets>=2.12.0 --quiet\n",
    "\n",
    "# ML utilities\n",
    "%pip install numpy>=1.24.0,<2.0.0 --quiet\n",
    "%pip install pandas>=2.0.0 --quiet\n",
    "%pip install scikit-learn>=1.3.0 --quiet\n",
    "\n",
    "# Utilities\n",
    "%pip install pyyaml>=6.0 --quiet\n",
    "%pip install tqdm>=4.65.0 --quiet\n",
    "%pip install seqeval>=1.2.2 --quiet\n",
    "%pip install sentencepiece>=0.1.99 --quiet\n",
    "\n",
    "# Experiment tracking\n",
    "%pip install mlflow --quiet\n",
    "%pip install optuna --quiet\n",
    "\n",
    "# ONNX support\n",
    "%pip install onnxruntime --quiet\n",
    "%pip install onnx>=1.16.0 --quiet\n",
    "%pip install onnxscript>=0.1.0 --quiet\n",
    "\n",
    "print(\"✓ All dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setup Paths and Import Paths\n",
    "\n",
    "Configure Python paths and verify Colab environment detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment detection and platform configuration\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect execution environment\n",
    "IN_COLAB = \"COLAB_GPU\" in os.environ or \"COLAB_TPU\" in os.environ\n",
    "IN_KAGGLE = \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "\n",
    "# Set platform-specific constants\n",
    "if IN_COLAB:\n",
    "    PLATFORM = \"colab\"\n",
    "    BASE_DIR = Path(\"/content\")\n",
    "    BACKUP_ENABLED = True\n",
    "    print(\"✓ Detected: Google Colab environment\")\n",
    "elif IN_KAGGLE:\n",
    "    PLATFORM = \"kaggle\"\n",
    "    BASE_DIR = Path(\"/kaggle/working\")\n",
    "    BACKUP_ENABLED = False  # Kaggle outputs are automatically persisted\n",
    "    print(\"✓ Detected: Kaggle environment\")\n",
    "else:\n",
    "    raise EnvironmentError(\n",
    "        \"This notebook requires Google Colab or Kaggle environment.\\n\"\n",
    "        \"Colab: Set runtime type to GPU/TPU\\n\"\n",
    "        \"Kaggle: Ensure KAGGLE_KERNEL_RUN_TYPE is set\"\n",
    "    )\n",
    "\n",
    "print(f\"Platform: {PLATFORM}\")\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Backup enabled: {BACKUP_ENABLED}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup paths (ROOT_DIR should be set in Cell 2)\n",
    "# If not, set it here\n",
    "if 'ROOT_DIR' not in globals():\n",
    "    if IN_COLAB:\n",
    "        ROOT_DIR = Path(\"/content/resume-ner-azureml\")\n",
    "    elif IN_KAGGLE:\n",
    "        ROOT_DIR = Path(\"/kaggle/working/resume-ner-azureml\")\n",
    "    else:\n",
    "        ROOT_DIR = Path(\"/content/resume-ner-azureml\")  # Default to Colab path\n",
    "\n",
    "SRC_DIR = ROOT_DIR / \"src\"\n",
    "CONFIG_DIR = ROOT_DIR / \"config\"\n",
    "NOTEBOOK_DIR = ROOT_DIR / \"notebooks\"\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, str(ROOT_DIR))\n",
    "sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "print(\"Notebook directory:\", NOTEBOOK_DIR)\n",
    "print(\"Project root:\", ROOT_DIR)\n",
    "print(\"Source directory:\", SRC_DIR)\n",
    "print(\"Config directory:\", CONFIG_DIR)\n",
    "print(\"Platform:\", PLATFORM if 'PLATFORM' in globals() else \"unknown\")\n",
    "print(\"In Colab:\", IN_COLAB if 'IN_COLAB' in globals() else False)\n",
    "print(\"In Kaggle:\", IN_KAGGLE if 'IN_KAGGLE' in globals() else False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Mount Google Drive\n",
    "\n",
    "Mount Google Drive to enable checkpoint persistence across Colab sessions. Checkpoints will be automatically saved to Drive after training completes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for checkpoint backup/restore (platform-aware)\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "def backup_to_drive(source_path: Path, backup_name: str, is_directory: bool = False) -> bool:\n",
    "    \"\"\"\n",
    "    Backup a file or directory to Google Drive if available.\n",
    "    \n",
    "    Args:\n",
    "        source_path: Path to the file or directory to backup\n",
    "        backup_name: Name for the backup (will be placed in DRIVE_BACKUP_DIR)\n",
    "        is_directory: True if backing up a directory, False for a file\n",
    "    \n",
    "    Returns:\n",
    "        True if backup was successful, False if backup is not available or failed\n",
    "    \"\"\"\n",
    "    if not BACKUP_ENABLED or not DRIVE_BACKUP_DIR:\n",
    "        return False\n",
    "    \n",
    "    if not source_path.exists():\n",
    "        print(f\"⚠ Warning: Source path does not exist: {source_path}\")\n",
    "        return False\n",
    "    \n",
    "    backup_path = DRIVE_BACKUP_DIR / backup_name\n",
    "    \n",
    "    try:\n",
    "        if is_directory:\n",
    "            # Remove existing backup if it exists\n",
    "            if backup_path.exists():\n",
    "                shutil.rmtree(backup_path)\n",
    "            shutil.copytree(source_path, backup_path)\n",
    "        else:\n",
    "            shutil.copy2(source_path, backup_path)\n",
    "        \n",
    "        print(f\"✓ Backed up to Google Drive: {backup_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Warning: Backup failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def restore_from_drive(backup_name: str, target_path: Path, is_directory: bool = False) -> bool:\n",
    "    \"\"\"\n",
    "    Restore a file or directory from Google Drive if available.\n",
    "    \n",
    "    Args:\n",
    "        backup_name: Name of the backup in DRIVE_BACKUP_DIR\n",
    "        target_path: Path where the restored file/directory should be placed\n",
    "        is_directory: True if restoring a directory, False for a file\n",
    "    \n",
    "    Returns:\n",
    "        True if restore was successful, False if backup is not available or failed\n",
    "    \"\"\"\n",
    "    if not BACKUP_ENABLED or not DRIVE_BACKUP_DIR:\n",
    "        return False\n",
    "    \n",
    "    backup_path = DRIVE_BACKUP_DIR / backup_name\n",
    "    \n",
    "    if not backup_path.exists():\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        if is_directory:\n",
    "            # Create parent directory if needed\n",
    "            target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copytree(backup_path, target_path)\n",
    "        else:\n",
    "            target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(backup_path, target_path)\n",
    "        \n",
    "        print(f\"✓ Restored from Google Drive: {target_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Warning: Restore failed: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"✓ Backup/restore helper functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Mount Google Drive (Colab only - Kaggle doesn't need this)\n",
    "DRIVE_BACKUP_DIR = None\n",
    "\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        DRIVE_BACKUP_DIR = Path(\"/content/drive/MyDrive/resume-ner-checkpoints\")\n",
    "        DRIVE_BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"✓ Google Drive mounted\")\n",
    "        print(f\"✓ Checkpoint backup directory: {DRIVE_BACKUP_DIR}\")\n",
    "        print(f\"\\nNote: Checkpoints will be automatically saved to this directory after training completes.\")\n",
    "    except ImportError:\n",
    "        print(\"⚠ Warning: google.colab.drive not available. Backup to Google Drive will be disabled.\")\n",
    "        BACKUP_ENABLED = False\n",
    "elif IN_KAGGLE:\n",
    "    print(\"✓ Kaggle environment detected - outputs are automatically persisted (no Drive mount needed)\")\n",
    "else:\n",
    "    print(\"⚠ Warning: Unknown environment. Backup to Google Drive will be disabled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.1: Load Centralized Configs\n",
    "\n",
    "Load and validate all configuration files. Configs are immutable and will be logged with each job for reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step P1-3.1.1: Define Constants\n",
    "\n",
    "Define constants for file and directory names used throughout the notebook. Benchmark settings come from centralized config, not hard-coded here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import constants from centralized module\n",
    "from orchestration import (\n",
    "    METRICS_FILENAME,\n",
    "    BENCHMARK_FILENAME,\n",
    "    CHECKPOINT_DIRNAME,\n",
    "    OUTPUTS_DIRNAME,\n",
    "    MLRUNS_DIRNAME,\n",
    "    DEFAULT_RANDOM_SEED,\n",
    "    DEFAULT_K_FOLDS,\n",
    ")\n",
    "\n",
    "# Note: Benchmark settings (batch_sizes, iterations, etc.) come from configs[\"benchmark\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step P1-3.1.2: Define Helper Functions\n",
    "\n",
    "Reusable helper functions following DRY principle for common operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helper functions from consolidated modules (DRY principle)\n",
    "from typing import List, Optional\n",
    "from orchestration import (\n",
    "    build_mlflow_experiment_name,\n",
    "    setup_mlflow_for_stage,\n",
    "    run_benchmarking,\n",
    ")\n",
    "from shared import verify_output_file\n",
    "\n",
    "# Wrapper function for run_benchmarking that uses notebook-specific paths\n",
    "def run_benchmarking_local(\n",
    "    checkpoint_dir: Path,\n",
    "    test_data_path: Path,\n",
    "    output_path: Path,\n",
    "    batch_sizes: List[int],\n",
    "    iterations: int,\n",
    "    warmup_iterations: int,\n",
    "    max_length: int = 512,\n",
    "    device: Optional[str] = None,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Run benchmarking on a model checkpoint (local notebook wrapper).\n",
    "    \n",
    "    This is a thin wrapper around orchestration.benchmark_utils.run_benchmarking\n",
    "    that automatically uses the notebook's SRC_DIR and ROOT_DIR.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_dir: Path to checkpoint directory.\n",
    "        test_data_path: Path to test data JSON file.\n",
    "        output_path: Path to output benchmark.json file.\n",
    "        batch_sizes: List of batch sizes to test.\n",
    "        iterations: Number of iterations per batch size.\n",
    "        warmup_iterations: Number of warmup iterations.\n",
    "        max_length: Maximum sequence length.\n",
    "        device: Device to use (None = auto-detect).\n",
    "    \n",
    "    Returns:\n",
    "        True if successful, False otherwise.\n",
    "    \"\"\"\n",
    "    return run_benchmarking(\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        test_data_path=test_data_path,\n",
    "        output_path=output_path,\n",
    "        batch_sizes=batch_sizes,\n",
    "        iterations=iterations,\n",
    "        warmup_iterations=warmup_iterations,\n",
    "        max_length=max_length,\n",
    "        device=device,\n",
    "        project_root=ROOT_DIR,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "\n",
    "from orchestration import EXPERIMENT_NAME\n",
    "from orchestration.config_loader import (\n",
    "    ExperimentConfig,\n",
    "    compute_config_hashes,\n",
    "    create_config_metadata,\n",
    "    load_all_configs,\n",
    "    load_experiment_config,\n",
    "    snapshot_configs,\n",
    "    validate_config_immutability,\n",
    ")\n",
    "\n",
    "# P1-3.1: Load Centralized Configs (local-only)\n",
    "# Mirrors the Azure orchestration notebook, but does not create an Azure ML client.\n",
    "\n",
    "if not CONFIG_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Config directory not found: {CONFIG_DIR}\")\n",
    "\n",
    "experiment_config: ExperimentConfig = load_experiment_config(CONFIG_DIR, EXPERIMENT_NAME)\n",
    "configs: Dict[str, Any] = load_all_configs(experiment_config)\n",
    "config_hashes = compute_config_hashes(configs)\n",
    "config_metadata = create_config_metadata(configs, config_hashes)\n",
    "\n",
    "# Immutable snapshots for runtime mutation checks\n",
    "original_configs = snapshot_configs(configs)\n",
    "validate_config_immutability(configs, original_configs)\n",
    "\n",
    "print(f\"Loaded experiment: {experiment_config.name}\")\n",
    "print(\"Loaded config domains:\", sorted(configs.keys()))\n",
    "print(\"Config hashes:\", config_hashes)\n",
    "print(\"Config metadata:\", config_metadata)\n",
    "\n",
    "# Get dataset path from data config (centralized configuration)\n",
    "# The local_path in the data config is relative to the config directory\n",
    "data_config = configs[\"data\"]\n",
    "local_path_str = data_config.get(\"local_path\", \"../dataset\")\n",
    "DATASET_LOCAL_PATH = (CONFIG_DIR / local_path_str).resolve()\n",
    "\n",
    "# Check if seed-based dataset structure (for dataset_tiny with seed subdirectories)\n",
    "seed = data_config.get(\"seed\")\n",
    "if seed is not None and \"dataset_tiny\" in str(DATASET_LOCAL_PATH):\n",
    "    DATASET_LOCAL_PATH = DATASET_LOCAL_PATH / f\"seed{seed}\"\n",
    "\n",
    "print(f\"Dataset path (from data config): {DATASET_LOCAL_PATH}\")\n",
    "if seed is not None:\n",
    "    print(f\"Using seed: {seed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.2: Verify Local Dataset\n",
    "\n",
    "Verify that the dataset directory (specified by `local_path` in the data config) exists and contains the required files. The dataset path is loaded from the centralized data configuration in Step P1-3.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1-3.2: Verify Local Dataset\n",
    "# The dataset path comes from the data config's local_path field (loaded in Step P1-3.1).\n",
    "# This ensures the dataset location is controlled by centralized configuration.\n",
    "# Note: train.json is required, but validation.json is optional (matches training script behavior).\n",
    "\n",
    "REQUIRED_FILE = \"train.json\"\n",
    "OPTIONAL_FILE = \"validation.json\"\n",
    "\n",
    "if not DATASET_LOCAL_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset directory not found: {DATASET_LOCAL_PATH}\\n\"\n",
    "        f\"This path comes from the data config's 'local_path' field.\\n\"\n",
    "        f\"If you need to create the dataset, run the notebook: notebooks/00_make_tiny_dataset.ipynb\"\n",
    "    )\n",
    "\n",
    "# Check required file\n",
    "train_file = DATASET_LOCAL_PATH / REQUIRED_FILE\n",
    "if not train_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Required dataset file not found: {train_file}\\n\"\n",
    "        f\"This path comes from the data config's 'local_path' field.\\n\"\n",
    "        f\"If you need to create it, run the notebook: notebooks/00_make_tiny_dataset.ipynb\"\n",
    "    )\n",
    "\n",
    "# Check optional file\n",
    "val_file = DATASET_LOCAL_PATH / OPTIONAL_FILE\n",
    "has_validation = val_file.exists()\n",
    "\n",
    "print(f\"✓ Dataset directory found: {DATASET_LOCAL_PATH}\")\n",
    "print(f\"  (from data config: {data_config.get('name', 'unknown')} v{data_config.get('version', 'unknown')})\")\n",
    "\n",
    "train_size = train_file.stat().st_size\n",
    "print(f\"  ✓ {REQUIRED_FILE} ({train_size:,} bytes)\")\n",
    "\n",
    "if has_validation:\n",
    "    val_size = val_file.stat().st_size\n",
    "    print(f\"  ✓ {OPTIONAL_FILE} ({val_size:,} bytes)\")\n",
    "else:\n",
    "    print(f\"  ⚠ {OPTIONAL_FILE} not found (optional - training will proceed without validation set)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.2.1: Optional Train/Test Split\n",
    "\n",
    "**Optional step**: Create a train/test split if `test.json` is missing. This is useful when you only have `train.json` and `validation.json` and want to create a separate test set.\n",
    "\n",
    "**⚠ WARNING**: This will overwrite `train.json` with the split version. Only enable if you want to create a permanent train/test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: create train/test split if test.json is missing\n",
    "# WARNING: This will overwrite train.json with the split version\n",
    "# Only enable if you want to create a permanent train/test split\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "from training.data import split_train_test, save_split_files\n",
    "\n",
    "CREATE_TEST_SPLIT = False  # Set True to create test.json when absent (WARNING: overwrites train.json)\n",
    "\n",
    "train_file = DATASET_LOCAL_PATH / \"train.json\"\n",
    "val_file = DATASET_LOCAL_PATH / \"validation.json\"\n",
    "test_file = DATASET_LOCAL_PATH / \"test.json\"\n",
    "\n",
    "if CREATE_TEST_SPLIT and not test_file.exists():\n",
    "    # Backup original train.json before overwriting\n",
    "    backup_file = DATASET_LOCAL_PATH / \"train.json.backup\"\n",
    "    if train_file.exists() and not backup_file.exists():\n",
    "        import shutil\n",
    "        shutil.copy2(train_file, backup_file)\n",
    "        print(f\"⚠ Backed up original train.json to {backup_file}\")\n",
    "    \n",
    "    full_dataset = []\n",
    "    # Start with train data; optionally include validation to maximize coverage\n",
    "    with open(train_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        full_dataset.extend(json.load(f))\n",
    "    if val_file.exists():\n",
    "        with open(val_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            full_dataset.extend(json.load(f))\n",
    "\n",
    "    split_cfg = configs.get(\"data\", {}).get(\"splitting\", {})\n",
    "    train_ratio = split_cfg.get(\"train_test_ratio\", 0.8)\n",
    "    stratified = split_cfg.get(\"stratified\", False)\n",
    "    random_seed = split_cfg.get(\"random_seed\", 42)\n",
    "    entity_types = configs.get(\"data\", {}).get(\"schema\", {}).get(\"entity_types\", [])\n",
    "\n",
    "    print(f\"Creating train/test split (train_ratio={train_ratio}, stratified={stratified})...\")\n",
    "    print(f\"⚠ WARNING: This will overwrite train.json with {int(len(full_dataset) * train_ratio)} samples\")\n",
    "    \n",
    "    new_train, new_test = split_train_test(\n",
    "        dataset=full_dataset,\n",
    "        train_ratio=train_ratio,\n",
    "        stratified=stratified,\n",
    "        random_seed=random_seed,\n",
    "        entity_types=entity_types,\n",
    "    )\n",
    "\n",
    "    save_split_files(DATASET_LOCAL_PATH, new_train, new_test)\n",
    "    print(f\"✓ Wrote train.json ({len(new_train)}) and test.json ({len(new_test)})\")\n",
    "elif test_file.exists():\n",
    "    print(f\"✓ Found existing test.json at {test_file}\")\n",
    "else:\n",
    "    print(\"⚠ test.json not found. Set CREATE_TEST_SPLIT=True to generate a split.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.3: Setup Local Environment\n",
    "\n",
    "Verify GPU availability, set up MLflow tracking (local file store), and check that key dependencies are installed. This step ensures the local environment is ready for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "DEFAULT_DEVICE = \"cuda\"\n",
    "\n",
    "env_config = configs[\"env\"]\n",
    "device_type = env_config.get(\"compute\", {}).get(\"device\", DEFAULT_DEVICE)\n",
    "\n",
    "if device_type == \"cuda\" and not torch.cuda.is_available():\n",
    "    raise RuntimeError(\n",
    "        \"CUDA device requested but not available. \"\n",
    "        \"In Colab, ensure you've selected a GPU runtime: Runtime > Change runtime type > GPU\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "MLFLOW_DIR = \"mlruns\"\n",
    "mlflow_tracking_path = ROOT_DIR / MLFLOW_DIR\n",
    "mlflow_tracking_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Convert path to file:// URI format for MLflow\n",
    "mlflow_tracking_uri = mlflow_tracking_path.as_uri()\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "    import optuna\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"Required package not installed: {e}\")\n",
    "\n",
    "REQUIRED_PACKAGES = {\n",
    "    \"torch\": torch,\n",
    "    \"transformers\": transformers,\n",
    "    \"mlflow\": mlflow,\n",
    "    \"optuna\": optuna,\n",
    "}\n",
    "\n",
    "for name, module in REQUIRED_PACKAGES.items():\n",
    "    if not hasattr(module, \"__version__\"):\n",
    "        raise ImportError(f\"Required package '{name}' is not properly installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.4: The Dry Run\n",
    "\n",
    "Run a minimal HPO sweep to validate the training pipeline works correctly before launching the full HPO sweep. Uses the smoke HPO configuration with reduced trials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib.util\n",
    "from orchestration import STAGE_SMOKE\n",
    "\n",
    "# Import local_sweeps directly to avoid triggering Azure ML imports in __init__.py\n",
    "local_sweeps_spec = importlib.util.spec_from_file_location(\n",
    "    \"local_sweeps\", SRC_DIR / \"orchestration\" / \"jobs\" / \"local_sweeps.py\"\n",
    ")\n",
    "local_sweeps = importlib.util.module_from_spec(local_sweeps_spec)\n",
    "local_sweeps_spec.loader.exec_module(local_sweeps)\n",
    "run_local_hpo_sweep = local_sweeps.run_local_hpo_sweep\n",
    "\n",
    "TRAINING_SCRIPT_PATH = SRC_DIR / \"train.py\"\n",
    "DRY_RUN_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"dry_run\"\n",
    "\n",
    "if not TRAINING_SCRIPT_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Training script not found: {TRAINING_SCRIPT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_config = configs[\"hpo\"]\n",
    "train_config = configs[\"train\"]\n",
    "backbone_values = hpo_config[\"search_space\"][\"backbone\"][\"values\"]\n",
    "\n",
    "dry_run_studies = {}\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    mlflow_experiment_name = f\"{experiment_config.name}-{STAGE_SMOKE}-{backbone}\"\n",
    "    backbone_output_dir = DRY_RUN_OUTPUT_DIR / backbone\n",
    "    \n",
    "    study = run_local_hpo_sweep(\n",
    "        dataset_path=str(DATASET_LOCAL_PATH),\n",
    "        config_dir=CONFIG_DIR,\n",
    "        backbone=backbone,\n",
    "        hpo_config=hpo_config,\n",
    "        train_config=train_config,\n",
    "        output_dir=backbone_output_dir,\n",
    "        mlflow_experiment_name=mlflow_experiment_name,\n",
    "    )\n",
    "    \n",
    "    dry_run_studies[backbone] = study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hpo_config from configs (loaded in cell 18 for dry run)\n",
    "dry_run_hpo_config = configs[\"hpo\"]\n",
    "objective_metric = dry_run_hpo_config['objective']['metric']\n",
    "\n",
    "for backbone, study in dry_run_studies.items():\n",
    "    if study.trials:\n",
    "        best_trial = study.best_trial\n",
    "        print(f\"{backbone}: {len(study.trials)} trials completed\")\n",
    "        print(f\"  Best {objective_metric}: {best_trial.value:.4f}\")\n",
    "        print(f\"  Best params: {best_trial.params}\")\n",
    "    else:\n",
    "        print(f\"{backbone}: No trials completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.5.1: The Sweep (HPO) - Local with Optuna\n",
    "\n",
    "Run the full hyperparameter optimization sweep using Optuna to systematically search for the best model configuration. Uses the production HPO configuration with more trials than the dry run.\n",
    "\n",
    "**Note on K-Fold Cross-Validation:**\n",
    "- When k-fold CV is enabled (`k_fold.enabled: true`), each trial trains **k models** (one per fold) and returns the **average metric** across folds\n",
    "- The number of **trials** is controlled by `sampling.max_trials` (e.g., 2 trials in smoke.yaml)\n",
    "- With k=5 folds and 2 trials: **2 trials × 5 folds = 10 model trainings total**\n",
    "- K-fold CV provides more robust hyperparameter evaluation but increases compute time (k× per trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib.util\n",
    "from orchestration import STAGE_HPO\n",
    "\n",
    "# Import local_sweeps directly to avoid triggering Azure ML imports in __init__.py\n",
    "local_sweeps_spec = importlib.util.spec_from_file_location(\n",
    "    \"local_sweeps\", SRC_DIR / \"orchestration\" / \"jobs\" / \"local_sweeps.py\"\n",
    ")\n",
    "local_sweeps = importlib.util.module_from_spec(local_sweeps_spec)\n",
    "local_sweeps_spec.loader.exec_module(local_sweeps)\n",
    "run_local_hpo_sweep = local_sweeps.run_local_hpo_sweep\n",
    "\n",
    "# Constants are imported from orchestration module (see Step P1-3.1.1)\n",
    "HPO_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"hpo\"\n",
    "HPO_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use HPO config already loaded in configs (from Step P1-3.1)\n",
    "# Following DRY principle - don't reload configs that are already available\n",
    "hpo_config = configs[\"hpo\"]\n",
    "train_config = configs[\"train\"]\n",
    "backbone_values = hpo_config[\"search_space\"][\"backbone\"][\"values\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.5.0: Setup K-Fold Splits and Google Drive Backup for HPO Trials\n",
    "\n",
    "**K-Fold Cross-Validation Setup**: If k-fold CV is enabled in the HPO config, create and save fold splits before starting the sweep.\n",
    "\n",
    "**Colab-specific feature**: Configure automatic backup of each HPO trial to Google Drive immediately after completion. This prevents data loss if the Colab session disconnects during long-running hyperparameter optimization sweeps.\n",
    "\n",
    "Each trial's results (including `metrics.json` and checkpoint) are automatically backed up to Google Drive as soon as the trial completes, ensuring no progress is lost even if the session times out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.cv_utils import create_kfold_splits, save_fold_splits, validate_splits\n",
    "from training.data import load_dataset\n",
    "\n",
    "# Setup k-fold splits if enabled\n",
    "k_fold_config = hpo_config.get(\"k_fold\", {})\n",
    "k_folds_enabled = k_fold_config.get(\"enabled\", False)\n",
    "fold_splits_file = None\n",
    "\n",
    "if k_folds_enabled:\n",
    "    n_splits = k_fold_config.get(\"n_splits\", DEFAULT_K_FOLDS)\n",
    "    random_seed = k_fold_config.get(\"random_seed\", DEFAULT_RANDOM_SEED)\n",
    "    shuffle = k_fold_config.get(\"shuffle\", True)\n",
    "    stratified = k_fold_config.get(\"stratified\", False)\n",
    "    entity_types = configs.get(\"data\", {}).get(\"schema\", {}).get(\"entity_types\", [])\n",
    "    \n",
    "    print(f\"Setting up {n_splits}-fold cross-validation splits...\")\n",
    "    full_dataset = load_dataset(str(DATASET_LOCAL_PATH))\n",
    "    train_data = full_dataset.get(\"train\", [])\n",
    "    \n",
    "    fold_splits = create_kfold_splits(\n",
    "        dataset=train_data,\n",
    "        k=n_splits,\n",
    "        random_seed=random_seed,\n",
    "        shuffle=shuffle,\n",
    "        stratified=stratified,\n",
    "        entity_types=entity_types,\n",
    "    )\n",
    "    \n",
    "    # Optional validation to ensure rare entities appear across folds\n",
    "    validate_splits(train_data, fold_splits, entity_types=entity_types)\n",
    "    \n",
    "    HPO_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    fold_splits_file = HPO_OUTPUT_DIR / \"fold_splits.json\"\n",
    "    save_fold_splits(\n",
    "        fold_splits,\n",
    "        fold_splits_file,\n",
    "        metadata={\n",
    "            \"k\": n_splits,\n",
    "            \"random_seed\": random_seed,\n",
    "            \"shuffle\": shuffle,\n",
    "            \"stratified\": stratified,\n",
    "            \"dataset_path\": str(DATASET_LOCAL_PATH),\n",
    "        }\n",
    "    )\n",
    "    print(f\"✓ K-fold splits saved to: {fold_splits_file}\")\n",
    "else:\n",
    "    print(\"K-fold CV disabled - using single train/validation split\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab-specific: Google Drive backup callback for HPO trials\n",
    "# This ensures trial results are persisted immediately after completion to prevent data loss\n",
    "# if the Colab session disconnects.\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional\n",
    "import optuna\n",
    "from orchestration import METRICS_FILENAME\n",
    "\n",
    "\n",
    "class DriveBackupTrialCallback:\n",
    "    \"\"\"Optuna callback to backup trial results to Google Drive after each trial completes.\n",
    "    \n",
    "    This callback is Colab-specific and automatically backs up each completed trial's\n",
    "    directory (including metrics.json and checkpoint) to Google Drive to prevent data\n",
    "    loss if the Colab session disconnects.\n",
    "    \n",
    "    Attributes:\n",
    "        output_base_dir: Base directory where trials are saved (e.g., HPO_OUTPUT_DIR / backbone)\n",
    "        backbone: Model backbone name for organizing backups in Google Drive\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_base_dir: Path, backbone: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the backup callback.\n",
    "        \n",
    "        Args:\n",
    "            output_base_dir: Base directory where trials are saved.\n",
    "            backbone: Model backbone name for organizing backups.\n",
    "        \"\"\"\n",
    "        self.output_base_dir = output_base_dir\n",
    "        self.backbone = backbone\n",
    "    \n",
    "    def __call__(self, study: optuna.Study, trial: optuna.trial.FrozenTrial) -> None:\n",
    "        \"\"\"Execute backup after trial completes.\n",
    "        \n",
    "        Args:\n",
    "            study: Optuna study object (unused but required by callback interface).\n",
    "            trial: Completed trial object containing trial number and state.\n",
    "        \"\"\"\n",
    "        if trial.state != optuna.trial.TrialState.COMPLETE:\n",
    "            return\n",
    "        \n",
    "        if not BACKUP_ENABLED or not DRIVE_BACKUP_DIR:\n",
    "            return\n",
    "        \n",
    "        trial_output_dir = self._find_trial_directory(trial.number)\n",
    "        if not trial_output_dir or not self._trial_completed_successfully(trial_output_dir):\n",
    "            return\n",
    "        \n",
    "        backup_name = f\"hpo_{self.backbone}_trial_{trial.number}\"\n",
    "        success = backup_to_drive(\n",
    "            source_path=trial_output_dir,\n",
    "            backup_name=backup_name,\n",
    "            is_directory=True\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            print(f\"  ✓ Trial {trial.number} backed up to Google Drive\")\n",
    "        else:\n",
    "            print(f\"  ⚠ Warning: Failed to backup trial {trial.number}\")\n",
    "    \n",
    "    def _find_trial_directory(self, trial_number: int) -> Optional[Path]:\n",
    "        \"\"\"Find the trial output directory, handling both regular and CV trials.\n",
    "        \n",
    "        Args:\n",
    "            trial_number: Trial number to find directory for.\n",
    "            \n",
    "        Returns:\n",
    "            Path to trial directory, or None if not found.\n",
    "        \"\"\"\n",
    "        trial_dir_name = f\"trial_{trial_number}\"\n",
    "        trial_output_dir = self.output_base_dir / trial_dir_name\n",
    "        \n",
    "        if trial_output_dir.exists():\n",
    "            return trial_output_dir\n",
    "        \n",
    "        fold_dirs = list(self.output_base_dir.glob(f\"trial_{trial_number}_fold*\"))\n",
    "        if fold_dirs:\n",
    "            fold_dirs.sort(key=lambda x: int(x.name.split('fold')[-1]) if 'fold' in x.name else 0)\n",
    "            return fold_dirs[-1]\n",
    "        \n",
    "        print(f\"⚠ Warning: Trial {trial_number} output directory not found\")\n",
    "        return None\n",
    "    \n",
    "    def _trial_completed_successfully(self, trial_output_dir: Path) -> bool:\n",
    "        \"\"\"Check if trial completed successfully by verifying metrics.json exists.\n",
    "        \n",
    "        Args:\n",
    "            trial_output_dir: Path to trial output directory.\n",
    "            \n",
    "        Returns:\n",
    "            True if metrics.json exists, False otherwise.\n",
    "        \"\"\"\n",
    "        metrics_file = trial_output_dir / METRICS_FILENAME\n",
    "        if not metrics_file.exists():\n",
    "            print(f\"⚠ Warning: Trial {trial_output_dir.name} metrics.json not found, skipping backup\")\n",
    "            return False\n",
    "        return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab-specific wrapper function that adds Google Drive backup to HPO sweep\n",
    "# This recreates the study setup from run_local_hpo_sweep but adds our backup callback\n",
    "\n",
    "from typing import Any, Optional\n",
    "\n",
    "\n",
    "def run_local_hpo_sweep_with_backup(\n",
    "    dataset_path: str,\n",
    "    config_dir: Path,\n",
    "    backbone: str,\n",
    "    hpo_config: dict,\n",
    "    train_config: dict,\n",
    "    output_dir: Path,\n",
    "    mlflow_experiment_name: str,\n",
    "    k_folds: Optional[int] = None,\n",
    "    fold_splits_file: Optional[Path] = None,\n",
    ") -> Any:\n",
    "    \"\"\"Run HPO sweep with automatic Google Drive backup after each trial.\n",
    "    \n",
    "    This is a Colab-specific wrapper around run_local_hpo_sweep that adds automatic\n",
    "    backup of each trial to Google Drive immediately after completion. This prevents\n",
    "    data loss if the Colab session disconnects during long-running HPO sweeps.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to dataset directory.\n",
    "        config_dir: Path to configuration directory.\n",
    "        backbone: Model backbone name.\n",
    "        hpo_config: HPO configuration dictionary.\n",
    "        train_config: Training configuration dictionary.\n",
    "        output_dir: Base output directory for all trials.\n",
    "        mlflow_experiment_name: MLflow experiment name.\n",
    "        k_folds: Number of folds for k-fold CV (None = no CV).\n",
    "        fold_splits_file: Path to fold splits file (for k-fold CV).\n",
    "    \n",
    "    Returns:\n",
    "        Optuna study object with completed trials.\n",
    "    \"\"\"\n",
    "    optuna_module, _, RandomSampler, _ = local_sweeps._import_optuna()\n",
    "    \n",
    "    objective_metric = hpo_config[\"objective\"][\"metric\"]\n",
    "    goal = hpo_config[\"objective\"][\"goal\"]\n",
    "    direction = \"maximize\" if goal == \"maximize\" else \"minimize\"\n",
    "    \n",
    "    pruner = local_sweeps.create_optuna_pruner(hpo_config)\n",
    "    algorithm = hpo_config[\"sampling\"][\"algorithm\"].lower()\n",
    "    sampler = RandomSampler() if algorithm == \"random\" else RandomSampler()\n",
    "    \n",
    "    print(f\"\\n[HPO] Starting optimization for {backbone} (with Google Drive backup)...\")\n",
    "    study = optuna_module.create_study(\n",
    "        direction=direction,\n",
    "        sampler=sampler,\n",
    "        pruner=pruner,\n",
    "        study_name=f\"hpo_{backbone}\",\n",
    "    )\n",
    "    \n",
    "    objective = local_sweeps.create_local_hpo_objective(\n",
    "        dataset_path=dataset_path,\n",
    "        config_dir=config_dir,\n",
    "        backbone=backbone,\n",
    "        hpo_config=hpo_config,\n",
    "        train_config=train_config,\n",
    "        output_base_dir=output_dir,\n",
    "        mlflow_experiment_name=mlflow_experiment_name,\n",
    "        objective_metric=objective_metric,\n",
    "        k_folds=k_folds,\n",
    "        fold_splits_file=fold_splits_file,\n",
    "    )\n",
    "    \n",
    "    backup_callback = DriveBackupTrialCallback(\n",
    "        output_base_dir=output_dir,\n",
    "        backbone=backbone,\n",
    "    )\n",
    "    \n",
    "    def display_metrics_callback(study: Any, trial: Any) -> None:\n",
    "        \"\"\"Display additional metrics after trial completes.\"\"\"\n",
    "        optuna_module, _, _, _ = local_sweeps._import_optuna()\n",
    "        if trial.state == optuna_module.trial.TrialState.COMPLETE:\n",
    "            attrs = trial.user_attrs\n",
    "            extra_info = []\n",
    "            \n",
    "            if \"macro_f1_span\" in attrs:\n",
    "                extra_info.append(f\"macro-f1-span={attrs['macro_f1_span']:.6f}\")\n",
    "            if \"loss\" in attrs:\n",
    "                extra_info.append(f\"loss={attrs['loss']:.6f}\")\n",
    "            if \"avg_entity_f1\" in attrs:\n",
    "                entity_count = attrs.get(\"entity_count\", \"?\")\n",
    "                extra_info.append(f\"avg_entity_f1={attrs['avg_entity_f1']:.6f} ({entity_count} entities)\")\n",
    "            \n",
    "            if extra_info:\n",
    "                print(f\"  Additional metrics: {' | '.join(extra_info)}\")\n",
    "    \n",
    "    def combined_callback(study: Any, trial: Any) -> None:\n",
    "        \"\"\"Combined callback that displays metrics and backs up to Google Drive.\"\"\"\n",
    "        display_metrics_callback(study, trial)\n",
    "        backup_callback(study, trial)\n",
    "    \n",
    "    max_trials = hpo_config[\"sampling\"][\"max_trials\"]\n",
    "    timeout_minutes = hpo_config[\"sampling\"][\"timeout_minutes\"]\n",
    "    timeout_seconds = timeout_minutes * 60\n",
    "    \n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=max_trials,\n",
    "        timeout=timeout_seconds,\n",
    "        show_progress_bar=True,\n",
    "        callbacks=[combined_callback],\n",
    "    )\n",
    "    \n",
    "    return study\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_studies = {}\n",
    "k_folds_param = k_fold_config.get(\"n_splits\", DEFAULT_K_FOLDS) if k_folds_enabled else None\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    mlflow_experiment_name = build_mlflow_experiment_name(\n",
    "        experiment_config.name, STAGE_HPO, backbone\n",
    "    )\n",
    "    backbone_output_dir = HPO_OUTPUT_DIR / backbone\n",
    "    \n",
    "    # Use Colab-specific wrapper with automatic Google Drive backup\n",
    "    study = run_local_hpo_sweep_with_backup(\n",
    "        dataset_path=str(DATASET_LOCAL_PATH),\n",
    "        config_dir=CONFIG_DIR,\n",
    "        backbone=backbone,\n",
    "        hpo_config=hpo_config,\n",
    "        train_config=train_config,\n",
    "        output_dir=backbone_output_dir,\n",
    "        mlflow_experiment_name=mlflow_experiment_name,\n",
    "        k_folds=k_folds_param,\n",
    "        fold_splits_file=fold_splits_file,\n",
    "    )\n",
    "    \n",
    "    hpo_studies[backbone] = study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cv_statistics(best_trial):\n",
    "    if not hasattr(best_trial, \"user_attrs\"):\n",
    "        return None\n",
    "    cv_mean = best_trial.user_attrs.get(\"cv_mean\")\n",
    "    cv_std = best_trial.user_attrs.get(\"cv_std\")\n",
    "    return (cv_mean, cv_std) if cv_mean is not None else None\n",
    "\n",
    "objective_metric = hpo_config['objective']['metric']\n",
    "\n",
    "for backbone, study in hpo_studies.items():\n",
    "    if not study.trials:\n",
    "        continue\n",
    "    \n",
    "    best_trial = study.best_trial\n",
    "    cv_stats = extract_cv_statistics(best_trial)\n",
    "    \n",
    "    print(f\"{backbone}: {len(study.trials)} trials completed\")\n",
    "    print(f\"  Best {objective_metric}: {best_trial.value:.4f}\")\n",
    "    print(f\"  Best params: {best_trial.params}\")\n",
    "    \n",
    "    if cv_stats:\n",
    "        cv_mean, cv_std = cv_stats\n",
    "        print(f\"  CV Statistics: Mean: {cv_mean:.4f} ± {cv_std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.5.2: Benchmarking Best Trials\n",
    "\n",
    "Benchmark the best trial from each backbone to measure actual inference performance. This provides real latency data that replaces parameter-count proxies in model selection, enabling more accurate speed comparisons.\n",
    "\n",
    "**Workflow:**\n",
    "1. Identify best trial per backbone (from HPO results)\n",
    "2. Run benchmarking on each best trial checkpoint\n",
    "3. Save benchmark results as `benchmark.json` in trial directories\n",
    "4. Model selection will automatically use this data when available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestration.jobs.local_selection import load_best_trial_from_disk\n",
    "import json\n",
    "\n",
    "# Load benchmark config (if available)\n",
    "benchmark_config = configs.get(\"benchmark\", {})\n",
    "benchmark_settings = benchmark_config.get(\"benchmarking\", {})\n",
    "\n",
    "# Get benchmark parameters from config or use defaults\n",
    "benchmark_batch_sizes = benchmark_settings.get(\"batch_sizes\", [1, 8, 16])\n",
    "benchmark_iterations = benchmark_settings.get(\"iterations\", 100)\n",
    "benchmark_warmup = benchmark_settings.get(\"warmup_iterations\", 10)\n",
    "benchmark_max_length = benchmark_settings.get(\"max_length\", 512)\n",
    "benchmark_device = benchmark_settings.get(\"device\")\n",
    "\n",
    "# Get test data path from benchmark config or data config\n",
    "test_data_path_str = benchmark_settings.get(\"test_data\")\n",
    "if test_data_path_str:\n",
    "    test_data_path = (CONFIG_DIR / test_data_path_str).resolve()\n",
    "else:\n",
    "    # Fallback to dataset directory\n",
    "    test_data_path = DATASET_LOCAL_PATH / \"test.json\"\n",
    "\n",
    "if not test_data_path.exists():\n",
    "    print(f\"Warning: Test data not found at {test_data_path}\")\n",
    "    print(\"Benchmarking will be skipped. Model selection will use parameter proxy.\")\n",
    "    test_data_path = None\n",
    "\n",
    "# Identify best trials per backbone\n",
    "objective_metric = hpo_config[\"objective\"][\"metric\"]\n",
    "best_trials = {}\n",
    "\n",
    "for backbone in backbone_values:\n",
    "    best_trial_info = load_best_trial_from_disk(\n",
    "        HPO_OUTPUT_DIR,\n",
    "        backbone,\n",
    "        objective_metric\n",
    "    )\n",
    "    if best_trial_info:\n",
    "        best_trials[backbone] = best_trial_info\n",
    "        print(f\"{backbone}: Best trial is {best_trial_info['trial_name']} \"\n",
    "              f\"({objective_metric}={best_trial_info['accuracy']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarking on best trials\n",
    "if test_data_path and test_data_path.exists():\n",
    "    benchmark_results = {}\n",
    "    \n",
    "    for backbone, trial_info in best_trials.items():\n",
    "        trial_dir = Path(trial_info[\"trial_dir\"])\n",
    "        checkpoint_dir = trial_dir / CHECKPOINT_DIRNAME\n",
    "        benchmark_output = trial_dir / BENCHMARK_FILENAME\n",
    "        \n",
    "        if not checkpoint_dir.exists():\n",
    "            print(f\"Warning: Checkpoint not found for {backbone} {trial_info['trial_name']}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nBenchmarking {backbone} ({trial_info['trial_name']})...\")\n",
    "        \n",
    "        success = run_benchmarking_local(\n",
    "            checkpoint_dir=checkpoint_dir,\n",
    "            test_data_path=test_data_path,\n",
    "            output_path=benchmark_output,\n",
    "            batch_sizes=benchmark_batch_sizes,\n",
    "            iterations=benchmark_iterations,\n",
    "            warmup_iterations=benchmark_warmup,\n",
    "            max_length=benchmark_max_length,\n",
    "            device=benchmark_device,\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            benchmark_results[backbone] = benchmark_output\n",
    "            print(f\"✓ Benchmark completed: {benchmark_output}\")\n",
    "        else:\n",
    "            print(f\"✗ Benchmark failed for {backbone}\")\n",
    "    \n",
    "    print(f\"\\n✓ Benchmarking complete. {len(benchmark_results)}/{len(best_trials)} trials benchmarked.\")\n",
    "else:\n",
    "    print(\"Skipping benchmarking (test data not available)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify benchmark files were created\n",
    "if test_data_path and test_data_path.exists():\n",
    "    for backbone, trial_info in best_trials.items():\n",
    "        trial_dir = Path(trial_info[\"trial_dir\"])\n",
    "        benchmark_file = trial_dir / BENCHMARK_FILENAME\n",
    "        \n",
    "        if benchmark_file.exists():\n",
    "            with open(benchmark_file, \"r\") as f:\n",
    "                benchmark_data = json.load(f)\n",
    "            batch_1_latency = benchmark_data.get(\"batch_1\", {}).get(\"mean_ms\", \"N/A\")\n",
    "            print(f\"{backbone}: benchmark.json exists (batch_1 latency: {batch_1_latency} ms)\")\n",
    "        else:\n",
    "            print(f\"{backbone}: benchmark.json not found (will use parameter proxy)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.6: Best Configuration Selection (Automated)\n",
    "\n",
    "Programmatically select the best configuration from all HPO sweep runs across all backbone models. The best configuration is determined by the objective metric specified in the HPO config.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib.util\n",
    "from shared.json_cache import save_json\n",
    "\n",
    "# Import local_selection directly to avoid triggering Azure ML imports in __init__.py\n",
    "local_selection_spec = importlib.util.spec_from_file_location(\n",
    "    \"local_selection\", SRC_DIR / \"orchestration\" / \"jobs\" / \"local_selection.py\"\n",
    ")\n",
    "local_selection = importlib.util.module_from_spec(local_selection_spec)\n",
    "local_selection_spec.loader.exec_module(local_selection)\n",
    "select_best_configuration_across_studies = local_selection.select_best_configuration_across_studies\n",
    "\n",
    "BEST_CONFIG_CACHE_FILE = ROOT_DIR / \"notebooks\" / \"best_configuration_cache.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_version = data_config.get(\"version\", \"unknown\")\n",
    "\n",
    "# Select best configuration with accuracy-speed tradeoff\n",
    "# Supports both in-memory studies and disk-based selection\n",
    "# Uses threshold from hpo_config[\"selection\"] if configured\n",
    "\n",
    "# Option 1: Use in-memory studies (if notebook still running)\n",
    "if 'hpo_studies' in locals() and hpo_studies:\n",
    "    best_configuration = select_best_configuration_across_studies(\n",
    "        studies=hpo_studies,\n",
    "        hpo_config=hpo_config,\n",
    "        dataset_version=dataset_version,\n",
    "        # Uses accuracy_threshold from hpo_config[\"selection\"] if set\n",
    "    )\n",
    "else:\n",
    "    # Option 2: Load from disk (works after notebook restart)\n",
    "    HPO_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"hpo\"\n",
    "    best_configuration = select_best_configuration_across_studies(\n",
    "        studies=None,  # No in-memory studies\n",
    "        hpo_config=hpo_config,\n",
    "        dataset_version=dataset_version,\n",
    "        hpo_output_dir=HPO_OUTPUT_DIR,  # Load from saved metrics.json files\n",
    "        # Uses accuracy_threshold from hpo_config[\"selection\"] if set\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(BEST_CONFIG_CACHE_FILE, best_configuration)\n",
    "\n",
    "print(f\"Best configuration selected:\")\n",
    "print(f\"  Backbone: {best_configuration.get('backbone')}\")\n",
    "print(f\"  Trial: {best_configuration.get('trial_name')}\")\n",
    "print(f\"  Best {hpo_config['objective']['metric']}: {best_configuration.get('selection_criteria', {}).get('best_value'):.4f}\")\n",
    "\n",
    "# Show selection reasoning (if available)\n",
    "selection_criteria = best_configuration.get('selection_criteria', {})\n",
    "if 'reason' in selection_criteria:\n",
    "    print(f\"  Selection reason: {selection_criteria['reason']}\")\n",
    "if 'accuracy_diff_from_best' in selection_criteria:\n",
    "    print(f\"  Accuracy difference from best: {selection_criteria['accuracy_diff_from_best']:.4f}\")\n",
    "\n",
    "# Show all candidates (if available)\n",
    "if 'all_candidates' in selection_criteria:\n",
    "    print(f\"\\nAll candidates considered:\")\n",
    "    for c in selection_criteria['all_candidates']:\n",
    "        marker = \"✓\" if c['backbone'] == best_configuration.get('backbone') else \" \"\n",
    "        print(f\"  {marker} {c['backbone']}: acc={c['accuracy']:.4f}, speed={c['speed_score']:.2f}x\")\n",
    "\n",
    "print(f\"\\nSaved to: {BEST_CONFIG_CACHE_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-3.7: Final Training (Post-HPO, Single Run)\n",
    "\n",
    "Train the final production model using the best configuration from HPO with stable, controlled conditions. This uses the full training epochs (no early stopping) and the best hyperparameters found during HPO.\n",
    "\n",
    "**Note**: After training completes, the checkpoint will be automatically backed up to Google Drive for persistence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import mlflow\n",
    "from shared.json_cache import load_json, save_json\n",
    "from orchestration import STAGE_TRAINING\n",
    "\n",
    "# Define build_final_training_config locally to avoid importing Azure ML dependencies\n",
    "# This function doesn't use Azure ML, so we can define it here\n",
    "def build_final_training_config(\n",
    "    best_config: dict,\n",
    "    train_config: dict,\n",
    "    random_seed: int = 42,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Build final training configuration by merging best HPO config with train.yaml defaults.\n",
    "    \"\"\"\n",
    "    hyperparameters = best_config.get(\"hyperparameters\", {})\n",
    "    training_defaults = train_config.get(\"training\", {})\n",
    "    \n",
    "    return {\n",
    "        \"backbone\": best_config[\"backbone\"],\n",
    "        \"learning_rate\": hyperparameters.get(\"learning_rate\", training_defaults.get(\"learning_rate\", 2e-5)),\n",
    "        \"dropout\": hyperparameters.get(\"dropout\", training_defaults.get(\"dropout\", 0.1)),\n",
    "        \"weight_decay\": hyperparameters.get(\"weight_decay\", training_defaults.get(\"weight_decay\", 0.01)),\n",
    "        \"batch_size\": training_defaults.get(\"batch_size\", 16),\n",
    "        \"epochs\": training_defaults.get(\"epochs\", 5),\n",
    "        \"random_seed\": random_seed,\n",
    "        \"early_stopping_enabled\": False,\n",
    "        \"use_combined_data\": True,\n",
    "        \"use_all_data\": True,\n",
    "    }\n",
    "\n",
    "DEFAULT_RANDOM_SEED = 42\n",
    "BEST_CONFIG_CACHE_FILE = ROOT_DIR / \"notebooks\" / \"best_configuration_cache.json\"\n",
    "FINAL_TRAINING_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"final_training\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_configuration = load_json(BEST_CONFIG_CACHE_FILE, default=None)\n",
    "\n",
    "if best_configuration is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Best configuration cache not found: {BEST_CONFIG_CACHE_FILE}\\n\"\n",
    "        f\"Please run Step P1-3.6: Best Configuration Selection first.\"\n",
    "    )\n",
    "\n",
    "final_training_config = build_final_training_config(\n",
    "    best_config=best_configuration,\n",
    "    train_config=configs[\"train\"],\n",
    "    random_seed=DEFAULT_RANDOM_SEED,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_experiment_name = f\"{experiment_config.name}-{STAGE_TRAINING}-{final_training_config['backbone']}\"\n",
    "final_output_dir = FINAL_TRAINING_OUTPUT_DIR / final_training_config['backbone']\n",
    "final_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mlflow.set_experiment(mlflow_experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_script_path = SRC_DIR / \"train.py\"\n",
    "training_args = [\n",
    "    sys.executable,\n",
    "    str(training_script_path),\n",
    "    \"--data-asset\",\n",
    "    str(DATASET_LOCAL_PATH),\n",
    "    \"--config-dir\",\n",
    "    str(CONFIG_DIR),\n",
    "    \"--backbone\",\n",
    "    final_training_config[\"backbone\"],\n",
    "    \"--learning-rate\",\n",
    "    str(final_training_config[\"learning_rate\"]),\n",
    "    \"--batch-size\",\n",
    "    str(final_training_config[\"batch_size\"]),\n",
    "    \"--dropout\",\n",
    "    str(final_training_config[\"dropout\"]),\n",
    "    \"--weight-decay\",\n",
    "    str(final_training_config[\"weight_decay\"]),\n",
    "    \"--epochs\",\n",
    "    str(final_training_config[\"epochs\"]),\n",
    "    \"--random-seed\",\n",
    "    str(final_training_config[\"random_seed\"]),\n",
    "    \"--early-stopping-enabled\",\n",
    "    str(final_training_config[\"early_stopping_enabled\"]).lower(),\n",
    "    \"--use-combined-data\",\n",
    "    str(final_training_config[\"use_combined_data\"]).lower(),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_env = os.environ.copy()\n",
    "training_env[\"AZURE_ML_OUTPUT_checkpoint\"] = str(final_output_dir)\n",
    "\n",
    "mlflow_tracking_uri = mlflow.get_tracking_uri()\n",
    "if mlflow_tracking_uri:\n",
    "    training_env[\"MLFLOW_TRACKING_URI\"] = mlflow_tracking_uri\n",
    "training_env[\"MLFLOW_EXPERIMENT_NAME\"] = mlflow_experiment_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(\n",
    "    training_args,\n",
    "    cwd=ROOT_DIR,\n",
    "    env=training_env,\n",
    "    capture_output=False,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "if result.returncode != 0:\n",
    "    raise RuntimeError(f\"Final training failed with return code {result.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Constants are imported from orchestration module (see Step P1-3.1.1)\n",
    "FINAL_TRAINING_CACHE_FILE = ROOT_DIR / \"notebooks\" / \"final_training_cache.json\"\n",
    "\n",
    "# Check actual checkpoint location\n",
    "# The training script may save to outputs/checkpoint instead of final_output_dir/checkpoint\n",
    "actual_checkpoint = ROOT_DIR / \"outputs\" / \"checkpoint\"\n",
    "actual_metrics = ROOT_DIR / \"outputs\" / METRICS_FILENAME\n",
    "expected_checkpoint = final_output_dir / \"checkpoint\"\n",
    "expected_metrics = final_output_dir / METRICS_FILENAME\n",
    "\n",
    "print(\"Checking training completion...\")\n",
    "print(f\"  Expected checkpoint: {expected_checkpoint} (exists: {expected_checkpoint.exists()})\")\n",
    "print(f\"  Actual checkpoint: {actual_checkpoint} (exists: {actual_checkpoint.exists()})\")\n",
    "print(f\"  Expected metrics: {expected_metrics} (exists: {expected_metrics.exists()})\")\n",
    "print(f\"  Actual metrics: {actual_metrics} (exists: {actual_metrics.exists()})\")\n",
    "\n",
    "# Determine which checkpoint and metrics to use\n",
    "checkpoint_source = None\n",
    "metrics_file = None\n",
    "\n",
    "if expected_checkpoint.exists() and any(expected_checkpoint.iterdir()):\n",
    "    checkpoint_source = expected_checkpoint\n",
    "    print(f\"✓ Using expected checkpoint location: {checkpoint_source}\")\n",
    "elif actual_checkpoint.exists() and any(actual_checkpoint.iterdir()):\n",
    "    checkpoint_source = actual_checkpoint\n",
    "    print(f\"✓ Using actual checkpoint location: {checkpoint_source}\")\n",
    "    # Update final_output_dir to match actual location\n",
    "    final_output_dir = actual_checkpoint.parent\n",
    "\n",
    "if expected_metrics.exists():\n",
    "    metrics_file = expected_metrics\n",
    "elif actual_metrics.exists():\n",
    "    metrics_file = actual_metrics\n",
    "\n",
    "# Load metrics if available\n",
    "metrics = None\n",
    "if metrics_file and metrics_file.exists():\n",
    "    with open(metrics_file, \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "    print(f\"✓ Metrics loaded from: {metrics_file}\")\n",
    "    print(f\"  Metrics: {metrics}\")\n",
    "elif checkpoint_source:\n",
    "    print(f\"⚠ Warning: Metrics file not found, but checkpoint exists.\")\n",
    "    metrics = {\"status\": \"completed\", \"checkpoint_found\": True}\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Training completed but no checkpoint found.\\n\"\n",
    "        f\"  Expected: {expected_checkpoint}\\n\"\n",
    "        f\"  Actual: {actual_checkpoint}\\n\"\n",
    "        f\"  Please check training logs for errors.\"\n",
    "    )\n",
    "\n",
    "# Save cache file with actual paths\n",
    "save_json(FINAL_TRAINING_CACHE_FILE, {\n",
    "    \"output_dir\": str(final_output_dir),\n",
    "    \"backbone\": final_training_config[\"backbone\"],\n",
    "    \"config\": final_training_config,\n",
    "})\n",
    "\n",
    "# Backup checkpoint to Google Drive (if available)\n",
    "if checkpoint_source and checkpoint_source.exists() and any(checkpoint_source.iterdir()):\n",
    "    backup_to_drive(\n",
    "        checkpoint_source,\n",
    "        f\"{final_training_config['backbone']}_checkpoint\",\n",
    "        is_directory=True\n",
    "    )\n",
    "    \n",
    "    # Backup cache file to Drive\n",
    "    backup_to_drive(FINAL_TRAINING_CACHE_FILE, \"final_training_cache.json\", is_directory=False)\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Checkpoint directory not found or empty.\\n\"\n",
    "        f\"  Expected: {expected_checkpoint}\\n\"\n",
    "        f\"  Actual: {actual_checkpoint}\\n\"\n",
    "        f\"Training may have failed. Please check the training output above.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step P1-4: Model Conversion & Optimization\n",
    "\n",
    "Convert the final training checkpoint to an optimized ONNX model (int8 quantized) for production inference.\n",
    "\n",
    "**Platform Adapter Note**: The conversion script (`src/convert_to_onnx.py`) uses the platform adapter to automatically handle output paths and logging appropriately for local execution.\n",
    "\n",
    "**Checkpoint Restoration**: \n",
    "- **Google Colab**: If the checkpoint is not found locally (e.g., after a session disconnect), it will be automatically restored from Google Drive.\n",
    "- **Kaggle**: Checkpoints are automatically persisted in `/kaggle/working/` - no restoration needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import mlflow\n",
    "import shutil\n",
    "from shared.json_cache import load_json\n",
    "\n",
    "CONVERSION_SCRIPT_PATH = SRC_DIR / \"convert_to_onnx.py\"\n",
    "FINAL_TRAINING_CACHE_FILE = ROOT_DIR / \"notebooks\" / \"final_training_cache.json\"\n",
    "CONVERSION_OUTPUT_DIR = ROOT_DIR / \"outputs\" / \"conversion\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cache = load_json(FINAL_TRAINING_CACHE_FILE, default=None)\n",
    "\n",
    "if training_cache is None:\n",
    "    # Try to restore from Google Drive (if available)\n",
    "    if restore_from_drive(\"final_training_cache.json\", FINAL_TRAINING_CACHE_FILE, is_directory=False):\n",
    "        training_cache = load_json(FINAL_TRAINING_CACHE_FILE, default=None)\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Final training cache not found locally or in backup.\\n\"\n",
    "            f\"Please run Step P1-3.7: Final Training first.\"\n",
    "        )\n",
    "\n",
    "# Try to find checkpoint in expected location or actual location\n",
    "backbone = training_cache[\"backbone\"]\n",
    "expected_checkpoint_dir = Path(training_cache[\"output_dir\"]) / \"checkpoint\"\n",
    "actual_checkpoint_dir = ROOT_DIR / \"outputs\" / \"checkpoint\"\n",
    "\n",
    "print(f\"Looking for checkpoint...\")\n",
    "print(f\"  Expected: {expected_checkpoint_dir} (exists: {expected_checkpoint_dir.exists()})\")\n",
    "print(f\"  Actual: {actual_checkpoint_dir} (exists: {actual_checkpoint_dir.exists()})\")\n",
    "\n",
    "# Determine which checkpoint to use\n",
    "checkpoint_dir = None\n",
    "if expected_checkpoint_dir.exists() and any(expected_checkpoint_dir.iterdir()):\n",
    "    checkpoint_dir = expected_checkpoint_dir\n",
    "    print(f\"✓ Using expected checkpoint location: {checkpoint_dir}\")\n",
    "elif actual_checkpoint_dir.exists() and any(actual_checkpoint_dir.iterdir()):\n",
    "    checkpoint_dir = actual_checkpoint_dir\n",
    "    print(f\"✓ Using actual checkpoint location: {checkpoint_dir}\")\n",
    "else:\n",
    "    # Try to restore from Google Drive (if available)\n",
    "    checkpoint_dir = expected_checkpoint_dir\n",
    "    if restore_from_drive(f\"{backbone}_checkpoint\", checkpoint_dir, is_directory=True):\n",
    "        print(f\"✓ Checkpoint restored from backup\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Checkpoint directory not found locally or in backup.\\n\"\n",
    "            f\"  Expected: {expected_checkpoint_dir}\\n\"\n",
    "            f\"  Actual: {actual_checkpoint_dir}\\n\"\n",
    "            f\"Please ensure training completed successfully and checkpoint was backed up.\"\n",
    "        )\n",
    "\n",
    "conversion_output_dir = CONVERSION_OUTPUT_DIR / backbone\n",
    "conversion_output_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_args = [\n",
    "    sys.executable,\n",
    "    str(CONVERSION_SCRIPT_PATH),\n",
    "    \"--checkpoint-path\",\n",
    "    str(checkpoint_dir),\n",
    "    \"--config-dir\",\n",
    "    str(CONFIG_DIR),\n",
    "    \"--backbone\",\n",
    "    backbone,\n",
    "    \"--output-dir\",\n",
    "    str(conversion_output_dir),\n",
    "    \"--quantize-int8\",\n",
    "    \"--run-smoke-test\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_env = os.environ.copy()\n",
    "conversion_env[\"AZURE_ML_OUTPUT_onnx_model\"] = str(conversion_output_dir)\n",
    "\n",
    "mlflow_tracking_uri = mlflow.get_tracking_uri()\n",
    "if mlflow_tracking_uri:\n",
    "    conversion_env[\"MLFLOW_TRACKING_URI\"] = mlflow_tracking_uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(\n",
    "    conversion_args,\n",
    "    cwd=ROOT_DIR,\n",
    "    env=conversion_env,\n",
    "    capture_output=False,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "if result.returncode != 0:\n",
    "    raise RuntimeError(f\"Model conversion failed with return code {result.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.json_cache import save_json\n",
    "import shutil\n",
    "\n",
    "ONNX_MODEL_FILENAME = \"model_int8.onnx\"\n",
    "FALLBACK_ONNX_MODEL_FILENAME = \"model.onnx\"\n",
    "CONVERSION_CACHE_FILE = ROOT_DIR / \"notebooks\" / \"conversion_cache.json\"\n",
    "\n",
    "onnx_model_path = conversion_output_dir / ONNX_MODEL_FILENAME\n",
    "if not onnx_model_path.exists():\n",
    "    onnx_model_path = conversion_output_dir / FALLBACK_ONNX_MODEL_FILENAME\n",
    "\n",
    "if not onnx_model_path.exists():\n",
    "    raise FileNotFoundError(f\"ONNX model not found in {conversion_output_dir}\")\n",
    "\n",
    "print(f\"✓ Conversion completed. ONNX model: {onnx_model_path}\")\n",
    "\n",
    "save_json(CONVERSION_CACHE_FILE, {\n",
    "    \"onnx_model_path\": str(onnx_model_path),\n",
    "    \"backbone\": backbone,\n",
    "    \"checkpoint_dir\": str(checkpoint_dir),\n",
    "})\n",
    "\n",
    "# Backup ONNX model to Google Drive (if available)\n",
    "if onnx_model_path.exists():\n",
    "    backup_to_drive(onnx_model_path, f\"{backbone}_model.onnx\", is_directory=False)\n",
    "else:\n",
    "    print(f\"⚠ Warning: ONNX model not found for backup: {onnx_model_path}\")\n",
    "\n",
    "# Backup conversion cache file to Drive\n",
    "backup_to_drive(CONVERSION_CACHE_FILE, \"conversion_cache.json\", is_directory=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
